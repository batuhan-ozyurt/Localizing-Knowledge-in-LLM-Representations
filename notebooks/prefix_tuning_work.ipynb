{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6b72624-3313-4b6e-ba0c-2b6bc384fb85",
   "metadata": {},
   "source": [
    "## Necessary Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89dacc0-0543-49cd-bbfb-95ec4ed9c7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kuacc/users/bozyurt20/.conda/envs/hf/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from jinja2 import Template\n",
    "import xmltodict\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from rouge import Rouge\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ac9bf2-6674-49ab-b4eb-61683e0bdbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56310521-4abf-4243-afd3-45d8ee04115c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kuacc/users/bozyurt20/.conda/envs/hf/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "path_andersen = \"/kuacc/users/bozyurt20/ChildrenStories/Andersen\"\n",
    "path_fanny = \"/kuacc/users/bozyurt20/ChildrenStories/Fanny Fern\"\n",
    "path_annotations = \"/kuacc/users/bozyurt20/ChildrenStories/Annotations\"\n",
    "\n",
    "dir_list_andersen = os.listdir(path_andersen)\n",
    "dir_list_fanny = os.listdir(path_fanny)\n",
    "dir_list_annotations = os.listdir(path_annotations)\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "def text_clean_ending(example_text):\n",
    "    example_text = example_text.rstrip(\", ;-\\n\")\n",
    "    if example_text[-1] != \".\":\n",
    "        example_text += \".\"\n",
    "    return example_text\n",
    "\n",
    "def remove_new_lines(text):\n",
    "    paragraphs = text.split(\"\\n\\n\")\n",
    "    new_paragraphs = []\n",
    "    for paragraph in paragraphs:\n",
    "        new_paragraphs.append(paragraph.replace(\"\\n\", \" \"))\n",
    "    new_text = \"\\n\".join(new_paragraphs)\n",
    "    return new_text\n",
    "\n",
    "def remove_pronouns(answer):  \n",
    "    if answer[:6] == \"he is \":\n",
    "        answer = answer[6:]\n",
    "    elif answer[:7] == \"she is \":\n",
    "        answer = answer[7:]\n",
    "    elif answer[:6] == \"it is \":\n",
    "        answer = answer[6:]\n",
    "    elif answer[9:] == \"they are \":\n",
    "        answer = answer[9:]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c3d0fa-deb9-44eb-915a-e06dbecb6f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55fa2735-d9a7-4752-a459-470bb156ff57",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed18807d-86a1-40ef-8ece-0f6535a3aeb8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (relative_attention_bias): Embedding(32, 12)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseActDense(\n",
       "          (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseActDense(\n",
       "          (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseActDense(\n",
       "          (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseActDense(\n",
       "          (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseActDense(\n",
       "          (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseActDense(\n",
       "          (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (6): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseActDense(\n",
       "          (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (7): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseActDense(\n",
       "          (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (8): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseActDense(\n",
       "          (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (9): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseActDense(\n",
       "          (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (10): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseActDense(\n",
       "          (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (11): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseActDense(\n",
       "          (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf4ef2f-be1d-4fd5-b62f-1e978e54c920",
   "metadata": {},
   "source": [
    "##Creating the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6219ebb-2fab-4dc8-aeb5-829f706de6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"T5_tokenizer_dataset.txt\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a20c5964-a404-4b82-bbd3-fa6c25c45dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m     src_txt\u001b[38;5;241m.\u001b[39mappend(tupl[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(src_txt)):\n\u001b[0;32m---> 63\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_txt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     gold_location \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(tgt_txt[i], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     65\u001b[0m     gold_locations \u001b[38;5;241m=\u001b[39m all_tgt_txt[i]\n",
      "File \u001b[0;32m~/.conda/envs/hf/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3471\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3468\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   3469\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 3471\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3475\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3476\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/hf/lib/python3.8/site-packages/transformers/tokenization_utils.py:939\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, spaces_between_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    937\u001b[0m current_sub_text \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m filtered_tokens:\n\u001b[0;32m--> 939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m skip_special_tokens \u001b[38;5;129;01mand\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_special_ids\u001b[49m:\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madded_tokens_encoder:\n",
      "File \u001b[0;32m~/.conda/envs/hf/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1298\u001b[0m, in \u001b[0;36mSpecialTokensMixin.all_special_ids\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;124;03m`List[int]`: List the ids of the special tokens(`'<unk>'`, `'<cls>'`, etc.) mapped to class attributes.\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m all_toks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_special_tokens\n\u001b[0;32m-> 1298\u001b[0m all_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_tokens_to_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_toks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_ids\n",
      "File \u001b[0;32m~/.conda/envs/hf/lib/python3.8/site-packages/transformers/tokenization_utils.py:579\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.convert_tokens_to_ids\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    577\u001b[0m ids \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens:\n\u001b[0;32m--> 579\u001b[0m     ids\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_token_to_id_with_added_voc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "File \u001b[0;32m~/.conda/envs/hf/lib/python3.8/site-packages/transformers/tokenization_utils.py:588\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._convert_token_to_id_with_added_voc\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madded_tokens_encoder:\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madded_tokens_encoder[token]\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_token_to_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/hf/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:307\u001b[0m, in \u001b[0;36mT5Tokenizer._convert_token_to_id\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    305\u001b[0m     num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m-\u001b[39m num \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msp_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpiece_to_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/hf/lib/python3.8/site-packages/sentencepiece/__init__.py:501\u001b[0m, in \u001b[0;36m_batchnize.<locals>._batched_func\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    499\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [_func(\u001b[38;5;28mself\u001b[39m, n) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m arg]\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 501\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/hf/lib/python3.8/site-packages/sentencepiece/__init__.py:495\u001b[0m, in \u001b[0;36m_batchnize.<locals>._func\u001b[0;34m(v, n)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(n) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mint\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mpiece_size()):\n\u001b[1;32m    494\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpiece id is out of range.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 495\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/hf/lib/python3.8/site-packages/sentencepiece/__init__.py:134\u001b[0m, in \u001b[0;36mSentencePieceProcessor.PieceToId\u001b[0;34m(self, piece)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mGetPieceSize\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _sentencepiece\u001b[38;5;241m.\u001b[39mSentencePieceProcessor_GetPieceSize(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mPieceToId\u001b[39m(\u001b[38;5;28mself\u001b[39m, piece):\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _sentencepiece\u001b[38;5;241m.\u001b[39mSentencePieceProcessor_PieceToId(\u001b[38;5;28mself\u001b[39m, piece)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mIdToPiece\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mid\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prefix_tuning_dataset = {}\n",
    "num_templates = 23\n",
    "\n",
    "for k in range(1, num_templates+1):\n",
    "    prefix_tuning_dataset[k] = {}\n",
    "    prefix_tuning_dataset[k][\"train\"] = []\n",
    "    prefix_tuning_dataset[k][\"validation\"] = []\n",
    "    prefix_tuning_dataset[k][\"test\"] = []\n",
    "\n",
    "for k in [6]:#range(1, num_templates+1):\n",
    "    \n",
    "    bank = {\"train\": 199,\n",
    "       \"validation\": 0,\n",
    "       \"test\": 50 }\n",
    "    \n",
    "    source_text = {\"train\": [],\n",
    "       \"validation\": [],\n",
    "       \"test\": [] \n",
    "    }\n",
    "    target_text = {\"train\": [],\n",
    "       \"validation\": [],\n",
    "       \"test\": [] \n",
    "    }\n",
    "    all_target_text = {\"train\": [],\n",
    "       \"validation\": [],\n",
    "       \"test\": [] \n",
    "    }\n",
    "    \n",
    "    for i in range(len(dataset[k])):\n",
    "\n",
    "        split = random.choice(list(bank.keys()))\n",
    "\n",
    "        while bank[split] < 1:\n",
    "            split = random.choice(list(bank.keys()))\n",
    "\n",
    "        bank[split] -= 1\n",
    "        \n",
    "        source_tokens = tokenizer.encode(dataset[k][i][\"prompt\"], return_tensors=\"pt\")\n",
    "        source_text[split].append((i, source_tokens[0]))\n",
    "        target_text[split].append((i, tokenizer.encode(dataset[k][i][\"gold_locations\"].split(\"/\")[0], return_tensors=\"pt\")[0]))\n",
    "        all_target_text[split].append((i, dataset[k][i][\"gold_locations\"]))\n",
    "    \n",
    "    for split in bank.keys():\n",
    "        \n",
    "        source_text[split] = sorted(source_text[split], key=lambda x: len(x[1]))\n",
    "\n",
    "        src_txt = []\n",
    "        tgt_txt = []\n",
    "        all_tgt_txt = []\n",
    "\n",
    "        for tupl in source_text[split]:\n",
    "            i, tokens = tupl\n",
    "            for a in target_text[split]:\n",
    "                if a[0] == i:\n",
    "                    tgt_txt.append(a[1])\n",
    "                    break\n",
    "            for b in all_target_text[split]:\n",
    "                if b[0] == i:\n",
    "                    all_tgt_txt.append(b[1])\n",
    "        for tupl in source_text[split]:\n",
    "            src_txt.append(tupl[1])\n",
    "        for i in range(len(src_txt)):\n",
    "            prompt = tokenizer.decode(src_txt[i], skip_special_tokens=True)\n",
    "            gold_location = tokenizer.decode(tgt_txt[i], skip_special_tokens=True)\n",
    "            gold_locations = all_tgt_txt[i]\n",
    "            data_point = {}\n",
    "            data_point[\"text_a\"] = prompt\n",
    "            data_point[\"tgt_text\"] = gold_location\n",
    "            data_point[\"guid\"] = gold_locations\n",
    "            data_point[\"text_b\"] = \"\"\n",
    "            data_point[\"meta\"] = {}\n",
    "            data_point[\"label\"] = None\n",
    "\n",
    "            prefix_tuning_dataset[k][split].append(data_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb6e320c-af45-4be4-bc7e-3d7e920a09c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prefix_tuning_dataset.txt\", \"wb\") as f:\n",
    "    pickle.dump(prefix_tuning_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19304425-d6ec-448d-b811-3201eae7488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prefix_tuning_dataset.txt\", \"rb\") as f:\n",
    "    prefix_tuning_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da4cde5-32ab-47eb-a274-3c5c459a8a15",
   "metadata": {},
   "source": [
    "## OLD Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "803a0e51-6c20-4e9d-b66c-3e64661f4d90",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andersen_story1.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-40932e6eea6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_new_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_prompt_clipped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharacter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrammatical_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mdata_point\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text_a\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ff62a235f770>\u001b[0m in \u001b[0;36mcreate_prompt_clipped\u001b[0;34m(version, context, character, grammatical_number, max_no_tokens)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintro\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hf/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3343\u001b[0m         \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_py_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3345\u001b[0;31m         return self._decode(\n\u001b[0m\u001b[1;32m   3346\u001b[0m             \u001b[0mtoken_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3347\u001b[0m             \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hf/lib/python3.9/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, spaces_between_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0mcurrent_sub_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiltered_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mskip_special_tokens\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    940\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madded_tokens_encoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hf/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mall_special_ids\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mids\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspecial\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m'<unk>'\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m'<cls>'\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mmapped\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m         \"\"\"\n\u001b[0;32m-> 1253\u001b[0;31m         \u001b[0mall_toks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m         \u001b[0mall_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_toks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mall_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hf/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mall_special_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mConvert\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtokenizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddedToken\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mto\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \"\"\"\n\u001b[0;32m-> 1229\u001b[0;31m         \u001b[0mall_toks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens_extended\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mall_toks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hf/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mall_special_tokens_extended\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattr_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m             \u001b[0mall_toks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_toks\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_value\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mattr_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1245\u001b[0;31m         \u001b[0mall_toks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_toks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mall_toks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = {}\n",
    "all_locations = {\n",
    "    \"train\": 0,\n",
    "    \"validation\": 0,\n",
    "    \"test\": 0\n",
    "}\n",
    "    \n",
    "for k in range(1, 24):\n",
    "    dataset[k] = {}\n",
    "    dataset[k][\"train\"] = []\n",
    "    dataset[k][\"validation\"] = []\n",
    "    dataset[k][\"test\"] = []\n",
    "\n",
    "bank = {\"train\": 170,\n",
    "       \"validation\": 39,\n",
    "       \"test\": 40 }\n",
    "\n",
    "i = {\"train\": 0,\n",
    "    \"validation\": 0,\n",
    "    \"test\": 0}\n",
    "\n",
    "for item in sorted(dir_list_andersen):\n",
    "    \n",
    "    if item in dir_list_annotations:\n",
    "        \n",
    "        print(item)        \n",
    "        \n",
    "        f = open(os.path.join(path_andersen, item), 'r') \n",
    "        story = f.read()\n",
    "        f.close()\n",
    "                \n",
    "        f = open(os.path.join(path_annotations, item), 'r')\n",
    "        annotations = pd.read_csv(f, sep=\"\\t\")\n",
    "        annotations = annotations.values\n",
    "        f.close()\n",
    "               \n",
    "        paragraphs = story.split(\"\\n\\n\")\n",
    "        paragraph = paragraphs[0]\n",
    "        len_title = len(paragraph) + 2        \n",
    "    \n",
    "        for line in annotations:\n",
    "            \n",
    "            character = line[1]\n",
    "            gold_answer = line[2]\n",
    "            grammatical_number = line[3]\n",
    "\n",
    "            gold_location = gold_answer.split(\"/\")[0]\n",
    "            \n",
    "            split = random.choice(list(bank.keys()))\n",
    "                \n",
    "            while bank[split] < 1:\n",
    "                split = random.choice(list(bank.keys()))\n",
    "\n",
    "            bank[split] -= 1\n",
    "            \n",
    "            for k in range(1, 24):\n",
    "                \n",
    "                data_point = {}\n",
    "                \n",
    "                y = line[0]\n",
    "                x = y - 5120\n",
    "\n",
    "                if x < len_title:\n",
    "                    text = story[len_title:y]\n",
    "\n",
    "                else:\n",
    "                    x = story[x:y].find(\" \") + x\n",
    "                    text = story[x:y]\n",
    "                                    \n",
    "                text = text_clean_ending(text)\n",
    "                text = remove_new_lines(text)\n",
    "                \n",
    "                prompt, context2 = create_prompt_clipped(k, text, character, grammatical_number, 512)\n",
    "                \n",
    "                data_point[\"text_a\"] = prompt\n",
    "                data_point[\"tgt_text\"] = gold_location\n",
    "                data_point[\"guid\"] = i[split]\n",
    "                data_point[\"text_b\"] = \"\"\n",
    "                data_point[\"meta\"] = {}\n",
    "                data_point[\"label\"] = None\n",
    "                \n",
    "                dataset[k][split].append(data_point)\n",
    "                \n",
    "            all_locations[split][i[split]] = gold_answer.split(\"/\")\n",
    "          \n",
    "            \n",
    "            i[split] += 1\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4475efe8-0efb-42da-b58e-48237f138655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 3, 'validation': 4, 'test': 6}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0c7936-6657-4ab6-a5ea-934190ad42b0",
   "metadata": {},
   "source": [
    "##Prefix Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "430b3283-1933-48aa-bac9-6697387f28f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kuacc/users/bozyurt20/.conda/envs/hf/lib/python3.8/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "\n",
    "from openprompt.data_utils import InputExample\n",
    "\n",
    "from openprompt.data_utils.conditional_generation_dataset import WebNLGProcessor\n",
    "\n",
    "from openprompt.plms import load_plm\n",
    "\n",
    "from openprompt.prompts.prefix_tuning_template import PrefixTuningTemplate\n",
    "\n",
    "from openprompt import PromptDataLoader\n",
    "\n",
    "from openprompt import PromptForGeneration\n",
    "\n",
    "from transformers import AdamW\n",
    "\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "\n",
    "from openprompt.utils.metrics import generation_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c11b205-a511-45a2-80f8-f7ed9c483cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"guid\": \"out in the woods/in the woods/woods/the forest\",\n",
      "  \"label\": null,\n",
      "  \"meta\": {},\n",
      "  \"text_a\": \"Out in the woods stood a nice little Fir Tree. From the passage, where is the fir tree?\",\n",
      "  \"text_b\": \"\",\n",
      "  \"tgt_text\": \"out in the woods\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_dataset = {}\n",
    "for k in [6]:\n",
    "    my_dataset[k] = {}\n",
    "    my_dataset[k][\"train\"] = []\n",
    "    my_dataset[k][\"validation\"] = []\n",
    "    my_dataset[k][\"test\"] = []\n",
    "for k in [6]:\n",
    "    for split in prefix_tuning_dataset[k]:\n",
    "        my_dataset[k][split] = []\n",
    "        for data_point in prefix_tuning_dataset[k][split]:\n",
    "            input_example = InputExample(text_a=data_point['text_a'], text_b = data_point['text_b'], tgt_text =data_point['tgt_text'], label=None, guid=data_point['guid'])\n",
    "            my_dataset[k][split].append(input_example)\n",
    "print(my_dataset[6]['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9721b743-6f63-45e6-be3f-aac7255f4cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"t5\"\n",
    "model_path = \"t5-base\"\n",
    "plm_eval_mode = \"store_true\"\n",
    "lr = 5e-5\n",
    "num_epochs = 5\n",
    "\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7922dc4-a2e7-4a0c-a923-e36cc28bc4a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'OpenPrompt/datasets/CondGen/webnlg_2017/train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# we use WebNLG as an example, as well. Note that the evaluation of generation result should be done\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# by using the scripts provided by https://github.com/Yale-LILY/dart/tree/master/evaluation,\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Which we do not include in it.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m dataset \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 6\u001b[0m dataset[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mWebNLGProcessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_train_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOpenPrompt/datasets/CondGen/webnlg_2017/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m dataset[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m WebNLGProcessor()\u001b[38;5;241m.\u001b[39mget_dev_examples(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./datasets/CondGen/webnlg_2017/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m dataset[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m WebNLGProcessor()\u001b[38;5;241m.\u001b[39mget_test_examples(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./datasets/CondGen/webnlg_2017/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/hf/lib/python3.8/site-packages/openprompt/data_utils/data_processor.py:100\u001b[0m, in \u001b[0;36mDataProcessor.get_train_examples\u001b[0;34m(self, data_dir)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_train_examples\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_dir: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m InputExample:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    get train examples from the training file under :obj:`data_dir`\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    call ``get_examples(data_dir, \"train\")``, see :py:meth:`~openprompt.data_utils.data_processor.DataProcessor.get_examples`\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/hf/lib/python3.8/site-packages/openprompt/data_utils/conditional_generation_dataset.py:61\u001b[0m, in \u001b[0;36mWebNLGProcessor.get_examples\u001b[0;34m(self, data_dir, split)\u001b[0m\n\u001b[1;32m     59\u001b[0m examples \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     60\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(split))\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     62\u001b[0m     lines_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     64\u001b[0m full_rela_lst \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'OpenPrompt/datasets/CondGen/webnlg_2017/train.json'"
     ]
    }
   ],
   "source": [
    "# we use WebNLG as an example, as well. Note that the evaluation of generation result should be done\n",
    "# by using the scripts provided by https://github.com/Yale-LILY/dart/tree/master/evaluation,\n",
    "# Which we do not include in it.\n",
    "\n",
    "dataset = {}\n",
    "dataset[1]['train'] = WebNLGProcessor().get_train_examples(\"OpenPrompt/datasets/CondGen/webnlg_2017/\")\n",
    "dataset[1]['validation'] = WebNLGProcessor().get_dev_examples(\"./datasets/CondGen/webnlg_2017/\")\n",
    "dataset[1]['test'] = WebNLGProcessor().get_test_examples(\"./datasets/CondGen/webnlg_2017/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b4a75a8-81dc-4e00-81f9-d890b24ad054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pretrained model, its tokenizer, its config, and its TokenzerWrapper by one function\n",
    "\n",
    "plm, tokenizer, model_config, WrapperClass = load_plm(model, model_path)\n",
    "plm = T5ForConditionalGeneration.from_pretrained(\"T5_prefix_tuned\")\n",
    "# we can use a plain text as the default setting\n",
    "# i.e.\n",
    "# mytemplate = PrefixTuningTemplate(model=plm, tokenizer=tokenizer)\n",
    "# is equal to\n",
    "# mytemplate = PrefixTuningTemplate(model=plm, tokenizer=tokenizer, text='{\"placeholder\":\"text_a\"} {\"mask\"}')\n",
    "\n",
    "mytemplate = PrefixTuningTemplate(model=plm,  tokenizer=tokenizer, text=' {\"placeholder\":\"text_a\"} {\"special\": \"<eos>\"} {\"mask\"} ', using_decoder_past_key_values=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d7db491-e4d4-428a-9b76-4dcdcb7d8fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'text': ' Out in the woods stood a nice little Fir Tree. From the passage, where is the fir tree?', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<eos>', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}], {'guid': 'out in the woods/in the woods/woods/the forest', 'tgt_text': 'out in the woods'}]\n"
     ]
    }
   ],
   "source": [
    "# To better understand how does the template wrap the example, we visualize one instance.\n",
    "# You may observe that the example doesn't end with <|endoftext|> token. Don't worry, adding specific end-of-text token\n",
    "# is a language-model-specific token. we will add it for you in the TokenizerWrapper once you pass `predict_eos_token=True`\n",
    "wrapped_example = mytemplate.wrap_one_example(my_dataset[6]['train'][0])\n",
    "print(wrapped_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c85451c-da02-47cd-ba1c-e34d55e2bc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 199it [00:00, 312.29it/s]\n",
      "tokenizing: 50it [00:00, 384.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Your can loop over the dataset by yourself by subsequently call mytemplate.wrap_one_example  and WrapperClass().tokenizer()\n",
    "# but we have provide a PromptDataLoader for you.\n",
    "\n",
    "dataset = my_dataset[6]\n",
    "train_dataloader = PromptDataLoader(dataset=dataset[\"train\"], template=mytemplate, tokenizer=tokenizer,\n",
    "    tokenizer_wrapper_class=WrapperClass, max_seq_length=512, decoder_max_length=512,\n",
    "    batch_size=1,shuffle=False, teacher_forcing=True, predict_eos_token=True, # be sure to pass predict_eos_token=True if your template doesn't contain one, or you model may fail to stop generation.\n",
    "    truncate_method=\"head\")\n",
    "\n",
    "\"\"\"validation_dataloader = PromptDataLoader(dataset=dataset[\"validation\"], template=mytemplate, tokenizer=tokenizer,\n",
    "    tokenizer_wrapper_class=WrapperClass, max_seq_length=512, decoder_max_length=512,\n",
    "    batch_size=1,shuffle=False, teacher_forcing=False, predict_eos_token=True,\n",
    "    truncate_method=\"head\")\"\"\"\n",
    "\n",
    "test_dataloader = PromptDataLoader(dataset=dataset[\"test\"], template=mytemplate, tokenizer=tokenizer,\n",
    "    tokenizer_wrapper_class=WrapperClass, max_seq_length=512, decoder_max_length=512,\n",
    "    batch_size=1,shuffle=False, teacher_forcing=False, predict_eos_token=True,\n",
    "    truncate_method=\"head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e910c724-2f01-41b7-b977-f6c3093caa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pipeline model PromptForGeneration.\n",
    "\n",
    "prompt_model = PromptForGeneration(plm=plm,template=mytemplate, freeze_plm=True, tokenizer=tokenizer, plm_eval_mode=plm_eval_mode)\n",
    "if use_cuda:\n",
    "    prompt_model = prompt_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6ae6397-2e1e-4fd8-aaba-ddb2fcbe262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow PrefixTuninghttps://github.com/XiangLi1999/PrefixTuning), we also fix the language model\n",
    "# only include the template's parameters in training.\n",
    "\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "{\n",
    "    \"params\": [p for n, p in mytemplate.named_parameters() if (not any(nd in n for nd in no_decay)) and p.requires_grad],\n",
    "    \"weight_decay\": 0.0,\n",
    "},\n",
    "{\n",
    "    \"params\": [p for n, p in mytemplate.named_parameters() if any(nd in n for nd in no_decay) and p.requires_grad],\n",
    "    \"weight_decay\": 0.0,\n",
    "},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3221aa05-b849-4e97-b007-7177a2c215fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kuacc/users/bozyurt20/.conda/envs/hf/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=lr, eps=1e-8)\n",
    "tot_step  = len(train_dataloader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, 0, tot_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b70bab56-0d16-40da-9e04-ca888ef3de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluate function\n",
    "\n",
    "def evaluate(prompt_model, dataloader, split):\n",
    "    generated_sentence = []\n",
    "    groundtruth_sentence = []\n",
    "    exact_accuracy = []\n",
    "    fuzzy_accuracy = []\n",
    "    prompt_model.eval()\n",
    "    for step, inputs in enumerate(dataloader):\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "        _, output_sentences = prompt_model.generate(inputs, **generation_arguments)\n",
    "        generated_sentence.extend(output_sentences)\n",
    "        groundtruth_sentence.extend(inputs['tgt_text'])\n",
    "        # TODO: Tm gold location'larla karlatrmalsn !!!\n",
    "        gold_locations = inputs[\"guid\"][0].split(\"/\")\n",
    "        match1 = \"No\"\n",
    "        match2 = \"No\"\n",
    "        \n",
    "        out2 = remove_pronouns(output_sentences[0].lower())\n",
    "\n",
    "        pred_tokenized = word_tokenize(out2)\n",
    "        new_pred_tokens = [ token for token in pred_tokenized if token not in stop_words ]\n",
    "        pred_wo_stop_words = \" \".join(new_pred_tokens) \n",
    "\n",
    "        for gold_location in gold_locations:\n",
    "\n",
    "            gold_tokenized = word_tokenize(gold_location[0].lower())\n",
    "            new_gold_tokens = [ token for token in gold_tokenized if token not in stop_words ]\n",
    "            gold_wo_stop_words = \" \".join(new_gold_tokens)\n",
    "\n",
    "            if gold_wo_stop_words == pred_wo_stop_words:\n",
    "                match1 = \"Yes\"\n",
    "            if fuzz.partial_ratio(gold_wo_stop_words, pred_wo_stop_words) > 90:\n",
    "                match2 = \"Yes\"\n",
    "                \n",
    "        if match1 == \"Yes\": \n",
    "            exact_accuracy.append(1)\n",
    "        else:\n",
    "            exact_accuracy.append(0)\n",
    "        if match2 == \"Yes\": \n",
    "            fuzzy_accuracy.append(1)\n",
    "        else:\n",
    "            fuzzy_accuracy.append(0)\n",
    "\n",
    "        \n",
    "    #score = generation_metric(generated_sentence, groundtruth_sentence, \"sentence_bleu\")\n",
    "    #print(\"test_score\", score, flush=True)\n",
    "    return generated_sentence, exact_accuracy, fuzzy_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "460dbacd-cf42-40de-a41e-35d9d667700c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([198])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "725bf8f7-2b64-49ba-8811-6c024e4b4450",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_arguments = {\n",
    "    \"max_length\": 512,\n",
    "    \"max_new_tokens\": None,\n",
    "    \"min_length\": 0,\n",
    "    \"temperature\": 1.0,\n",
    "    \"do_sample\": False,\n",
    "    \"top_k\": 0,\n",
    "    \"top_p\": 0.9,\n",
    "    \"repetition_penalty\": 1.0,\n",
    "    \"num_beams\": 5,\n",
    "    \"bad_words_ids\": [[628], [198]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "885907f8-54de-491d-b454-e91c50a3e759",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, global_step 10 average loss: 0.4252411231994629 lr: 4.949748743718593e-05\n",
      "Epoch 0, global_step 20 average loss: 0.41144375228881835 lr: 4.899497487437186e-05\n",
      "Epoch 0, global_step 30 average loss: 0.48745624542236327 lr: 4.849246231155779e-05\n",
      "Epoch 0, global_step 40 average loss: 0.43117365264892576 lr: 4.7989949748743725e-05\n",
      "Epoch 0, global_step 50 average loss: 0.4726151542663574 lr: 4.748743718592965e-05\n",
      "Epoch 0, global_step 60 average loss: 0.5515932235717773 lr: 4.6984924623115577e-05\n",
      "Epoch 0, global_step 70 average loss: 0.5945601272583008 lr: 4.648241206030151e-05\n",
      "Epoch 0, global_step 80 average loss: 0.5067963943481445 lr: 4.597989949748744e-05\n",
      "Epoch 0, global_step 90 average loss: 0.467736457824707 lr: 4.5477386934673374e-05\n",
      "Epoch 0, global_step 100 average loss: 0.43539627265930175 lr: 4.49748743718593e-05\n",
      "Epoch 0, global_step 110 average loss: 0.43823619079589843 lr: 4.4472361809045225e-05\n",
      "Epoch 0, global_step 120 average loss: 0.5028336029052735 lr: 4.396984924623116e-05\n",
      "Epoch 0, global_step 130 average loss: 0.36822909164428713 lr: 4.346733668341709e-05\n",
      "Epoch 0, global_step 140 average loss: 0.31633499145507815 lr: 4.2964824120603016e-05\n",
      "Epoch 0, global_step 150 average loss: 0.3275475845336914 lr: 4.246231155778895e-05\n",
      "Epoch 0, global_step 160 average loss: 0.31049873733520506 lr: 4.1959798994974874e-05\n",
      "Epoch 0, global_step 170 average loss: 0.25449973678588866 lr: 4.1457286432160806e-05\n",
      "Epoch 0, global_step 180 average loss: 0.5041931371688843 lr: 4.095477386934674e-05\n",
      "Epoch 0, global_step 190 average loss: 0.18685029315948487 lr: 4.0452261306532664e-05\n",
      "Epoch 1, global_step 200 average loss: 0.21814311933517455 lr: 3.9949748743718597e-05\n",
      "Epoch 1, global_step 210 average loss: 0.11745638346672058 lr: 3.944723618090452e-05\n",
      "Epoch 1, global_step 220 average loss: 0.1615849552154541 lr: 3.8944723618090455e-05\n",
      "Epoch 1, global_step 230 average loss: 0.17972437286376952 lr: 3.844221105527639e-05\n",
      "Epoch 1, global_step 240 average loss: 0.13668950366973878 lr: 3.793969849246231e-05\n",
      "Epoch 1, global_step 250 average loss: 0.1336813645362854 lr: 3.7437185929648245e-05\n",
      "Epoch 1, global_step 260 average loss: 0.18373043155670166 lr: 3.693467336683417e-05\n",
      "Epoch 1, global_step 270 average loss: 0.1373252251148224 lr: 3.64321608040201e-05\n",
      "Epoch 1, global_step 280 average loss: 0.08321013712882995 lr: 3.592964824120603e-05\n",
      "Epoch 1, global_step 290 average loss: 0.1268927755355835 lr: 3.542713567839196e-05\n",
      "Epoch 1, global_step 300 average loss: 0.10141383934020996 lr: 3.4924623115577894e-05\n",
      "Epoch 1, global_step 310 average loss: 0.1385543918609619 lr: 3.442211055276382e-05\n",
      "Epoch 1, global_step 320 average loss: 0.12758715260028838 lr: 3.391959798994975e-05\n",
      "Epoch 1, global_step 330 average loss: 0.14744129228591918 lr: 3.341708542713568e-05\n",
      "Epoch 1, global_step 340 average loss: 0.09461723232269287 lr: 3.291457286432161e-05\n",
      "Epoch 1, global_step 350 average loss: 0.13172338926792146 lr: 3.241206030150754e-05\n",
      "Epoch 1, global_step 360 average loss: 0.07072831571102142 lr: 3.190954773869347e-05\n",
      "Epoch 1, global_step 370 average loss: 0.055546899914741515 lr: 3.14070351758794e-05\n",
      "Epoch 1, global_step 380 average loss: 0.3278674407303333 lr: 3.0904522613065326e-05\n",
      "Epoch 1, global_step 390 average loss: 0.13111688446998596 lr: 3.0402010050251255e-05\n",
      "Epoch 2, global_step 400 average loss: 0.10895961618423462 lr: 2.989949748743719e-05\n",
      "Epoch 2, global_step 410 average loss: 0.03835949194431305 lr: 2.9396984924623116e-05\n",
      "Epoch 2, global_step 420 average loss: 0.13495320415496825 lr: 2.8894472361809045e-05\n",
      "Epoch 2, global_step 430 average loss: 0.09246722674369812 lr: 2.8391959798994978e-05\n",
      "Epoch 2, global_step 440 average loss: 0.0912718563079834 lr: 2.7889447236180903e-05\n",
      "Epoch 2, global_step 450 average loss: 0.08433893322944641 lr: 2.738693467336684e-05\n",
      "Epoch 2, global_step 460 average loss: 0.14518886613845824 lr: 2.6884422110552765e-05\n",
      "Epoch 2, global_step 470 average loss: 0.11662658011913299 lr: 2.6381909547738694e-05\n",
      "Epoch 2, global_step 480 average loss: 0.05348619174957275 lr: 2.5879396984924626e-05\n",
      "Epoch 2, global_step 490 average loss: 0.08477118158340455 lr: 2.5376884422110552e-05\n",
      "Epoch 2, global_step 500 average loss: 0.06564743971824646 lr: 2.4874371859296484e-05\n",
      "Epoch 2, global_step 510 average loss: 0.12761922788619995 lr: 2.4371859296482413e-05\n",
      "Epoch 2, global_step 520 average loss: 0.0931575849801302 lr: 2.3869346733668342e-05\n",
      "Epoch 2, global_step 530 average loss: 0.12450394368171692 lr: 2.3366834170854275e-05\n",
      "Epoch 2, global_step 540 average loss: 0.07701924175024033 lr: 2.28643216080402e-05\n",
      "Epoch 2, global_step 550 average loss: 0.14136902742087842 lr: 2.2361809045226133e-05\n",
      "Epoch 2, global_step 560 average loss: 0.041838166803121565 lr: 2.1859296482412062e-05\n",
      "Epoch 2, global_step 570 average loss: 0.05760026562213898 lr: 2.135678391959799e-05\n",
      "Epoch 2, global_step 580 average loss: 0.2873816582113504 lr: 2.085427135678392e-05\n",
      "Epoch 2, global_step 590 average loss: 0.11729116159677505 lr: 2.035175879396985e-05\n",
      "Epoch 3, global_step 600 average loss: 0.09124937748908997 lr: 1.984924623115578e-05\n",
      "Epoch 3, global_step 610 average loss: 0.05149933367967605 lr: 1.934673366834171e-05\n",
      "Epoch 3, global_step 620 average loss: 0.1004981861114502 lr: 1.884422110552764e-05\n",
      "Epoch 3, global_step 630 average loss: 0.08566759493947029 lr: 1.834170854271357e-05\n",
      "Epoch 3, global_step 640 average loss: 0.08925906866788864 lr: 1.7839195979899497e-05\n",
      "Epoch 3, global_step 650 average loss: 0.11425586634874343 lr: 1.7336683417085427e-05\n",
      "Epoch 3, global_step 660 average loss: 0.13142138236761094 lr: 1.683417085427136e-05\n",
      "Epoch 3, global_step 670 average loss: 0.07123459941148758 lr: 1.6331658291457288e-05\n",
      "Epoch 3, global_step 680 average loss: 0.04861099320650101 lr: 1.5829145728643217e-05\n",
      "Epoch 3, global_step 690 average loss: 0.06685456866025925 lr: 1.5326633165829146e-05\n",
      "Epoch 3, global_step 700 average loss: 0.05922509264945984 lr: 1.4824120603015077e-05\n",
      "Epoch 3, global_step 710 average loss: 0.1463203754425049 lr: 1.4321608040201007e-05\n",
      "Epoch 3, global_step 720 average loss: 0.06522895316407085 lr: 1.3819095477386935e-05\n",
      "Epoch 3, global_step 730 average loss: 0.08402315998077392 lr: 1.3316582914572864e-05\n",
      "Epoch 3, global_step 740 average loss: 0.07095403027534485 lr: 1.2814070351758795e-05\n",
      "Epoch 3, global_step 750 average loss: 0.13156847917288542 lr: 1.2311557788944725e-05\n",
      "Epoch 3, global_step 760 average loss: 0.0227232041656971 lr: 1.1809045226130654e-05\n",
      "Epoch 3, global_step 770 average loss: 0.17051795054972171 lr: 1.1306532663316583e-05\n",
      "Epoch 3, global_step 780 average loss: 0.17769122653454542 lr: 1.0804020100502512e-05\n",
      "Epoch 3, global_step 790 average loss: 0.08916768652200699 lr: 1.0301507537688443e-05\n",
      "Epoch 4, global_step 800 average loss: 0.07751907905936241 lr: 9.798994974874372e-06\n",
      "Epoch 4, global_step 810 average loss: 0.06844074140489101 lr: 9.296482412060301e-06\n",
      "Epoch 4, global_step 820 average loss: 0.05956159445643425 lr: 8.793969849246232e-06\n",
      "Epoch 4, global_step 830 average loss: 0.08752457638084889 lr: 8.291457286432161e-06\n",
      "Epoch 4, global_step 840 average loss: 0.08808998748660088 lr: 7.788944723618092e-06\n",
      "Epoch 4, global_step 850 average loss: 0.11417863392829895 lr: 7.28643216080402e-06\n",
      "Epoch 4, global_step 860 average loss: 0.11614434217289091 lr: 6.7839195979899505e-06\n",
      "Epoch 4, global_step 870 average loss: 0.06187576217949391 lr: 6.2814070351758795e-06\n",
      "Epoch 4, global_step 880 average loss: 0.04188831928372383 lr: 5.778894472361809e-06\n",
      "Epoch 4, global_step 890 average loss: 0.06069218409061432 lr: 5.276381909547739e-06\n",
      "Epoch 4, global_step 900 average loss: 0.0478508015871048 lr: 4.773869346733668e-06\n",
      "Epoch 4, global_step 910 average loss: 0.14088162815570832 lr: 4.271356783919598e-06\n",
      "Epoch 4, global_step 920 average loss: 0.05719587225280702 lr: 3.7688442211055276e-06\n",
      "Epoch 4, global_step 930 average loss: 0.07529765677452087 lr: 3.2663316582914575e-06\n",
      "Epoch 4, global_step 940 average loss: 0.0711508531421423 lr: 2.7638190954773874e-06\n",
      "Epoch 4, global_step 950 average loss: 0.12146225360780954 lr: 2.261306532663317e-06\n",
      "Epoch 4, global_step 960 average loss: 0.009130210310220719 lr: 1.7587939698492463e-06\n",
      "Epoch 4, global_step 970 average loss: 0.270608619466424 lr: 1.256281407035176e-06\n",
      "Epoch 4, global_step 980 average loss: 0.06318360709771514 lr: 7.537688442211055e-07\n",
      "Epoch 4, global_step 990 average loss: 0.08727684679627419 lr: 2.5125628140703517e-07\n"
     ]
    }
   ],
   "source": [
    "# training and generation.\n",
    "global_step = 0\n",
    "tot_loss = 0\n",
    "log_loss = 0\n",
    "for epoch in range(num_epochs):\n",
    "    prompt_model.train()\n",
    "    for step, inputs in enumerate(train_dataloader):\n",
    "        global_step += 1\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "        loss = prompt_model(inputs)\n",
    "        loss.backward()\n",
    "        tot_loss += loss.item()\n",
    "        torch.nn.utils.clip_grad_norm_(mytemplate.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        if global_step %10 ==0:\n",
    "            print(\"Epoch {}, global_step {} average loss: {} lr: {}\".format(epoch, global_step, (tot_loss-log_loss)/500, scheduler.get_last_lr()[0]), flush=True)\n",
    "            log_loss = tot_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b54ac4ad-c3fa-4681-807d-de48d683bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_model.plm.save_pretrained(\"T5_prefix_tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a5b5e2a-2fa8-4cad-bb1a-ef3d03d55488",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sentence, exact_accuracy, fuzzy_accuracy = evaluate(prompt_model, train_dataloader, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5dfbf71-8cbd-41e8-92a4-9f988af732af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in the woods.',\n",
       " 'the time.',\n",
       " 'the street.',\n",
       " 'passage.',\n",
       " \"boy's mother.\",\n",
       " 'the chimney-corner.',\n",
       " 'leap-frog.',\n",
       " 'flea?',\n",
       " 'leap-frog.',\n",
       " 'king.',\n",
       " 'palace.',\n",
       " 'old man.',\n",
       " '.',\n",
       " 'the passage.',\n",
       " 'the door.',\n",
       " 'Emperor is sitting in his wardrobe.',\n",
       " 'the door.',\n",
       " '.',\n",
       " 'old King asked.',\n",
       " 'Prince asked.',\n",
       " 'the way.',\n",
       " 'the carriage.',\n",
       " 'the passage.',\n",
       " 'old King asked.',\n",
       " 'the hall.',\n",
       " 'the hall.',\n",
       " 'old King asked.',\n",
       " 'burdocks.',\n",
       " '<unk> <extra_id_1> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>',\n",
       " 'the house.',\n",
       " 'the middle of the room.',\n",
       " 'old house.',\n",
       " 'the middle of the village.',\n",
       " 'the palace.',\n",
       " 'the passage, where is Tuk?',\n",
       " 'the middle of the street.',\n",
       " 'the middle of the village.',\n",
       " 'of the passage.',\n",
       " 'the other side of the passage.',\n",
       " 'of the passage.',\n",
       " 'the castle.',\n",
       " 'the castle.',\n",
       " 'the midst of the snow.',\n",
       " 'the forest?',\n",
       " 'mother took?',\n",
       " 'the house?',\n",
       " 'heaven?',\n",
       " '?',\n",
       " '?',\n",
       " 'the tomb?',\n",
       " 'the church?',\n",
       " 'the midst of the procession?',\n",
       " '?',\n",
       " 'Emperor is supposed to be?',\n",
       " 'the tree?',\n",
       " '?',\n",
       " 'elderbush?',\n",
       " \"King's Son?\",\n",
       " '?',\n",
       " 'the wall?',\n",
       " 'other day?',\n",
       " '?',\n",
       " 'other day?',\n",
       " 'ant?',\n",
       " 'n?',\n",
       " '?',\n",
       " 'the collar?',\n",
       " 'collar came from?',\n",
       " 'the tree?',\n",
       " 'the other side?',\n",
       " 'God?',\n",
       " 'the wall?',\n",
       " 'horseback?',\n",
       " 'horseback?',\n",
       " 'hen?',\n",
       " 'house of Thorwaldsen?',\n",
       " 'castle?',\n",
       " 'sor?',\n",
       " 'old lady?',\n",
       " 'old lady?',\n",
       " 'old lady?',\n",
       " 'tained the old lady?',\n",
       " 'the church?',\n",
       " 'the church?',\n",
       " 'the church?',\n",
       " '?',\n",
       " 'door?',\n",
       " 'the church?',\n",
       " 'tained the old lady?',\n",
       " 'the church?',\n",
       " 'the church?',\n",
       " 'angel?',\n",
       " 'the door?',\n",
       " 'old lady?',\n",
       " 'psalm?',\n",
       " 'o?',\n",
       " 'prayer-book?',\n",
       " 'o?',\n",
       " \"Emperor's second ambassador?\",\n",
       " \"Emperor's second ambassador?\",\n",
       " '?',\n",
       " 'you?',\n",
       " 'atrics?',\n",
       " 'the procession?',\n",
       " 'side of the canopy?',\n",
       " 'world?',\n",
       " 'sion going?',\n",
       " 'sion?',\n",
       " 'Prince?',\n",
       " 'Prince?',\n",
       " 'pigsty?',\n",
       " 'Prince came?',\n",
       " '-by swineherd?',\n",
       " 'Prince?',\n",
       " 'Prince?',\n",
       " 'Emperor?',\n",
       " 'Prince?',\n",
       " 'rage coming from?',\n",
       " '?',\n",
       " 'the tree?',\n",
       " 'swineherd?',\n",
       " '?',\n",
       " '?',\n",
       " 'ferno?',\n",
       " 'nation?',\n",
       " 'the room?',\n",
       " 'the room?',\n",
       " 'truders?',\n",
       " 'the house?',\n",
       " 'n?',\n",
       " 'the tree?',\n",
       " 'growths? he asked.',\n",
       " 'n?',\n",
       " 'the house?',\n",
       " 'room?',\n",
       " 'room?',\n",
       " 'truder?',\n",
       " 'nkeepers?',\n",
       " 'truders?',\n",
       " 'ing?',\n",
       " 'n?',\n",
       " 'truders?',\n",
       " 'n?',\n",
       " 'Queen of Hearts?',\n",
       " 'Leap-frog?',\n",
       " 'the house?',\n",
       " 'wear?',\n",
       " '?',\n",
       " 'the tree?',\n",
       " 'children?',\n",
       " 'children?',\n",
       " 'sailor?',\n",
       " 'elderbush?',\n",
       " 'Elderbush?',\n",
       " '?',\n",
       " 'knob?',\n",
       " 'door?',\n",
       " 'little boy?',\n",
       " 'castle? he asked.',\n",
       " 'to the church?',\n",
       " '-up?',\n",
       " 'smithy?',\n",
       " '?',\n",
       " 'door?',\n",
       " 'story?',\n",
       " 'wear?',\n",
       " 'the tree?',\n",
       " 'n?',\n",
       " '?',\n",
       " 'Elder Tree? he asked.',\n",
       " 'the tea-pot?',\n",
       " 'casts?',\n",
       " 'owls?',\n",
       " 'owl?',\n",
       " 'children?',\n",
       " 'arrows?',\n",
       " 'ear?',\n",
       " 'atrics?',\n",
       " \"king's son?\",\n",
       " 'orems?',\n",
       " 'the trees?',\n",
       " 'son of a king?',\n",
       " 'ology?',\n",
       " 'old man?',\n",
       " 'boy?',\n",
       " 'old man?',\n",
       " 'boy came?',\n",
       " 'house?',\n",
       " 'little boy?',\n",
       " 'the wall?',\n",
       " 'old man?',\n",
       " '?',\n",
       " 'pewter soldier?',\n",
       " 'pewter soldier?',\n",
       " 'pewter soldier?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " 'the picture?']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8bda9522-1529-46af-b0b1-c6e846466ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function Module.named_buffers at 0x2b6db7c46430>\n"
     ]
    }
   ],
   "source": [
    "print(PromptForGeneration.named_buffers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ece9ce7b-4443-4575-b3ab-c95acb459e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"prefix_generations.txt\",'w') as f:\n",
    "    for i in generated_sentence:\n",
    "        f.write(i+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e387cbd-58c2-426e-ae6a-0527198cd1f2",
   "metadata": {},
   "source": [
    "##TO-DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7996e691-4f02-46b6-a496-335688db73e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_prompt_clipped(version, context, character, grammatical_number, max_no_tokens=512):\n",
    "    \n",
    "    if grammatical_number == 'singular':\n",
    "        to_be = 'is'\n",
    "    elif grammatical_number == 'plural':\n",
    "        to_be = 'are'\n",
    "    \n",
    "    if version in [1, 2, 9, 10, 11, 12, 13, 20, 21, 22]:\n",
    "        question = \"Where \" + to_be + \" \" + character + \"?\"\n",
    "    elif version in [4, 5, 7, 8, 15, 16, 18, 19]:\n",
    "        question = \"where \" + character + \" \" + to_be + \".\"\n",
    "    elif version in [3, 14]:\n",
    "        question = \"where \" + character + \" \" + to_be + \"?\"\n",
    "    elif version in [6, 17]:\n",
    "        question = \"where \" + to_be + \" \" + character + \"?\"\n",
    "        \n",
    "    if version == 1 or version == 12:\n",
    "        intro = \"Answer the question depending on the context.\"\n",
    "    elif version == 2 or version == 13:\n",
    "        intro = \"What is the answer?\"\n",
    "    elif version == 3 or version == 14:\n",
    "        intro = \"Can you tell me \"\n",
    "    elif version == 4 or version == 15:\n",
    "        intro = \"Please tell me \"\n",
    "    elif version == 5 or version == 16:\n",
    "        intro = \"Tell me \"\n",
    "    elif version == 6 or version == 17:\n",
    "        intro = \"From the passage, \"\n",
    "    elif version == 7 or version == 18:\n",
    "        intro = \"I want to know \"\n",
    "    elif version == 8 or version == 19:\n",
    "        intro = \"I want to ask \"\n",
    "    elif version == 9 or version == 20:\n",
    "        intro = \"What is the answer to: \"\n",
    "    elif version == 10 or version == 21:\n",
    "        intro = \"Find the answer to: \"\n",
    "    elif version == 11 or version == 22:\n",
    "        intro = \"Answer: \"     \n",
    "    \n",
    "    if version in [1, 2]:\n",
    "        oo = 0\n",
    "        tm = Template(\"\"\"{{ intro }}\n",
    "Context: {{context}};\n",
    "Question: {{question}};\n",
    "Answer: \"\"\")        \n",
    "        prompt = tm.render(intro=intro, context=context, question=question)\n",
    "        \n",
    "        while len(tokenizer.encode(prompt)) > max_no_tokens:\n",
    "            context = tokenizer.encode(context)\n",
    "            diff = len(tokenizer.encode(prompt)) - max_no_tokens\n",
    "            context = context[diff:]\n",
    "            oo += 1\n",
    "            if oo > 4:\n",
    "                context = context[1:]\n",
    "            context = tokenizer.decode(context, skip_special_tokens=True)\n",
    "            prompt = tm.render(intro=intro, context=context, question=question)\n",
    "        \n",
    "    elif version in [3, 4, 5, 6, 7, 8, 9, 10, 11]:\n",
    "        oo = 0\n",
    "        tm = Template(\"{{context}} {{intro}}{{question}} \")\n",
    "        prompt = tm.render(intro=intro, context=context, question=question)\n",
    "        while len(tokenizer.encode(prompt)) > max_no_tokens:\n",
    "            context = tokenizer.encode(context)\n",
    "            diff = len(tokenizer.encode(prompt)) - max_no_tokens\n",
    "            context = context[diff:]            \n",
    "            oo += 1\n",
    "            if oo > 4:\n",
    "                context = context[1:]\n",
    "            context = tokenizer.decode(context, skip_special_tokens=True)\n",
    "            prompt = tm.render(intro=intro, context=context, question=question)\n",
    "        \n",
    "        \n",
    "    elif version in [12, 13]:\n",
    "        oo = 0\n",
    "        tm = Template(\"\"\"{{ intro }}\n",
    "Context: {{context}};\n",
    "Question: {{question}};\n",
    "If you can't find the answer, please respond \"unanswerable\".\n",
    "Answer: \"\"\")\n",
    "        prompt = tm.render(intro=intro, context=context, question=question)\n",
    "        while len(tokenizer.encode(prompt)) > max_no_tokens:\n",
    "            context = tokenizer.encode(context)\n",
    "            diff = len(tokenizer.encode(prompt)) - max_no_tokens\n",
    "            context = context[diff:]\n",
    "            oo += 1\n",
    "            if oo > 4:\n",
    "                context = context[1:]\n",
    "            context = tokenizer.decode(context, skip_special_tokens=True)\n",
    "            prompt = tm.render(intro=intro, context=context, question=question)\n",
    "        \n",
    "    elif version in [14, 15, 16, 17, 18, 19, 20, 21, 22]:\n",
    "        oo = 0\n",
    "        tm = Template('{{context}} {{intro}}{{question}} If you can\\'t find the answer, please respond \"unanswerable\". ')\n",
    "        prompt = tm.render(intro=intro, context=context, question=question)    \n",
    "        while len(tokenizer.encode(prompt)) > max_no_tokens:\n",
    "            context = tokenizer.encode(context)\n",
    "            diff = len(tokenizer.encode(prompt)) - max_no_tokens\n",
    "            context = context[diff:]\n",
    "            oo += 1\n",
    "            if oo > 4:\n",
    "                context = context[1:]\n",
    "            context = tokenizer.decode(context, skip_special_tokens=True)\n",
    "            prompt = tm.render(intro=intro, context=context, question=question)\n",
    "            \n",
    "    elif version == 23:\n",
    "        oo = 0\n",
    "        prompt = \"Where \" + to_be + \" \" + character + \" in the following text: \" + context + \" Answer: \"\n",
    "        while len(tokenizer.encode(prompt)) > max_no_tokens:\n",
    "            context = tokenizer.encode(context)\n",
    "            diff = len(tokenizer.encode(prompt)) - max_no_tokens\n",
    "            context = context[diff:]\n",
    "            oo += 1\n",
    "            if oo > 4:\n",
    "                context = context[1:]\n",
    "            context = tokenizer.decode(context, skip_special_tokens=True)\n",
    "            prompt = \"Where \" + to_be + \" \" + character + \" in the following text: \" + context + \" Answer: \"\n",
    "        \n",
    "    return prompt, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af0d05d-0de9-48ae-bde4-f903a6ede3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
