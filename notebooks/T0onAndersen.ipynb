{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3763502-c173-4885-8e74-67b9989f9965",
   "metadata": {},
   "source": [
    "# Running for the First Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e4c89-5306-4ed8-84c6-4216cdf00b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27a870-9829-4468-a3b8-0515ef8dfd4a",
   "metadata": {},
   "source": [
    "# Necessary Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bee5eff-3541-40b0-8fbd-59af2f380947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from jinja2 import Template\n",
    "import xmltodict\n",
    "import pickle\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "#import Levenshtein as lev\n",
    "#from rouge import Rouge\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b619091-b6d2-4e8d-82ce-1d25739b198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ada4030-34b6-4805-92bf-23c70b572fea",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kuacc/users/bozyurt20/ChildrenStories/Andersen'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m path_fanny \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kuacc/users/bozyurt20/ChildrenStories/Fanny Fern\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m path_annotations \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kuacc/users/bozyurt20/ChildrenStories/Annotations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m dir_list_andersen \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_andersen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m dir_list_fanny \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(path_fanny)\n\u001b[1;32m      7\u001b[0m dir_list_annotations \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(path_annotations)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kuacc/users/bozyurt20/ChildrenStories/Andersen'"
     ]
    }
   ],
   "source": [
    "path_andersen = \"/kuacc/users/bozyurt20/ChildrenStories/Andersen\"\n",
    "path_fanny = \"/kuacc/users/bozyurt20/ChildrenStories/Fanny Fern\"\n",
    "path_annotations = \"/kuacc/users/bozyurt20/ChildrenStories/Annotations\"\n",
    "\n",
    "dir_list_andersen = os.listdir(path_andersen)\n",
    "dir_list_fanny = os.listdir(path_fanny)\n",
    "dir_list_annotations = os.listdir(path_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88c92f31-8a16-4eb4-837b-3b471a503e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /kuacc/apps/anaconda/5.2.0\n",
      "RBERT                    /kuacc/users/bozyurt20/.conda/envs/RBERT\n",
      "ace                      /kuacc/users/bozyurt20/.conda/envs/ace\n",
      "booknlp                  /kuacc/users/bozyurt20/.conda/envs/booknlp\n",
      "hf                    *  /kuacc/users/bozyurt20/.conda/envs/hf\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd0ac82-8b57-409b-9e4a-ffa79ca8ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1600cd2-9f4a-44bc-8f4c-6a0b8994e095",
   "metadata": {},
   "source": [
    "# Preparing the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e738a8ae-2775-4968-b490-b0f5b0705c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d36b8cdf6db424882e63aa8a0aa0933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e73d8984bc4a98a381301e6dc95981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"spiece.model\";:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c074d8fc97e34f0181256b731af6893b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/T0pp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f13e8bd-0576-4b17-902f-f776d312f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/kuacc/users/bozyurt20/hpc_run/105_persuasion.txt\"\n",
    "\n",
    "with open(path, \"r\") as f:\n",
    "    book = f.read()\n",
    "    \n",
    "indices = []\n",
    "for i in range(1, 100):\n",
    "    chapter_header = \"Chapter \" + str(i) + \"\\n\\n\"\n",
    "    indices.append(book.find(chapter_header))\n",
    "\n",
    "ind1 = indices[0]\n",
    "ind2 = indices[1]\n",
    "i = 2\n",
    "chapters = []\n",
    "while ind2 != -1:\n",
    "    chapters.append(book[ind1:ind2])\n",
    "    ind1 = ind2\n",
    "    ind2 = indices[i]\n",
    "    i += 1   \n",
    "    \n",
    "chapter1 = chapters[0]\n",
    "paragraph_start_ind = chapters[1].find(\"Mr Shepherd\")\n",
    "chapter2 = chapters[1][paragraph_start_ind:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "724c6501-9a44-47c5-b705-0d71641ffa2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2574 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2574"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(chapter2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a87aa8d3-4c85-4dac-a192-4442060b9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0pp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed849774-31b4-4398-827f-2919cb735370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have multiple GPU's, use this:\n",
    "model.parallelize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1cef84-c361-4767-9fad-7a721fe9c3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are using a single GPU, use the following to do parameter offloading:\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "431eba97-7b2f-4ac2-b5a5-ce7bed0b8628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c01be6-fc97-40bd-9b1f-5f8def074f47",
   "metadata": {},
   "source": [
    "# Example Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32ccd783-8bb7-4350-981c-9e14b7581366",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_str = \"\"\"What is the answer?\n",
    "Context: , and sent to her. The Emperor had them brought into a large hall, where the Princess was playing at “Visiting,” with the ladies of the court; and when she saw the caskets with the presents, she clapped her hands for joy. “Ah, if it were but a little pussy-cat!” said she; but the rose tree, with its beautiful rose came to view. “Oh, how prettily it is made!” said all the court ladies. “It is more than pretty,” said the Emperor, “it is charming!” But the Princess touched it, and was almost ready to cry. “Fie, papa!” said she. “It is not made at all, it is natural!” “Let us see what is in the other casket, before we get into a bad humor,” said the Emperor. So the nightingale came forth and sang so delightfully that at first no one could say anything ill-humored of her. “Superbe! Charmant!” exclaimed the ladies; for they all used to chatter French, each one worse than her neighbor. “How much the bird reminds me of the musical box that belonged to our blessed Empress,” said an old knight. “Oh yes! These are the same tones, the same execution.” “Yes! yes!” said the Emperor, and he wept like a child at the remembrance. “I will still hope that it is not a real bird,” said the Princess. “Yes, it is a real bird,” said those who had brought it. “Well then let the bird fly,” said the Princess; and she positively refused to see the Prince. However, he was not to be discouraged; he daubed his face over brown and black; pulled his cap over his ears, and knocked at the door. “Good day to my lord, the Emperor!” said he. “Can I have employment at the palace?” “Why, yes,” said the Emperor. “I want some one to take care of the pigs, for we have a great many of them.” So the Prince was appointed “Imperial Swineherd.” He had a dirty little room close by the pigsty; and there he sat the whole day, and worked. By the evening he had made a pretty little kitchen-pot. Little bells were hung all round it; and when the pot was boiling, these bells tinkled in the most charming manner, and played the old melody, “Ach! du lieber Augustin, Alles ist weg, weg, weg!”* * “Ah! dear Augustine! All is gone, gone, gone!” But what was still more curious, whoever held his finger in the smoke of the kitchen-pot, immediately smelt all the dishes that were cooking on every hearth in the city--this, you see, was something quite different from the rose. Now the Princess happened to walk that way; and when she heard the tune, she stood quite still, and seemed pleased; for she could play “Lieber Augustine”; it was the only piece she knew; and she played it with one finger. “Why there is my piece,” said the Princess. “That swineherd must certainly have been well educated! Go in and ask him the price of the instrument.” So one of the court-ladies must run in; however, she drew on wooden slippers first. “What will you take for the kitchen-pot?” said the lady. “I will have ten kisses from the Princess,” said the swineherd. “Yes, indeed!” said the lady. “I cannot sell it for less,” rejoined the swineherd. “He is an impudent fellow!” said the Princess, and she walked on; but when she had gone a little way, the bells tinkled so prettily “Ach! du lieber Augustin, Alles ist weg, weg, weg!” “Stay,” said the Princess. “Ask him if he will have ten kisses from the ladies of my court.” “No, thank you!” said the swineherd. “Ten kisses from the Princess, or I keep the kitchen-pot myself.” “That must not be, either!” said the Princess. “But do you all stand before me that no one may see us.” And the court-ladies placed themselves in front of her, ;\n",
    "Question: Where are the court-ladies?;,\n",
    "Answer: is not known haha. Told you. I rock.\n",
    "What is the answer?\n",
    "Context: , and sent to her. The Emperor had them brought into a large hall, where the Princess was playing at “Visiting,” with the ladies of the court; and when she saw the caskets with the presents, she clapped her hands for joy. “Ah, if it were but a little pussy-cat!” said she; but the rose tree, with its beautiful rose came to view. “Oh, how prettily it is made!” said all the court ladies. “It is more than pretty,” said the Emperor, “it is charming!” But the Princess touched it, and was almost ready to cry. “Fie, papa!” said she. “It is not made at all, it is natural!” “Let us see what is in the other casket, before we get into a bad humor,” said the Emperor. So the nightingale came forth and sang so delightfully that at first no one could say anything ill-humored of her. “Superbe! Charmant!” exclaimed the ladies; for they all used to chatter French, each one worse than her neighbor. “How much the bird reminds me of the musical box that belonged to our blessed Empress,” said an old knight. “Oh yes! These are the same tones, the same execution.” “Yes! yes!” said the Emperor, and he wept like a child at the remembrance. “I will still hope that it is not a real bird,” said the Princess. “Yes, it is a real bird,” said those who had brought it. “Well then let the bird fly,” said the Princess; and she positively refused to see the Prince. However, he was not to be discouraged; he daubed his face over brown and black; pulled his cap over his ears, and knocked at the door. “Good day to my lord, the Emperor!” said he. “Can I have employment at the palace?” “Why, yes,” said the Emperor. “I want some one to take care of the pigs, for we have a great many of them.” So the Prince was appointed “Imperial Swineherd.” He had a dirty little room close by the pigsty; and there he sat the whole day, and worked. By the evening he had made a pretty little kitchen-pot. Little bells were hung all round it; and when the pot was boiling, these bells tinkled in the most charming manner, and played the old melody, “Ach! du lieber Augustin, Alles ist weg, weg, weg!”* * “Ah! dear Augustine! All is gone, gone, gone!” But what was still more curious, whoever held his finger in the smoke of the kitchen-pot, immediately smelt all the dishes that were cooking on every hearth in the city--this, you see, was something quite different from the rose. Now the Princess happened to walk that way; and when she heard the tune, she stood quite still, and seemed pleased; for she could play “Lieber Augustine”; it was the only piece she knew; and she played it with one finger. “Why there is my piece,” said the Princess. “That swineherd must certainly have been well educated! Go in and ask him the price of the instrument.” So one of the court-ladies must run in; however, she drew on wooden slippers first. “What will you take for the kitchen-pot?” said the lady. “I will have ten kisses from the Princess,” said the swineherd. “Yes, indeed!” said the lady. “I cannot sell it for less,” rejoined the swineherd. “He is an impudent fellow!” said the Princess, and she walked on; but when she had gone a little way, the bells tinkled so prettily “Ach! du lieber Augustin, Alles ist weg, weg, weg!” “Stay,” said the Princess. “Ask him if he will have ten kisses from the ladies of my court.” “No, thank you!” said the swineherd. “Ten kisses from the Princess, or I keep the kitchen-pot myself.” “That must not be, either!” said the Princess. “But do you all stand before me that no one may see us.” And the court-ladies placed themselves in front of her, ;\n",
    "Question: Where are the court-ladies?;\n",
    "Answer: is not known haha. Told you. I rock.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecfde35e-af4b-4afa-8d88-85c34f729776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2074 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(my_str, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb0d94e1-2e44-4839-990f-7a34b7f24ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2074"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ee2e859-21bf-4fea-b176-b3a30ee7adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.to(\"cuda:0\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(inputs)   \n",
    "\n",
    "out = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ed0190f-a713-4e4c-9e03-fdb123bebe93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Emperor had them brought into a large hall, where the Princess was playing at “Visiting'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a792afb-afce-4c43-97a0-90cb34e3b6fe",
   "metadata": {},
   "source": [
    "# Creating Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98bc9d9-e777-4f38-b700-22576854470c",
   "metadata": {},
   "source": [
    "## 1. Context Already Finalized Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a0e218f-326a-4067-882a-5da92cdf66c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_strict(version, context, character, grammatical_number):\n",
    "    \n",
    "    if grammatical_number == 'singular':\n",
    "        to_be = 'is'\n",
    "    elif grammatical_number == 'plural':\n",
    "        to_be = 'are'\n",
    "    \n",
    "    if version in [1, 2, 9, 10, 11, 12, 13, 20, 21, 22]:\n",
    "        question = \"Where \" + to_be + \" \" + character + \"?\"\n",
    "    elif version in [4, 5, 7, 8, 15, 16, 18, 19]:\n",
    "        question = \"where \" + character + \" \" + to_be + \".\"\n",
    "    elif version in [3, 14]:\n",
    "        question = \"where \" + character + \" \" + to_be + \"?\"\n",
    "    elif version in [6, 17]:\n",
    "        question = \"where \" + to_be + \" \" + character + \"?\"\n",
    "        \n",
    "    if version == 1 or version == 12:\n",
    "        intro = \"Answer the question depending on the context.\"\n",
    "    elif version == 2 or version == 13:\n",
    "        intro = \"What is the answer?\"\n",
    "    elif version == 3 or version == 14:\n",
    "        intro = \"Can you tell me \"\n",
    "    elif version == 4 or version == 15:\n",
    "        intro = \"Please tell me \"\n",
    "    elif version == 5 or version == 16:\n",
    "        intro = \"Tell me \"\n",
    "    elif version == 6 or version == 17:\n",
    "        intro = \"From the passage, \"\n",
    "    elif version == 7 or version == 18:\n",
    "        intro = \"I want to know \"\n",
    "    elif version == 8 or version == 19:\n",
    "        intro = \"I want to ask \"\n",
    "    elif version == 9 or version == 20:\n",
    "        intro = \"What is the answer to: \"\n",
    "    elif version == 10 or version == 21:\n",
    "        intro = \"Find the answer to: \"\n",
    "    elif version == 11 or version == 22:\n",
    "        intro = \"Answer: \"     \n",
    "        \n",
    "    if version in [1, 2]:\n",
    "        tm = Template(\"\"\"{{ intro }}\n",
    "Context: {{context}};\n",
    "Question: {{question}};\n",
    "Answer: \"\"\")\n",
    "        prompt = tm.render(intro=intro, context=context, question=question)\n",
    "    elif version in [3, 4, 5, 6, 7, 8, 9, 10, 11]:\n",
    "        tm = Template(\"{{context}} {{intro}}{{question}}\")\n",
    "        prompt = tm.render(intro=intro, context=context, question=question)\n",
    "    elif version in [12, 13]:\n",
    "        tm = Template(\"\"\"{{ intro }}\n",
    "Context: {{context}};\n",
    "Question: {{question}};\n",
    "If you can't find the answer, please respond \"unanswerable\".\n",
    "Answer: \"\"\")\n",
    "        prompt = tm.render(intro=intro, context=context, question=question)\n",
    "    elif version in [14, 15, 16, 17, 18, 19, 20, 21, 22]:\n",
    "        tm = Template('{{context}} {{intro}}{{question}} If you can\\'t find the answer, please respond \"unanswerable\".\"')\n",
    "        prompt = tm.render(intro=intro, context=context, question=question)\n",
    "    elif version == 23:\n",
    "        prompt = \"Where \" + to_be + \" \" + character + \" in the following text: \" + context + \" Answer: \"         \n",
    "        \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085a9071-abd1-48e7-8079-9796de752813",
   "metadata": {},
   "source": [
    "## 2. Context Has To Be Clipped First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35fe6cd6-cc82-4a49-ae35-9db9815218e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_clipped(version, context, character, grammatical_number, max_no_tokens=1024):\n",
    "    \n",
    "    if grammatical_number == 'singular':\n",
    "        to_be = 'is'\n",
    "    elif grammatical_number == 'plural':\n",
    "        to_be = 'are'\n",
    "    \n",
    "    if version in [1, 2, 9, 10, 11, 12, 13, 20, 21, 22]:\n",
    "        question = \"Where \" + to_be + \" \" + character + \"?\"\n",
    "    elif version in [4, 5, 7, 8, 15, 16, 18, 19]:\n",
    "        question = \"where \" + character + \" \" + to_be + \".\"\n",
    "    elif version in [3, 14]:\n",
    "        question = \"where \" + character + \" \" + to_be + \"?\"\n",
    "    elif version in [6, 17]:\n",
    "        question = \"where \" + to_be + \" \" + character + \"?\"\n",
    "        \n",
    "    if version == 1 or version == 12:\n",
    "        intro = \"Answer the question depending on the context.\"\n",
    "    elif version == 2 or version == 13:\n",
    "        intro = \"What is the answer?\"\n",
    "    elif version == 3 or version == 14:\n",
    "        intro = \"Can you tell me \"\n",
    "    elif version == 4 or version == 15:\n",
    "        intro = \"Please tell me \"\n",
    "    elif version == 5 or version == 16:\n",
    "        intro = \"Tell me \"\n",
    "    elif version == 6 or version == 17:\n",
    "        intro = \"From the passage, \"\n",
    "    elif version == 7 or version == 18:\n",
    "        intro = \"I want to know \"\n",
    "    elif version == 8 or version == 19:\n",
    "        intro = \"I want to ask \"\n",
    "    elif version == 9 or version == 20:\n",
    "        intro = \"What is the answer to: \"\n",
    "    elif version == 10 or version == 21:\n",
    "        intro = \"Find the answer to: \"\n",
    "    elif version == 11 or version == 22:\n",
    "        intro = \"Answer: \"     \n",
    "    \n",
    "    if version in [1, 2]:\n",
    "        oo = 0\n",
    "        tm = Template(\"\"\"{{ intro }}\n",
    "Context: {{context}};\n",
    "Question: {{question}};\n",
    "Answer: \"\"\")        \n",
    "        prompt = tm.render(intro=intro, context=context, question=question)\n",
    "        \n",
    "        while len(tokenizer.encode(prompt)) > max_no_tokens:\n",
    "            context = tokenizer.encode(context)\n",
    "            diff = len(tokenizer.encode(prompt)) - max_no_tokens\n",
    "            context = context[diff:]\n",
    "            oo += 1\n",
    "            if oo > 4:\n",
    "                context = context[1:]\n",
    "            context = tokenizer.decode(context, skip_special_tokens=True)\n",
    "            prompt = tm.render(intro=intro, context=context, question=question)\n",
    "        \n",
    "    elif version in [3, 4, 5, 6, 7, 8, 9, 10, 11]:\n",
    "        oo = 0\n",
    "        tm = Template(\"{{context}} {{intro}}{{question}}\")\n",
    "        prompt = tm.render(intro=intro, context=context, question=question)\n",
    "        while len(tokenizer.encode(prompt)) > max_no_tokens:\n",
    "            context = tokenizer.encode(context)\n",
    "            diff = len(tokenizer.encode(prompt)) - max_no_tokens\n",
    "            context = context[diff:]            \n",
    "            oo += 1\n",
    "            if oo > 4:\n",
    "                context = context[1:]\n",
    "            context = tokenizer.decode(context, skip_special_tokens=True)\n",
    "            prompt = tm.render(intro=intro, context=context, question=question)\n",
    "        \n",
    "        \n",
    "    elif version in [12, 13]:\n",
    "        oo = 0\n",
    "        tm = Template(\"\"\"{{ intro }}\n",
    "Context: {{context}};\n",
    "Question: {{question}};\n",
    "If you can't find the answer, please respond \"unanswerable\".\n",
    "Answer: \"\"\")\n",
    "        prompt = tm.render(intro=intro, context=context, question=question)\n",
    "        while len(tokenizer.encode(prompt)) > max_no_tokens:\n",
    "            context = tokenizer.encode(context)\n",
    "            diff = len(tokenizer.encode(prompt)) - max_no_tokens\n",
    "            context = context[diff:]\n",
    "            oo += 1\n",
    "            if oo > 4:\n",
    "                context = context[1:]\n",
    "            context = tokenizer.decode(context, skip_special_tokens=True)\n",
    "            prompt = tm.render(intro=intro, context=context, question=question)\n",
    "        \n",
    "    elif version in [14, 15, 16, 17, 18, 19, 20, 21, 22]:\n",
    "        oo = 0\n",
    "        tm = Template('{{context}} {{intro}}{{question}} If you can\\'t find the answer, please respond \"unanswerable\".\"')\n",
    "        prompt = tm.render(intro=intro, context=context, question=question)    \n",
    "        while len(tokenizer.encode(prompt)) > max_no_tokens:\n",
    "            context = tokenizer.encode(context)\n",
    "            diff = len(tokenizer.encode(prompt)) - max_no_tokens\n",
    "            context = context[diff:]\n",
    "            oo += 1\n",
    "            if oo > 4:\n",
    "                context = context[1:]\n",
    "            context = tokenizer.decode(context, skip_special_tokens=True)\n",
    "            prompt = tm.render(intro=intro, context=context, question=question)\n",
    "            \n",
    "    elif version == 23:\n",
    "        oo = 0\n",
    "        prompt = \"Where \" + to_be + \" \" + character + \" in the following text: \" + context + \" Answer: \"\n",
    "        while len(tokenizer.encode(prompt)) > max_no_tokens:\n",
    "            context = tokenizer.encode(context)\n",
    "            diff = len(tokenizer.encode(prompt)) - max_no_tokens\n",
    "            context = context[diff:]\n",
    "            oo += 1\n",
    "            if oo > 4:\n",
    "                context = context[1:]\n",
    "            context = tokenizer.decode(context, skip_special_tokens=True)\n",
    "            prompt = \"Where \" + to_be + \" \" + character + \" in the following text: \" + context + \" Answer: \"\n",
    "        \n",
    "    return prompt, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4c5565e9-589d-4115-b14d-e73382ba6868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 11, 1]\n",
      "[5, 11, 1]\n",
      ". and\n",
      "[3, 5, 11, 1]\n",
      ". and\n"
     ]
    }
   ],
   "source": [
    "context = tokenizer.encode(\". and\")\n",
    "print(context)\n",
    "context = context[1:]\n",
    "print(context)\n",
    "context = tokenizer.decode(context, skip_special_tokens=True)\n",
    "print(context)\n",
    "context = tokenizer.encode(context)\n",
    "print(context)\n",
    "context = tokenizer.decode(context, skip_special_tokens=True)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cea7fd34-19c9-492b-9938-9683e917ea18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode( [3, 5] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d673a6e6-c6a4-47d9-9acd-622bd0ae3600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([3, 5], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8882b3d6-81ae-42a3-b73c-9e42f0a681dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1700, 1]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(tokenizer.decode([1700]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44dc77b-4a47-4a26-a244-49347b5b9c41",
   "metadata": {},
   "source": [
    "# Accuracy Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e05c3c73-9c36-42a9-bd3f-0847713d4e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(predictions):\n",
    "\n",
    "    matches_exact = {}\n",
    "\n",
    "    for item in predictions:\n",
    "\n",
    "        matches_exact[item] = [ [] for _ in range(1,24)]\n",
    "\n",
    "        f = open(os.path.join(path_annotations, item), 'r')\n",
    "        annotations = pd.read_csv(f, sep=\"\\t\")\n",
    "        annotations = annotations.values #numpy array\n",
    "        f.close()\n",
    "\n",
    "        for k in range(1,24):\n",
    "\n",
    "            pred_locs = predictions[item][k-1]\n",
    "            i = 0\n",
    "\n",
    "            for line in annotations:\n",
    "\n",
    "                character = line[1]\n",
    "                gold_locations = line[2].split(\"/\")\n",
    "                \n",
    "                \n",
    "                pred_tokenized = word_tokenize(pred_locs[i].lower())\n",
    "                new_pred_tokens = [ token for token in pred_tokenized if token not in stop_words]\n",
    "                pred_wo_stop_words = \" \".join(new_pred_tokens)\n",
    "                \n",
    "                char_tokenized = word_tokenize(character.lower())\n",
    "                new_char_tokens = [ token for token in char_tokenized if token not in stop_words]\n",
    "                char_wo_stop_words = \" \".join(new_char_tokens)\n",
    "                \n",
    "                if char_wo_stop_words not in \" \".join(gold_locations):\n",
    "                    pred_wo_stop_words = pred_wo_stop_words.replace(char_wo_stop_words, \"\")   \n",
    "                \n",
    "                else:\n",
    "                    if pred_wo_stop_words[len(char_wo_stop_words)+1:len(char_wo_stop_words)+3] == \"is\" or pred_wo_stop_words[len(char_wo_stop_words)+1:len(char_wo_stop_words)+4] == \"are\":\n",
    "                        pred_wo_stop_words = pred_wo_stop_words[len(char_wo_stop_words)+1:]\n",
    "\n",
    "                match = False\n",
    "\n",
    "                for gold_location in gold_locations:\n",
    "\n",
    "                    gold_tokenized = word_tokenize(gold_location.lower())\n",
    "                    new_gold_tokens = [ token for token in gold_tokenized if token not in stop_words]\n",
    "                    gold_wo_stop_words = \" \".join(new_gold_tokens)\n",
    "\n",
    "                    if gold_wo_stop_words == pred_wo_stop_words:\n",
    "                        match = True\n",
    "\n",
    "                if match:\n",
    "                    matches_exact[item][k-1].append(1)\n",
    "                else:\n",
    "                    matches_exact[item][k-1].append(0)\n",
    "\n",
    "                i += 1\n",
    "    \n",
    "    return matches_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7086fd32-b6ad-4b27-b361-a5a019b2431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_match(predictions):\n",
    "    \n",
    "    matches_fuzzy = {}\n",
    "\n",
    "    for item in predictions:\n",
    "\n",
    "        print(item)\n",
    "        matches_fuzzy[item] = [ [] for _ in range(1,24)]\n",
    "\n",
    "        f = open(os.path.join(path_annotations, item), 'r')\n",
    "        annotations = pd.read_csv(f, sep=\"\\t\")\n",
    "        annotations = annotations.values #numpy array\n",
    "        f.close()\n",
    "\n",
    "        for k in range(1,24):\n",
    "\n",
    "            pred_locs = predictions[item][k-1]        \n",
    "            i = 0\n",
    "\n",
    "            for line in annotations:\n",
    "\n",
    "                gold_locations = line[2].split(\"/\")\n",
    "\n",
    "                pred_tokenized = word_tokenize(pred_locs[i].lower())\n",
    "                new_pred_tokens = [ token for token in pred_tokenized if token not in stop_words ]\n",
    "                pred_wo_stop_words = \" \".join(new_pred_tokens)\n",
    "                \n",
    "                char_tokenized = word_tokenize(character.lower())\n",
    "                new_char_tokens = [ token for token in char_tokenized if token not in stop_words]\n",
    "                char_wo_stop_words = \" \".join(new_char_tokens)\n",
    "                \n",
    "                if char_wo_stop_words not in \" \".join(gold_locations):\n",
    "                    pred_wo_stop_words = pred_wo_stop_words.replace(char_wo_stop_words, \"\")   \n",
    "                \n",
    "                else:\n",
    "                    if pred_wo_stop_words[len(char_wo_stop_words)+1:len(char_wo_stop_words)+3] == \"is\" or pred_wo_stop_words[len(char_wo_stop_words)+1:len(char_wo_stop_words)+4] == \"are\":\n",
    "                        pred_wo_stop_words = pred_wo_stop_words[len(char_wo_stop_words)+1:]\n",
    "\n",
    "                match = False\n",
    "\n",
    "                for gold_location in gold_locations:\n",
    "\n",
    "                    gold_tokenized = word_tokenize(gold_location.lower())\n",
    "                    new_gold_tokens = [ token for token in gold_tokenized if token not in stop_words ]\n",
    "                    gold_wo_stop_words = \" \".join(new_gold_tokens)\n",
    "\n",
    "                    if fuzz.partial_ratio(gold_wo_stop_words, pred_wo_stop_words) > 90:\n",
    "                        match = True\n",
    "\n",
    "                if match: \n",
    "                    matches_fuzzy[item][k-1].append(1)\n",
    "                else:\n",
    "                    matches_fuzzy[item][k-1].append(0)\n",
    "\n",
    "                i += 1\n",
    "                \n",
    "    return matches_fuzzy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468584f6-949d-4e1a-a06c-1611d89a45ed",
   "metadata": {},
   "source": [
    "# Closer look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e35213ac-cc5c-4126-89da-a19bde63bfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andersen_story2.txt\n",
      "Andersen_story8.txt\n",
      "Andersen_story11.txt\n",
      "Andersen_story7.txt\n",
      "Andersen_story17.txt\n",
      "Andersen_story15.txt\n",
      "Andersen_story9.txt\n",
      "Andersen_story5.txt\n",
      "Andersen_story1.txt\n",
      "Andersen_story12.txt\n",
      "Andersen_story16.txt\n",
      "Andersen_story18.txt\n",
      "Andersen_story3.txt\n",
      "Andersen_story10.txt\n",
      "Andersen_story13.txt\n"
     ]
    }
   ],
   "source": [
    "no_tokens = {}\n",
    "for item in dir_list_andersen:\n",
    "    \n",
    "    if item in dir_list_annotations:\n",
    "        \n",
    "        f = open(os.path.join(path_andersen, item), 'r') \n",
    "        story = f.read()\n",
    "        f.close()\n",
    "        \n",
    "        tokens = tokenizer.encode(story)\n",
    "        \n",
    "        no_tokens[item[len(\"Andersen_story\"):-4]] = len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "78ada52d-039f-4f6d-88f4-d9743decfb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(\"no_tokens.xlsx\", engine='xlsxwriter')\n",
    "no_tokens = dict(sorted(no_tokens.items(), key=lambda item: int(item[0])))\n",
    "df = pd.DataFrame(data=no_tokens, index=[\"no_tokens\"])\n",
    "df = (df.T)\n",
    "df.to_excel(writer, sheet_name=str(1))\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73e44ff4-2027-4295-85c7-f0ead2f708c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tokens_np = np.array(list(no_tokens.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6ce6f1ae-463a-4114-bc6b-275c1e19b2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "547"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(no_tokens_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c6ce0748-45cb-4a73-9ef6-037b54b8e58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4628"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(no_tokens_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c86ae8a-8b7d-439b-8a9c-5a722c59c796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2441.0666666666666"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(no_tokens_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8d68221f-e86b-4641-b7f1-9ec9a6f3b07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1221.2500954168052"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(no_tokens_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d5a82db3-71e4-4fce-b0b7-1e0f7ead4d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1333.5, 2558. , 2908.5])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(no_tokens_np, [25, 50, 75])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3319e22f-60ad-494e-bdce-d844fa813fff",
   "metadata": {},
   "source": [
    "# Method 1: Start of the paragraph --> End of the paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26bc4bd-4791-474b-96dc-c79a47ce268a",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed314f-32c1-45dd-bb77-0d4b1a2460ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andersen_story2.txt\n",
      "60\n",
      "Andersen_story8.txt\n",
      "54\n",
      "Andersen_story11.txt\n",
      "24\n",
      "Andersen_story7.txt\n",
      "19\n",
      "Andersen_story17.txt\n",
      "17\n",
      "Andersen_story15.txt\n",
      "15\n",
      "Andersen_story9.txt\n",
      "22\n",
      "Andersen_story5.txt\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "m1_predictions = {}\n",
    "\n",
    "for item in dir_list_andersen:\n",
    "    \n",
    "    if item in dir_list_annotations:\n",
    "        \n",
    "        print(item)\n",
    "        \n",
    "        f = open(os.path.join(path_andersen, item), 'r') \n",
    "        story = f.read()\n",
    "        f.close()\n",
    "\n",
    "        paragraphs = story.split(\"\\n\\n\")\n",
    "        \n",
    "        out_path = \"Method1_\" + item[:-3] + \"xlsx\"\n",
    "        writer = pd.ExcelWriter(out_path, engine='xlsxwriter')\n",
    "        workbook = writer.book\n",
    "        format = workbook.add_format({'text_wrap': True})\n",
    "        \n",
    "        m1_predictions[item] = [ [] for _ in range(1,24)]\n",
    "        \n",
    "        f = open(os.path.join(path_annotations, item), 'r')\n",
    "        annotations = pd.read_csv(f, sep=\"\\t\")\n",
    "        annotations = annotations.values\n",
    "        f.close()\n",
    "        \n",
    "        no_paragraphs = len(paragraphs)\n",
    "        print(no_paragraphs)\n",
    "        \n",
    "        i = 0 # line number in the annotation file\n",
    "        j = 0 # paragraph number\n",
    "        \n",
    "        paragraph = paragraphs[0]\n",
    "        paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "        char_count = len(paragraph) + 2\n",
    "        \n",
    "        while i < len(annotations) and j < no_paragraphs:\n",
    "            \n",
    "            if annotations[i][2] == \"0\":\n",
    "                i += 1\n",
    "                continue\n",
    "            else:     \n",
    "                if char_count + 2 >= annotations[i][0]:\n",
    "                    \n",
    "                    character = annotations[i][1]\n",
    "                    gold_answer = annotations[i][2]\n",
    "                    grammatical_number = annotations[i][3]         \n",
    "                    context = paragraph\n",
    "                    context = context.rstrip(\", ;-\\n\")\n",
    "                    my_dic = {context: [gold_answer, \"-\"]} \n",
    "                    gold_locations = gold_answer.split(\"/\")\n",
    "                    \n",
    "                    for k in range(1, 24):\n",
    "                        \n",
    "                        prompt = create_prompt_strict(k, context, character, grammatical_number)\n",
    "                        inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "                        inputs = inputs.to(\"cuda:0\")\n",
    "                        \n",
    "                        with torch.no_grad():\n",
    "                            outputs = model.generate(inputs)   \n",
    "                            \n",
    "                        out = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                        \n",
    "                        match = \"No\"\n",
    "                        \n",
    "                        pred_tokenized = word_tokenize(out.lower())\n",
    "                        new_pred_tokens = [token for token in pred_tokenized if token not in stop_words]\n",
    "                        pred_wo_stop_words = \" \".join(new_pred_tokens)\n",
    "                        \n",
    "                        for gold_location in gold_locations:\n",
    "                            \n",
    "                            gold_tokenized = word_tokenize(gold_location.lower())\n",
    "                            new_gold_tokens = [token for token in gold_tokenized if token not in stop_words]\n",
    "                            gold_wo_stop_words = \" \".join(new_gold_tokens)\n",
    "                            \n",
    "                            if gold_wo_stop_words == pred_wo_stop_words:\n",
    "                                match = \"Yes\"\n",
    "                            \n",
    "                        my_dic[prompt] = [out, match]\n",
    "                        m1_predictions[item][k-1].append(out)\n",
    "                        \n",
    "                    df = pd.DataFrame(data=my_dic, index=[\"output\", \"match?\"])\n",
    "                    df = (df.T)\n",
    "                    df.to_excel(writer, sheet_name=str(i+1))\n",
    "                    worksheet = writer.sheets[str(i+1)]\n",
    "                    \n",
    "                    for idx, col in enumerate(df):\n",
    "                        max_len = 75\n",
    "                        worksheet.set_column(idx, idx, max_len, format)\n",
    "                    i += 1\n",
    "                    \n",
    "                else:\n",
    "                    j += 1\n",
    "                    paragraph = paragraphs[j]\n",
    "                    paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "                    char_count += (len(paragraph) + 2)\n",
    "                    \n",
    "        writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a96a631-3821-4056-af73-1722098fbaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Method1Predictions.txt\", \"wb\") as f:\n",
    "    pickle.dump(m1_predictions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0652ce-46df-4945-a96a-cad9b86d9397",
   "metadata": {},
   "source": [
    "## Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e394b3a-0b48-479e-8a00-2e08e814922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Method1Predictions.txt\", \"rb\") as f:\n",
    "    m1_predictions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e8453b-2f49-466c-ad5f-410785266029",
   "metadata": {},
   "source": [
    "### Exact Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5cbfa12-1359-47b6-99f1-47f6cdff28e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m1_matches_exact = exact_match(m1_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "166643bc-80c6-42dd-9228-ac0cc69cbba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_accuracy_exact = {}\n",
    "\n",
    "for item in m1_matches_exact:\n",
    "    m1_accuracy_exact[item] = []\n",
    "    for prompt_version in m1_matches_exact[item]:\n",
    "        m1_accuracy_exact[item].append(np.mean(np.array(prompt_version)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8eb33d98-8764-411a-a838-b7c741cb376f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m1_prompt_accuracies_exact = [ [] for _ in range(23)]\n",
    "\n",
    "for k in range(23):\n",
    "    for item in m1_accuracy_exact:\n",
    "        m1_prompt_accuracies_exact[k].append(m1_accuracy_exact[item][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb1f5c57-8cf1-4b46-848e-4ea9e4c4e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_prompt_accuracy_exact = np.mean(np.array(m1_prompt_accuracies_exact), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b441683a-b6e5-4c7c-9fae-cb4053eb749b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35076094, 0.37265525, 0.40456159, 0.11157917, 0.10264385,\n",
       "       0.3989781 , 0.06079699, 0.08038259, 0.37405052, 0.43098295,\n",
       "       0.38670935, 0.42467556, 0.43525905, 0.33064735, 0.32372326,\n",
       "       0.30505434, 0.44866851, 0.30667549, 0.24513342, 0.38024758,\n",
       "       0.40203384, 0.35130457, 0.33826623])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_prompt_accuracy_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6e36615-0124-4fd9-83e4-211905fb97a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_prompt_accuracy_exact.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2634a11a-b9d2-4db2-a6a5-042b3cf12851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3202517604726581"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_prompt_accuracy_exact.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "24108fc8-f319-4cbe-a111-2bf4bda8319f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3075927695492913"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_prompt_accuracy_exact.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e9305c9-759a-4e65-b7c7-a6597b205704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14586817168338903"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without removing the stop words, this is the accuracy: 0.14586817168338903\n",
    "m1_prompt_accuracy_exact.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2416d1bd-aad7-4cea-97bf-0d7cc6c929b6",
   "metadata": {},
   "source": [
    "### Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b1a22e8-8142-4e77-8f88-cee4463f1fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andersen_story2.txt\n",
      "Andersen_story8.txt\n",
      "Andersen_story11.txt\n",
      "Andersen_story7.txt\n",
      "Andersen_story17.txt\n",
      "Andersen_story15.txt\n",
      "Andersen_story9.txt\n",
      "Andersen_story5.txt\n",
      "Andersen_story1.txt\n",
      "Andersen_story12.txt\n",
      "Andersen_story16.txt\n",
      "Andersen_story18.txt\n",
      "Andersen_story3.txt\n",
      "Andersen_story10.txt\n",
      "Andersen_story13.txt\n"
     ]
    }
   ],
   "source": [
    "m1_matches_fuzzy = fuzzy_match(m1_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88474c17-da18-49b2-b0f0-05cbc6ffe4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_accuracy_fuzzy = {}\n",
    "\n",
    "for item in m1_matches_fuzzy:\n",
    "    m1_accuracy_fuzzy[item] = []\n",
    "    for prompt_version in m1_matches_fuzzy[item]:\n",
    "        m1_accuracy_fuzzy[item].append(np.mean(np.array(prompt_version)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d361fb5d-97f3-4fd4-aeb3-6ce0aa723cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_prompt_accuracies_fuzzy = [ [] for _ in range(23)]\n",
    "\n",
    "for k in range(23):\n",
    "    for item in m1_accuracy_fuzzy:\n",
    "        m1_prompt_accuracies_fuzzy[k].append(m1_accuracy_fuzzy[item][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aad25bf1-943f-4db1-be1f-ec3161d262c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_prompt_accuracy_fuzzy = np.mean(np.array(m1_prompt_accuracies_fuzzy), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8159cbc8-0338-4b59-a233-6633bcb9cf03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_prompt_accuracy_fuzzy.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5066c5bd-0b58-48c5-a210-c1633250f813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44995912780274633"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_prompt_accuracy_fuzzy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "893c5199-92a1-4170-9fd2-5d4e74d05f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35411357965705786"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_prompt_accuracy_fuzzy.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a00a21-2018-4d91-bab0-0f5fe2d6c76c",
   "metadata": {},
   "source": [
    "### Previous Trials with Fuzzy Matching: Accuracy Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabaf166-23b0-430f-b185-1bc9768176c9",
   "metadata": {},
   "source": [
    "Fuzzy, Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00fa26dd-392f-4901-915a-3f54611c77cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1698394220043369"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_prompt_accuracy_70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d15e119-fd57-457d-b94a-eab7a6f35d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11329736681650657"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_prompt_accuracy_80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5588bfa-4df8-4096-b06b-e4ca53ba0b7b",
   "metadata": {},
   "source": [
    "Fuzzy, partial Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50a24feb-9e7d-40e7-bbc9-70cc7b9022e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3591770613766706"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_prompt_accuracy_70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcb90fa3-ecf8-4da7-94ae-8b2f49241a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3368717003830875"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_prompt_accuracy_80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbad78a4-aea0-420c-aaf4-20ff336abab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3037468581108252"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_prompt_accuracy_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "861f147a-914d-43a1-b3f9-1bce9af95a49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27213765"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_promt_accuracy_old = np.array([0.27450094, 0.28109715, 0.30291931, 0.28313673, 0.33539873,\n",
    "       0.30931097, 0.29294206, 0.24973622, 0.31162207, 0.34091457,\n",
    "       0.27815897, 0.3024651 , 0.28303893, 0.19987987, 0.23212544,\n",
    "       0.23353597, 0.32855765, 0.26473733, 0.21746238, 0.28135172,\n",
    "       0.25382514, 0.19567048, 0.20677822])\n",
    "m1_promt_accuracy_old.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8915fb8-19e8-434c-9f61-5bbbac673912",
   "metadata": {},
   "source": [
    "### Compare the Two Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b815425-c0b7-4572-8b71-ef8825feec7d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andersen_story2.txt\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "100\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  his own little kingdom\n",
      "100\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "100\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  his own little kingdom\n",
      "100\n",
      "GOLD:  ['a dirty little room close by the pigsty', 'his room', \"prince's room\", 'by the pigsty', 'room']\n",
      "PREDICTION:  The Prince is in the pigsty\n",
      "100\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The Emperor was in the court-yard.\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The Emperor is in the court-yard.\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The Emperor is in the court-yard.\n",
      "100\n",
      "GOLD:  ['in a large hall', 'large hall']\n",
      "PREDICTION:  The princess is in the large hall.\n",
      "100\n",
      "GOLD:  ['the door', \"the emperor's house\", 'the palace']\n",
      "PREDICTION:  The Emperor's Palace\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The Emperor is in the court-yard.\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The court-ladies are in the court-yard.\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The Emperor is in the court-yard.\n",
      "100\n",
      "GOLD:  ['behind a tree']\n",
      "PREDICTION:  Behind a tree.\n",
      "100\n",
      "GOLD:  ['in a large hall', 'large hall']\n",
      "PREDICTION:  The princess is in the large hall.\n",
      "100\n",
      "GOLD:  ['the door', \"the emperor's house\", 'the palace']\n",
      "PREDICTION:  The Emperor's Palace\n",
      "100\n",
      "GOLD:  ['a dirty little room close by the pigsty', 'his room', \"prince's room\", 'by the pigsty', 'room']\n",
      "PREDICTION:  The Prince went to the pigsty, and saw the pigs were very\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The Emperor is in the court-yard.\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The court-ladies are in the court-yard.\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The Emperor is in the court-yard.\n",
      "100\n",
      "GOLD:  ['out of the city']\n",
      "PREDICTION:  The swineherd is outside the city.\n",
      "100\n",
      "GOLD:  ['behind a tree']\n",
      "PREDICTION:  Behind a tree.\n",
      "100\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "100\n",
      "GOLD:  ['around the princess']\n",
      "PREDICTION:  around her\n",
      "100\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  The prince is in his own little kingdom\n",
      "100\n",
      "GOLD:  ['in a large hall', 'large hall']\n",
      "PREDICTION:  The princess is in the large hall.\n",
      "100\n",
      "GOLD:  ['the door', \"the emperor's house\", 'the palace']\n",
      "PREDICTION:  The Emperor's Palace\n",
      "100\n",
      "GOLD:  ['the door', \"the emperor's house\", 'the palace']\n",
      "PREDICTION:  He is at the palace.\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The Emperor is in the court-yard.\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The Emperor is in the court-yard.\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The Emperor is in the court-yard.\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The Emperor is in the court-yard.\n",
      "100\n",
      "GOLD:  ['out of the city']\n",
      "PREDICTION:  The swineherd is outside the city.\n",
      "100\n",
      "GOLD:  ['out of the city']\n",
      "PREDICTION:  The swineherd is in the city.\n",
      "100\n",
      "GOLD:  ['in a large hall', 'large hall']\n",
      "PREDICTION:  The princess is in a large hall.\n",
      "100\n",
      "GOLD:  ['the door', \"the emperor's house\", 'the palace']\n",
      "PREDICTION:  The Emperor's Palace\n",
      "100\n",
      "GOLD:  ['the door', \"the emperor's house\", 'the palace']\n",
      "PREDICTION:  He is at the palace.\n",
      "100\n",
      "GOLD:  ['a dirty little room close by the pigsty', 'his room', \"prince's room\", 'by the pigsty', 'room']\n",
      "PREDICTION:  The Prince went to the pigsty\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The Emperor is in the court-yard.\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The ladies are in the court-yard.\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The Emperor is in the court-yard.\n",
      "100\n",
      "GOLD:  ['out of the city']\n",
      "PREDICTION:  He is outside the city.\n",
      "100\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "100\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  his own little kingdom\n",
      "100\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "100\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  his own little kingdom\n",
      "100\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "100\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  He is in his own little kingdom\n",
      "100\n",
      "GOLD:  ['the door', \"the emperor's house\", 'the palace']\n",
      "PREDICTION:  The emperor is at the palace.\n",
      "100\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  In front of her\n",
      "100\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  His own little kingdom\n",
      "100\n",
      "GOLD:  ['the door', \"the emperor's house\", 'the palace']\n",
      "PREDICTION:  The prince is at the palace.\n",
      "100\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  In front of her\n",
      "100\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  His own little kingdom\n",
      "100\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  In front of her\n",
      "100\n",
      "GOLD:  ['the door', \"the emperor's house\", 'the palace']\n",
      "PREDICTION:  The prince is at the palace.\n",
      "100\n",
      "GOLD:  ['a dirty little room close by the pigsty', 'his room', \"prince's room\", 'by the pigsty', 'room']\n",
      "PREDICTION:  The Prince is in the pigsty\n",
      "100\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  In front of her\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The emperor is in the court-yard.\n",
      "100\n",
      "GOLD:  ['the door', \"the emperor's house\", 'the palace']\n",
      "PREDICTION:  The prince is at the palace.\n",
      "100\n",
      "GOLD:  ['a dirty little room close by the pigsty', 'his room', \"prince's room\", 'by the pigsty', 'room']\n",
      "PREDICTION:  The Prince\n",
      "100\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  In front of her\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The emperor is in the court-yard.\n",
      "100\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  The prince is in his own little kingdom\n",
      "100\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  In front of her\n",
      "100\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  He is in his own little kingdom\n",
      "100\n",
      "GOLD:  ['a dirty little room close by the pigsty', 'his room', \"prince's room\", 'by the pigsty', 'room']\n",
      "PREDICTION:  The Prince is in the pigsty\n",
      "100\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  In front of her\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The Emperor is in the court-yard.\n",
      "100\n",
      "GOLD:  ['a dirty little room close by the pigsty', 'his room', \"prince's room\", 'by the pigsty', 'room']\n",
      "PREDICTION:  The Prince is in the pigsty\n",
      "100\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  In front of her\n",
      "100\n",
      "GOLD:  ['the court-yard']\n",
      "PREDICTION:  The Emperor is in the court-yard.\n",
      "100\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  In front of her\n",
      "100\n",
      "GOLD:  ['out of the city']\n",
      "PREDICTION:  outside the city\n",
      "100\n",
      "GOLD:  ['out of the city']\n",
      "PREDICTION:  outside the city\n",
      "100\n",
      "GOLD:  ['a dirty little room close by the pigsty', 'his room', \"prince's room\", 'by the pigsty', 'room']\n",
      "PREDICTION:  In a dirty little room\n",
      "100\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  In front of her\n",
      "100\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  In front of her\n",
      "100\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  He is in his own little kingdom\n",
      "100\n",
      "GOLD:  ['the door', \"the emperor's house\", 'the palace']\n",
      "PREDICTION:  The Emperor's Palace\n",
      "100\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  In front of her\n",
      "100\n",
      "GOLD:  ['out of the city']\n",
      "PREDICTION:  The swineherd is in the city\n",
      "100\n",
      "Andersen_story8.txt\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  up a-top of the house\n",
      "100\n",
      "GOLD:  [\"old woman's bosom\"]\n",
      "PREDICTION:  on her bosom\n",
      "100\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  a beautiful garden\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  up a-top of the house\n",
      "100\n",
      "GOLD:  [\"old woman's bosom\"]\n",
      "PREDICTION:  on her bosom\n",
      "100\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  in the beautiful garden of their home\n",
      "100\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  a beautiful garden\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  up a-top of the house\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  He lives up a-top of the house all alone.\n",
      "100\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  The old woman is in the middle of the Elderbush.\n",
      "100\n",
      "GOLD:  ['under the elder tree', 'tree']\n",
      "PREDICTION:  She is in the tree.\n",
      "100\n",
      "GOLD:  ['under the elder tree', 'tree']\n",
      "PREDICTION:  He is in the tree.\n",
      "100\n",
      "GOLD:  ['in the tree', 'tree']\n",
      "PREDICTION:  She is in the tree.\n",
      "100\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  The little maiden is in the garden.\n",
      "100\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  He is in the garden.\n",
      "100\n",
      "GOLD:  ['the country']\n",
      "PREDICTION:  She is in the country.\n",
      "100\n",
      "GOLD:  ['the country']\n",
      "PREDICTION:  The boy is in the country.\n",
      "100\n",
      "GOLD:  ['in his bed']\n",
      "PREDICTION:  The boy is in bed.\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  He lives up a-top of the house all alone.\n",
      "100\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  The old woman is in the middle of the Elderbush.\n",
      "100\n",
      "GOLD:  ['under the elder tree', 'tree']\n",
      "PREDICTION:  She is in the tree.\n",
      "100\n",
      "GOLD:  ['under the elder tree', 'tree']\n",
      "PREDICTION:  He is in the tree.\n",
      "100\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  The little maiden is in the garden.\n",
      "100\n",
      "GOLD:  ['the country']\n",
      "PREDICTION:  She is in the country.\n",
      "100\n",
      "GOLD:  ['the country']\n",
      "PREDICTION:  The boy is in the country.\n",
      "100\n",
      "GOLD:  ['in his bed']\n",
      "PREDICTION:  The boy is in bed.\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  up a-top of the house\n",
      "100\n",
      "GOLD:  ['under the elder tree', 'tree']\n",
      "PREDICTION:  under the large blooming Elder Tree\n",
      "100\n",
      "GOLD:  [\"old woman's bosom\"]\n",
      "PREDICTION:  on his bosom\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  He lives up a-top of the house all alone.\n",
      "100\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  The old woman is in the middle of the Elderbush.\n",
      "100\n",
      "GOLD:  ['under the elder tree', 'tree']\n",
      "PREDICTION:  She is in the tree.\n",
      "100\n",
      "GOLD:  ['in the tree', 'tree']\n",
      "PREDICTION:  She is in the tree.\n",
      "100\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  She is in the garden.\n",
      "100\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  He is in the garden.\n",
      "100\n",
      "GOLD:  ['the country']\n",
      "PREDICTION:  She is in the country.\n",
      "100\n",
      "GOLD:  ['the country']\n",
      "PREDICTION:  The boy is in the country.\n",
      "100\n",
      "GOLD:  ['in the tree']\n",
      "PREDICTION:  She is in the tree.\n",
      "100\n",
      "GOLD:  ['in his bed']\n",
      "PREDICTION:  He is in bed.\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  He lives up a-top of the house all alone.\n",
      "100\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  In the middle of the Elderbush\n",
      "100\n",
      "GOLD:  ['under the elder tree', 'tree']\n",
      "PREDICTION:  She is in the tree.\n",
      "100\n",
      "GOLD:  ['in the tree', 'tree']\n",
      "PREDICTION:  She is in the tree.\n",
      "100\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  She is in the garden.\n",
      "100\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  He is in the garden.\n",
      "100\n",
      "GOLD:  ['the country']\n",
      "PREDICTION:  She is in the country.\n",
      "100\n",
      "GOLD:  ['the country']\n",
      "PREDICTION:  The boy is in the country-seat.\n",
      "100\n",
      "GOLD:  ['in his bed']\n",
      "PREDICTION:  He is in bed.\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  up a-top of the house\n",
      "100\n",
      "GOLD:  [\"old woman's bosom\"]\n",
      "PREDICTION:  on her bosom\n",
      "100\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  in the beautiful garden of their home\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  up a-top of the house\n",
      "100\n",
      "GOLD:  [\"old woman's bosom\"]\n",
      "PREDICTION:  on her bosom\n",
      "100\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  in the beautiful garden of their home\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  up a-top of the house\n",
      "100\n",
      "GOLD:  [\"old woman's bosom\"]\n",
      "PREDICTION:  on her bosom\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  up a-top of the house\n",
      "100\n",
      "GOLD:  [\"old woman's bosom\"]\n",
      "PREDICTION:  on her bosom\n",
      "100\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  in the beautiful garden of their home\n",
      "100\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  a beautiful garden\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  a-top of the house\n",
      "100\n",
      "GOLD:  [\"old woman's bosom\"]\n",
      "PREDICTION:  on her bosom\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  Up a-top of the house\n",
      "100\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  In the middle of the Elderbush\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  Up a-top of the house\n",
      "100\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  In the middle of the Elderbush\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  Up a-top of the house\n",
      "100\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  In the middle of the Elderbush\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  Up a-top of the house\n",
      "100\n",
      "GOLD:  [\"old woman's bosom\"]\n",
      "PREDICTION:  on his bosom\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  Up a-top of the house\n",
      "100\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  In the middle of the Elderbush\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  He lives up a-top of the house\n",
      "100\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  In the middle of the Elderbush\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  Up a-top of the house\n",
      "100\n",
      "GOLD:  [\"old woman's bosom\"]\n",
      "PREDICTION:  on his bosom\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  Up a-top of the house\n",
      "100\n",
      "GOLD:  [\"old woman's bosom\"]\n",
      "PREDICTION:  on his bosom\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  Up a-top of the house\n",
      "100\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  He lives up a-top of the house\n",
      "100\n",
      "GOLD:  [\"old woman's bosom\"]\n",
      "PREDICTION:  on her bosom\n",
      "100\n",
      "Andersen_story7.txt\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  A grasshopper is in the room.\n",
      "100\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The leap-frog is in the middle of the room.\n",
      "100\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  he is in the middle of the room\n",
      "100\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The leap-frog is in the middle of the room.\n",
      "100\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The grasshopper is in the middle of the room.\n",
      "100\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The leap-frog is in the middle of the room.\n",
      "100\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The leap-frog is in the middle of the room.\n",
      "100\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The leap-frog is in the middle of the room.\n",
      "100\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The leap-frog is in the middle of the room.\n",
      "100\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The leap-frog is in the middle of the room.\n",
      "100\n",
      "Andersen_story9.txt\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  a clump of willows which grew on the skirts of the forest\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  a clump of willows which grew on the skirts of the forest\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  a clump of willows which grew on the skirts of the forest\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  The King's Son was in the forest\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  The confectioner of the town is in the forest.\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  The King's Son was in the forest.\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  The confectioner of the town is in the forest.\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  The King's Son is in the forest.\n",
      "100\n",
      "GOLD:  ['upon the trees', 'trees']\n",
      "PREDICTION:  The apes are on the trees.\n",
      "100\n",
      "GOLD:  ['the summit']\n",
      "PREDICTION:  He is on the summit of the hill.\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  a clump of willows which grew on the skirts of the forest\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  He is in the forest.\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  The King's Son is in the forest.\n",
      "100\n",
      "GOLD:  ['the summit']\n",
      "PREDICTION:  He is on the summit of the hill.\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  The King's Son is in the forest.\n",
      "100\n",
      "GOLD:  ['the summit']\n",
      "PREDICTION:  He is on the summit of a hill.\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  a clump of willows which grew on the skirts of the forest\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  a clump of willows which grew on the skirts of the forest\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  a clump of willows which grew on the skirts of the forest\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  a clump of willows which grew on the skirts of the forest\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  a clump of willows which grew on the skirts of the forest\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  The confectioner of the town is in the forest.\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  a clump of willows which grew on the skirts of the forest\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  The confectioner of the town is in the forest.\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  The confectioner of the town is in the forest.\n",
      "100\n",
      "GOLD:  ['a little house']\n",
      "PREDICTION:  They are in the house\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  a clump of willows which grew on the skirts of the forest\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  a clump of willows which grew on the skirts of the forest\n",
      "100\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  a clump of willows which grew on the skirts of the forest\n",
      "100\n",
      "Andersen_story5.txt\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  rushed in as if they would upset the Tree\n",
      "100\n",
      "GOLD:  ['round the tree', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  a troop of children rushed in as if they would upset the Tree\n",
      "100\n",
      "GOLD:  ['out of the room', 'in the loft', 'in a dark corner']\n",
      "PREDICTION:  in a dark corner, where no daylight can enter\n",
      "100\n",
      "GOLD:  ['in the hole', 'in his hole']\n",
      "PREDICTION:  peeping out of his hole\n",
      "100\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  rushed in as if they would upset the Tree\n",
      "100\n",
      "GOLD:  ['in the hole', 'in his hole']\n",
      "PREDICTION:  peeping out of his hole\n",
      "100\n",
      "GOLD:  ['round the tree', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  They are dancing around the tree.\n",
      "100\n",
      "GOLD:  ['between the branches', 'round the tree', 'in the room', 'room', 'near the tree', 'by the tree', 'tree']\n",
      "PREDICTION:  The old nurse is in the tree.\n",
      "100\n",
      "GOLD:  ['under the tree', 'in the room', 'room', 'next to the fat man']\n",
      "PREDICTION:  They are under the tree.\n",
      "100\n",
      "GOLD:  ['out of the room', 'in the loft', 'in a dark corner']\n",
      "PREDICTION:  in a dark corner, where no daylight can enter\n",
      "100\n",
      "GOLD:  ['around the tree', 'around the fir tree', 'about the tree', 'about the fir tree', 'in the loft']\n",
      "PREDICTION:  The mice are in the Fir Tree.\n",
      "100\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  rushed in as if they would upset the Tree\n",
      "100\n",
      "GOLD:  ['round the tree', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  They are dancing round the tree.\n",
      "100\n",
      "GOLD:  ['between the branches', 'round the tree', 'in the room', 'room', 'near the tree', 'by the tree', 'tree']\n",
      "PREDICTION:  The old nurse is in the tree.\n",
      "100\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree', 'tree']\n",
      "PREDICTION:  Under the tree.\n",
      "100\n",
      "GOLD:  ['under the tree', 'in the room', 'room']\n",
      "PREDICTION:  Under the tree.\n",
      "100\n",
      "GOLD:  ['under the tree', 'in the room', 'room', 'next to the fat man']\n",
      "PREDICTION:  They are under the tree.\n",
      "100\n",
      "GOLD:  ['out of the room', 'in the loft', 'in a dark corner']\n",
      "PREDICTION:  in a dark corner, where no daylight can enter\n",
      "100\n",
      "GOLD:  ['around the tree', 'around the fir tree', 'about the tree', 'about the fir tree', 'in the loft']\n",
      "PREDICTION:  They are in the Fir Tree.\n",
      "100\n",
      "GOLD:  ['in the hole', 'in his hole']\n",
      "PREDICTION:  peeping out of his hole\n",
      "100\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  They are in the room.\n",
      "100\n",
      "GOLD:  ['behind the children', 'following the children', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  The older persons are in the room.\n",
      "100\n",
      "GOLD:  ['round the tree', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  They are dancing around the tree.\n",
      "100\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree', 'tree']\n",
      "PREDICTION:  He is under the tree.\n",
      "100\n",
      "GOLD:  ['under the tree', 'in the room', 'room']\n",
      "PREDICTION:  He is under the tree.\n",
      "100\n",
      "GOLD:  ['under the tree', 'in the room', 'room', 'next to the fat man']\n",
      "PREDICTION:  They are under the tree.\n",
      "100\n",
      "GOLD:  ['around the tree', 'around the fir tree', 'about the tree', 'about the fir tree', 'in the loft']\n",
      "PREDICTION:  They are in the Fir Tree.\n",
      "100\n",
      "GOLD:  ['in the court-yard', 'out in the courtyard', 'in the courtyard', 'in the yard', 'out', 'outside', 'about the tree', 'about the fir tree', 'near the tree', 'near the fir tree']\n",
      "PREDICTION:  In the court-yard some of the merry children were playing who had danced at\n",
      "100\n",
      "GOLD:  ['round the tree', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  They are dancing around the tree.\n",
      "100\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree', 'tree']\n",
      "PREDICTION:  The fat man is under the tree.\n",
      "100\n",
      "GOLD:  ['under the tree', 'in the room', 'room']\n",
      "PREDICTION:  The fat man is under the tree.\n",
      "100\n",
      "GOLD:  ['under the tree', 'in the room', 'room', 'next to the fat man']\n",
      "PREDICTION:  They are under the tree.\n",
      "100\n",
      "GOLD:  ['round the tree', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  rushed in as if they would upset the Tree\n",
      "100\n",
      "GOLD:  ['between the branches', 'round the tree', 'in the room', 'room', 'near the tree', 'by the tree', 'tree']\n",
      "PREDICTION:  peeped between the branches\n",
      "100\n",
      "GOLD:  ['in the hole', 'in his hole']\n",
      "PREDICTION:  peeping out of his hole\n",
      "100\n",
      "GOLD:  ['between the branches', 'round the tree', 'in the room', 'room', 'near the tree', 'by the tree', 'tree']\n",
      "PREDICTION:  peeped between the branches\n",
      "100\n",
      "GOLD:  ['in the hole', 'in his hole']\n",
      "PREDICTION:  peeping out of his hole\n",
      "100\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  rushed in as if they would upset the Tree\n",
      "100\n",
      "GOLD:  ['round the tree', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  a troop of children rushed in as if they would upset the Tree\n",
      "100\n",
      "GOLD:  ['out of the room', 'in the loft', 'in a dark corner']\n",
      "PREDICTION:  in a dark corner, where no daylight can enter\n",
      "100\n",
      "GOLD:  ['in the hole', 'in his hole']\n",
      "PREDICTION:  peeping out of his hole\n",
      "100\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  rushed in as if they would upset the Tree\n",
      "100\n",
      "GOLD:  ['round the tree', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  a troop of children rushed in as if they would upset the Tree\n",
      "100\n",
      "GOLD:  ['in the hole', 'in his hole']\n",
      "PREDICTION:  peeping out of his hole\n",
      "100\n",
      "GOLD:  ['behind the children', 'following the children', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  The older persons are outside the room.\n",
      "100\n",
      "GOLD:  ['under the tree', 'in the room', 'room', 'next to the fat man']\n",
      "PREDICTION:  They are under a tree.\n",
      "100\n",
      "GOLD:  ['behind the children', 'following the children', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  The older persons are in the room with the tree\n",
      "100\n",
      "GOLD:  ['in the hole', 'in his hole']\n",
      "PREDICTION:  peeping out of his hole\n",
      "100\n",
      "GOLD:  ['between the branches', 'round the tree', 'in the room', 'room', 'near the tree', 'by the tree', 'tree']\n",
      "PREDICTION:  The old nurse is in the tree.\n",
      "100\n",
      "Andersen_story1.txt\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "100\n",
      "GOLD:  ['the court']\n",
      "PREDICTION:  The weavers are in the court.\n",
      "100\n",
      "GOLD:  ['the hall']\n",
      "PREDICTION:  He is in the hall.\n",
      "100\n",
      "GOLD:  ['the court']\n",
      "PREDICTION:  The weavers are in the court.\n",
      "100\n",
      "GOLD:  ['the hall']\n",
      "PREDICTION:  He is in the hall.\n",
      "100\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  on the street\n",
      "100\n",
      "GOLD:  ['the hall']\n",
      "PREDICTION:  He is in the hall.\n",
      "100\n",
      "GOLD:  ['the hall']\n",
      "PREDICTION:  He is in the hall.\n",
      "100\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  on the street\n",
      "100\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  on the street\n",
      "100\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "100\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "100\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "100\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "100\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "100\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "100\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "100\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "100\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  In the street\n",
      "100\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  on the street\n",
      "100\n",
      "Andersen_story3.txt\n",
      "GOLD:  ['the bedroom']\n",
      "PREDICTION:  The old Queen-mother is in the bedroom.\n",
      "100\n",
      "GOLD:  ['the bedroom']\n",
      "PREDICTION:  The old Queen-mother is in the bedroom.\n",
      "100\n",
      "GOLD:  ['the bedroom']\n",
      "PREDICTION:  The old Queen-mother is in the bedroom.\n",
      "100\n",
      "Andersen_story10.txt\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  in a house\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is at the old house.\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is in the old house.\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The little boy is in the room with the projecting windows.\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The old man is in the room with the projecting windows.\n",
      "100\n",
      "GOLD:  ['the other room', 'room']\n",
      "PREDICTION:  He is in the other room.\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  The little boy is at the old house.\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is in the old house.\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home.\n",
      "100\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  He is in the garden.\n",
      "100\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  She is in the garden.\n",
      "100\n",
      "GOLD:  ['the doorway']\n",
      "PREDICTION:  The little boy was in the doorway.\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is at the old house.\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  The old man is in the old house.\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The little boy is in the room with the projecting windows.\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  He is in the room with the projecting windows.\n",
      "100\n",
      "GOLD:  ['the other room', 'room']\n",
      "PREDICTION:  He is in the other room.\n",
      "100\n",
      "GOLD:  ['on the drawers', 'drawers']\n",
      "PREDICTION:  On the drawers.\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  The little boy is at the old house.\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is in the old house.\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home.\n",
      "100\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  He is in the garden.\n",
      "100\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  She is in the garden.\n",
      "100\n",
      "GOLD:  ['the doorway']\n",
      "PREDICTION:  The little boy is in the doorway\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  the old man's room\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  in a house\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is at the old house.\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is in the old house.\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The little boy is in the room with the projecting windows.\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  He is in the room with the projecting windows.\n",
      "100\n",
      "GOLD:  ['the other room', 'room']\n",
      "PREDICTION:  He is in the other room.\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is at the old house.\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  He is at home.\n",
      "100\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  He is in the house where the garden is.\n",
      "100\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  She is in the garden.\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is at the old house.\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is in the old house.\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The little boy is in the room with the old man.\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  He is in the room with the projecting windows.\n",
      "100\n",
      "GOLD:  ['the other room', 'room']\n",
      "PREDICTION:  He is in the other room.\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is at the old house.\n",
      "100\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  He is in the house where the garden is.\n",
      "100\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  She is in the garden.\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  in a house\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  in a house\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  the old man's room\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  in a house\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The little boy is in the room with the old man\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is in a house\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The little boy is in the room with the old man\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is in a house\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The little boy is in the room with the old man\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  He is in the room with the projecting windows.\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  The little boy is at the old house\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The little boy is in the room with the old man\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The old man is in the room with the projecting windows.\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home.\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home.\n",
      "100\n",
      "GOLD:  [\"outside the boy's house\", \"the boy's house\"]\n",
      "PREDICTION:  The little boy's house\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The little boy is in the room with the old man\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  He is in the room with the projecting windows.\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home.\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home.\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The little boy is in the room with the old man\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  He is in the room with the projecting windows.\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is in a house\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home.\n",
      "100\n",
      "GOLD:  [\"outside the boy's house\", \"the boy's house\"]\n",
      "PREDICTION:  The little boy's house\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  The old man is in the old house\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The little boy is in the room with the old man\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  He is in the room with the projecting windows.\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  The old man is in the old house\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The little boy is in the room with the old man\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  He is in the room with the projecting windows.\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The little boy is in the room with the old man\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  He is in the room with the projecting windows.\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The little boy is in the room with the old man\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  He is in the room with the projecting windows.\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  In a house\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  In the room with the old man\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home.\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home.\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  The old man is in the old house\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The little boy is in the room with the old man\n",
      "100\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  He is in the room with the windows\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home\n",
      "100\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is in a house\n",
      "100\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "for item in m1_predictions:\n",
    "    \n",
    "    print(item)    \n",
    "    \n",
    "    f = open(os.path.join(path_annotations, item), 'r')\n",
    "    annotations = pd.read_csv(f, sep=\"\\t\")\n",
    "    annotations = annotations.values #numpy array\n",
    "    f.close()\n",
    "    \n",
    "    for k in range(1,24):\n",
    "        \n",
    "        pred_locs = m1_predictions[item][k-1]\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        for line in annotations:\n",
    "            \n",
    "            gold_locations = line[2].split(\"/\")\n",
    "            \n",
    "            pred_tokenized = word_tokenize(pred_locs[i].lower())\n",
    "            new_pred_tokens = [ token for token in pred_tokenized if token not in stop_words]\n",
    "            pred_wo_stop_words = \" \".join(new_pred_tokens)\n",
    "            \n",
    "            match1 = False\n",
    "            match2 = False\n",
    " \n",
    "            for gold_location in gold_locations:                \n",
    "                \n",
    "                gold_tokenized = word_tokenize(gold_location.lower())\n",
    "                new_gold_tokens = [ token for token in gold_tokenized if token not in stop_words]\n",
    "                gold_wo_stop_words = \" \".join(new_gold_tokens)\n",
    "                \n",
    "                if gold_wo_stop_words == pred_wo_stop_words:\n",
    "                    match1 = True\n",
    "                \n",
    "                if fuzz.partial_ratio(gold_wo_stop_words, pred_wo_stop_words) > 90:\n",
    "                    ratio = fuzz.partial_ratio(gold_wo_stop_words, pred_wo_stop_words)\n",
    "                    match2 = True\n",
    "                \n",
    "            if match2 and not match1:\n",
    "                print(\"GOLD: \", gold_locations)\n",
    "                print(\"PREDICTION: \", pred_locs[i])\n",
    "                print(ratio)\n",
    "            \n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2644e290-9541-409c-8e91-71c99de3a474",
   "metadata": {},
   "source": [
    "### Save the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2fd513f-cfee-407f-8f87-6979ade1db4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(\"method1_accuracy.xlsx\", engine='xlsxwriter')\n",
    "df = pd.DataFrame(data = method1_accuracy)\n",
    "df.to_excel(writer, sheet_name=\"Accuracies\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5393de6-7c20-4fba-a00e-41a63c8ab879",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(\"method1_accuracy_prompt.xlsx\", engine='xlsxwriter')\n",
    "df = pd.DataFrame(data = m1_prompt_accuracy)\n",
    "df.to_excel(writer, sheet_name=\"Accuracies\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ba2bd79-ad89-4efe-8d9d-148ef9e2477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro = \"This is the intro.\"\n",
    "context  = \" : This is the context.\"\n",
    "question = \"This is the question.\"\n",
    "\n",
    "tm = Template(\"\"\"{{ intro }}\n",
    "Context: {{context}};\n",
    "Question: {{question}};\n",
    "If you can't find the answer, please respond \"unanswerable\".\n",
    "Answer: \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad27c68-450e-4522-9fff-b5280ea66b81",
   "metadata": {},
   "source": [
    "# Method 2: Start of the Paragraph --> Where the Location is Mentioned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe7ce8-3381-4726-82f0-046bd52fd242",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f39169d6-3ae4-48e1-9d7f-7e52c398f572",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m2_predictions = {}\n",
    "\n",
    "for item in dir_list_andersen:\n",
    "#for item in [\"Andersen_story1.txt\"]: \n",
    "    \n",
    "    if item in dir_list_annotations:\n",
    "        \n",
    "        f = open(os.path.join(path_andersen, item), 'r') \n",
    "        story = f.read()\n",
    "        f.close()\n",
    "\n",
    "        paragraphs = story.split(\"\\n\\n\")\n",
    "        \n",
    "        out_path = \"Method2_\" + item[:-3] + \"xlsx\"\n",
    "        writer = pd.ExcelWriter(out_path, engine='xlsxwriter')\n",
    "        workbook = writer.book\n",
    "        format = workbook.add_format({'text_wrap': True})\n",
    "        \n",
    "        m2_predictions[item] = [ [] for _ in range(1,24)]\n",
    "        \n",
    "        f = open(os.path.join(path_annotations, item), 'r')\n",
    "        annotations = pd.read_csv(f, sep=\"\\t\")\n",
    "        annotations = annotations.values\n",
    "        f.close()\n",
    "        \n",
    "        no_paragraphs = len(paragraphs)\n",
    "        \n",
    "        i = 0 # line number in the annotation file\n",
    "        j = 1 # paragraph number\n",
    "        \n",
    "        paragraph = paragraphs[1]\n",
    "        paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "        char_count = len(paragraphs[0]) + 2 + len(paragraph) + 2\n",
    "        \n",
    "        while i < len(annotations) and j < no_paragraphs:\n",
    "            \n",
    "            if annotations[i][2] == \"0\":\n",
    "                i += 1\n",
    "                continue\n",
    "            else:     \n",
    "                if char_count + 2 >= annotations[i][0]:\n",
    "                    \n",
    "                    character = annotations[i][1]\n",
    "                    gold_answer = annotations[i][2]\n",
    "                    grammatical_number = annotations[i][3]         \n",
    "                    context = paragraph[:annotations[i][0] - (char_count - (len(paragraph) + 2) )]\n",
    "                    context = context.rstrip(\", ;-\\n\")\n",
    "                    my_dic = {context: [gold_answer, \"-\", \"-\"]} \n",
    "                    gold_locations = gold_answer.split(\"/\")\n",
    "                    \n",
    "                    for k in range(1, 24):\n",
    "                        \n",
    "                        prompt = create_prompt_strict(k, context, character, grammatical_number)\n",
    "                            \n",
    "                        inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "                        inputs = inputs.to(\"cuda:0\")\n",
    "                        \n",
    "                        with torch.no_grad():\n",
    "                            outputs = model.generate(inputs)   \n",
    "                            \n",
    "                        out = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                        \n",
    "                        match1 = \"No\"\n",
    "                        match2 = \"No\"\n",
    "                        \n",
    "                        pred_tokenized = word_tokenize(out.lower())\n",
    "                        new_pred_tokens = [token for token in pred_tokenized if token not in stop_words]\n",
    "                        pred_wo_stop_words = \" \".join(new_pred_tokens)\n",
    "                        \n",
    "                        for gold_location in gold_locations:\n",
    "                            \n",
    "                            gold_tokenized = word_tokenize(gold_location.lower())\n",
    "                            new_gold_tokens = [token for token in gold_tokenized if token not in stop_words]\n",
    "                            gold_wo_stop_words = \" \".join(new_gold_tokens)\n",
    "                            \n",
    "                            if gold_wo_stop_words == pred_wo_stop_words:\n",
    "                                match1 = \"Yes\"\n",
    "                                \n",
    "                            if fuzz.partial_ratio(gold_wo_stop_words, pred_wo_stop_words) > 90:\n",
    "                                match2 = \"Yes\"\n",
    "                            \n",
    "                        my_dic[prompt] = [out, match1, match2]\n",
    "                        m2_predictions[item][k-1].append(out)\n",
    "                        \n",
    "                    df = pd.DataFrame(data=my_dic, index=[\"output\", \"exact match?\", \"fuzzy match?\"])\n",
    "                    df = (df.T)\n",
    "                    df.to_excel(writer, sheet_name=str(i+1))\n",
    "                    worksheet = writer.sheets[str(i+1)]\n",
    "                    \n",
    "                    for idx, col in enumerate(df):\n",
    "                        max_len = 75\n",
    "                        worksheet.set_column(idx, idx, max_len, format)\n",
    "                    i += 1\n",
    "                    \n",
    "                else:\n",
    "                    j += 1\n",
    "                    paragraph = paragraphs[j]\n",
    "                    paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "                    char_count += (len(paragraph) + 2)\n",
    "                    \n",
    "        writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1622527-7254-408c-90c6-3d56e6b7dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Method2Predictions.txt\", \"wb\") as f:\n",
    "    pickle.dump(m2_predictions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee345e6-7459-4f72-a666-8beb500fb0a2",
   "metadata": {},
   "source": [
    "## Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec6c071a-a67b-4fa2-add6-1ed7e09eb8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Method2Predictions.txt\", \"rb\") as f:\n",
    "    m2_predictions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256c11b7-5620-447b-a3fc-d48bffd950da",
   "metadata": {},
   "source": [
    "### Exact Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4278ff8e-9ea7-42cf-8469-d99404aef923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m2_matches_exact = exact_match(m2_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6697054f-a1a3-4139-ba86-ffdc5c031b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_accuracy_exact = {}\n",
    "\n",
    "for item in m2_matches_exact:\n",
    "    m2_accuracy_exact[item] = []\n",
    "    for prompt_version in m2_matches_exact[item]:\n",
    "        m2_accuracy_exact[item].append(np.mean(np.array(prompt_version)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40a4ccc5-390f-4f67-807a-36d9e93d1baa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m2_prompt_accuracies_exact = [ [] for _ in range(23)]\n",
    "\n",
    "for k in range(23):\n",
    "    for item in m2_accuracy_exact:\n",
    "        m2_prompt_accuracies_exact[k].append(m2_accuracy_exact[item][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c303b499-2a3f-4b26-b5ce-5a29cd87c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_prompt_accuracy_exact = np.mean(np.array(m2_prompt_accuracies_exact), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c731513a-25f3-468a-a022-a024e009eeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_exact.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f952acaa-cdee-4a3b-9df5-208aff4dacbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34719794140200866"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_exact.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c554785-e6a3-4157-9dc8-dfbd6dbadc61",
   "metadata": {},
   "source": [
    "### Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41092351-4ebc-4aee-9ed2-1b7f01ee27ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andersen_story2.txt\n",
      "Andersen_story8.txt\n",
      "Andersen_story11.txt\n",
      "Andersen_story7.txt\n",
      "Andersen_story17.txt\n",
      "Andersen_story15.txt\n",
      "Andersen_story9.txt\n",
      "Andersen_story5.txt\n",
      "Andersen_story1.txt\n",
      "Andersen_story12.txt\n",
      "Andersen_story16.txt\n",
      "Andersen_story18.txt\n",
      "Andersen_story3.txt\n",
      "Andersen_story10.txt\n",
      "Andersen_story13.txt\n"
     ]
    }
   ],
   "source": [
    "m2_matches_fuzzy = fuzzy_match(m2_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db41db09-ec65-4c2e-9575-fbc55350aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_accuracy_fuzzy = {}\n",
    "\n",
    "for item in m2_matches_fuzzy:\n",
    "    m2_accuracy_fuzzy[item] = []\n",
    "    for prompt_version in m2_matches_fuzzy[item]:\n",
    "        m2_accuracy_fuzzy[item].append(np.mean(np.array(prompt_version)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53e421cc-3dea-4260-bc95-aa4d41f356a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_prompt_accuracies_fuzzy = [ [] for _ in range(23)]\n",
    "\n",
    "for k in range(23):\n",
    "    for item in m2_accuracy_fuzzy:\n",
    "        m2_prompt_accuracies_fuzzy[k].append(m2_accuracy_fuzzy[item][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ead1854-7305-4275-b232-6d1428380f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_prompt_accuracy_fuzzy = np.mean(np.array(m2_prompt_accuracies_fuzzy), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d4dfb61-d7d4-4c2b-8763-8e75eca793ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_fuzzy.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fa26bcd7-06dd-4d30-aede-6f5d5bbb2809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5003249652793833"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_fuzzy.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaece33-071f-4e87-a2ce-2b09489097a2",
   "metadata": {},
   "source": [
    "# Method 3: 1024 tokens backwards --> End of the paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1111aa61-1ea0-402c-8a9c-9e6167296440",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c7943c9-31bf-494d-aeb1-351855b48d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# prompt has the max number of tokens: 1024, and we start at a \" \" char.\n",
    "m3_predictions = {}\n",
    "\n",
    "for item in dir_list_andersen:\n",
    "    \n",
    "    if item in dir_list_annotations:\n",
    "        \n",
    "        f = open(os.path.join(path_andersen, item), 'r') \n",
    "        story = f.read()\n",
    "        f.close()\n",
    "        \n",
    "        paragraphs = story.split(\"\\n\\n\")\n",
    "        \n",
    "        out_path = \"Method3_\" + item[:-3] + \"xlsx\"\n",
    "        writer = pd.ExcelWriter(out_path, engine='xlsxwriter')\n",
    "        workbook = writer.book\n",
    "        format = workbook.add_format({'text_wrap': True})\n",
    "        \n",
    "        m3_predictions[item] = [ [] for _ in range(1,24)]\n",
    "        \n",
    "        f = open(os.path.join(path_annotations, item), 'r')\n",
    "        annotations = pd.read_csv(f, sep=\"\\t\")\n",
    "        annotations = annotations.values\n",
    "        f.close()\n",
    "        \n",
    "        no_paragraphs = len(paragraphs)\n",
    "        \n",
    "        i = 0 # line number in the annotation file\n",
    "        j = 0 # paragraph number\n",
    "        \n",
    "        paragraph = paragraphs[0]\n",
    "        paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "        len_title = len(paragraph) + 2\n",
    "        char_count = len_title        \n",
    "    \n",
    "        while i < len(annotations) and j < no_paragraphs:\n",
    "            \n",
    "            if char_count + 2 >= annotations[i][0]:\n",
    "                \n",
    "                line = annotations[i]\n",
    "\n",
    "                character = line[1]\n",
    "                gold_answer = line[2]\n",
    "                grammatical_number = line[3]\n",
    "                context = paragraph\n",
    "                context = context.rstrip(\", ;-\\n\")\n",
    "\n",
    "                gold_locations = gold_answer.split(\"/\")\n",
    "                my_dic = {\"Prompts\": [gold_answer, \"-\", \"-\"]}\n",
    "\n",
    "                for k in range(1, 24):\n",
    "\n",
    "                    y = char_count\n",
    "                    x = y - 5120\n",
    "\n",
    "                    if x < len_title:\n",
    "                        text = story[len_title:y]\n",
    "\n",
    "                    else:\n",
    "                        x = story[x:y].find(\" \") + x\n",
    "                        text = story[x:y]\n",
    "\n",
    "                    text = text.rstrip(\", ;-\\n\")           \n",
    "                    prompt = create_prompt_clipped(k, text, character, grammatical_number, 1024)\n",
    "                    \n",
    "                    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "                    inputs = inputs.to(\"cuda:0\")\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model.generate(inputs)\n",
    "\n",
    "                    out = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "                    match1 = \"No\"\n",
    "                    match2 = \"No\"\n",
    "\n",
    "                    pred_tokenized = word_tokenize(out.lower())\n",
    "                    new_pred_tokens = [ token for token in pred_tokenized if token not in stop_words ]\n",
    "                    pred_wo_stop_words = \" \".join(new_pred_tokens) \n",
    "\n",
    "                    for gold_location in gold_locations:\n",
    "\n",
    "                        gold_tokenized = word_tokenize(gold_location.lower())\n",
    "                        new_gold_tokens = [ token for token in gold_tokenized if token not in stop_words ]\n",
    "                        gold_wo_stop_words = \" \".join(new_gold_tokens)\n",
    "\n",
    "                        if gold_wo_stop_words == pred_wo_stop_words:\n",
    "                            match1 = \"Yes\"\n",
    "\n",
    "                        if fuzz.partial_ratio(gold_wo_stop_words, pred_wo_stop_words) > 90:\n",
    "                            match2 = \"Yes\"\n",
    "\n",
    "                    my_dic[prompt] = [out, match1, match2]\n",
    "                    m3_predictions[item][k-1].append(out)\n",
    "\n",
    "                df = pd.DataFrame(data=my_dic, index=[\"output\", \"exact match?\", \"fuzzy match?\"])\n",
    "                df = (df.T)\n",
    "                df.to_excel(writer, sheet_name=str(i+1))\n",
    "                worksheet = writer.sheets[str(i+1)]\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                for idx, col in enumerate(df):\n",
    "                    max_len = 75\n",
    "                    worksheet.set_column(idx, idx, max_len, format)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                j += 1\n",
    "                paragraph = paragraphs[j]\n",
    "                paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "                char_count += (len(paragraph) + 2)\n",
    "        \n",
    "        writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef167cc1-1f69-45ad-ba1e-47ab2bed36bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Method3Predictions.txt\", \"wb\") as f:\n",
    "    pickle.dump(m3_predictions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47afb8f4-33ce-4562-bd0a-5a3e2ba4ae1c",
   "metadata": {},
   "source": [
    "## Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55ba2ba7-f61a-4057-be7d-d9096b095fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Method3Predictions.txt\", \"rb\") as f:\n",
    "    m3_predictions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55c84da-4586-44f0-9e5d-c107d67fd554",
   "metadata": {},
   "source": [
    "### Exact Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fbeee6fa-6109-4128-92f5-430649b16fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m3_matches_exact = exact_match(m3_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b13c1a5-4a38-405b-83e5-f36b3a36774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_accuracy_exact = {}\n",
    "\n",
    "for item in m3_matches_exact:\n",
    "    m3_accuracy_exact[item] = []\n",
    "    for prompt_version in m3_matches_exact[item]:\n",
    "        m3_accuracy_exact[item].append(np.mean(np.array(prompt_version)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f026df6-84dd-4c97-9a3a-3a5073ddf96f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m3_prompt_accuracies_exact = [ [] for _ in range(23)]\n",
    "\n",
    "for k in range(23):\n",
    "    for item in m3_accuracy_exact:\n",
    "        m3_prompt_accuracies_exact[k].append(m3_accuracy_exact[item][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ac60b46-ef0d-46c3-87d6-51162485adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_prompt_accuracy_exact = np.mean(np.array(m3_prompt_accuracies_exact), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4c677f1d-f728-47e3-9d49-2fdfc038e0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3_prompt_accuracy_exact.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9e887888-d083-4d84-aa96-8d9774a15bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33080947233121144"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3_prompt_accuracy_exact.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba087b3-21e2-4dcc-91db-09f40c04d4aa",
   "metadata": {},
   "source": [
    "### Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2fb27fda-b67e-43c4-ab08-9e9e6304b307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andersen_story2.txt\n",
      "Andersen_story8.txt\n",
      "Andersen_story11.txt\n",
      "Andersen_story7.txt\n",
      "Andersen_story17.txt\n",
      "Andersen_story15.txt\n",
      "Andersen_story9.txt\n",
      "Andersen_story5.txt\n",
      "Andersen_story1.txt\n",
      "Andersen_story12.txt\n",
      "Andersen_story16.txt\n",
      "Andersen_story18.txt\n",
      "Andersen_story3.txt\n",
      "Andersen_story10.txt\n",
      "Andersen_story13.txt\n"
     ]
    }
   ],
   "source": [
    "m3_matches_fuzzy = fuzzy_match(m3_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dd296396-c877-4672-ab1f-82fab1680d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_accuracy_fuzzy = {}\n",
    "\n",
    "for item in m3_matches_fuzzy:\n",
    "    m3_accuracy_fuzzy[item] = []\n",
    "    for prompt_version in m3_matches_fuzzy[item]:\n",
    "        m3_accuracy_fuzzy[item].append(np.mean(np.array(prompt_version)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "22b45d78-fb30-4fd8-b646-59f7d305e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_prompt_accuracies_fuzzy = [ [] for _ in range(23)]\n",
    "\n",
    "for k in range(23):\n",
    "    for item in m3_accuracy_fuzzy:\n",
    "        m3_prompt_accuracies_fuzzy[k].append(m3_accuracy_fuzzy[item][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c3ab52d5-c849-4c85-8bbe-cbf7e154554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_prompt_accuracy_fuzzy = np.mean(np.array(m3_prompt_accuracies_fuzzy), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2dfbbcab-c023-4edf-a80e-bf2ae13ee93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3_prompt_accuracy_fuzzy.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "479cda22-73b2-4ecf-8fa1-01267c496dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4770774821511148"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3_prompt_accuracy_fuzzy.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d913305a-0030-45f6-9a3d-46db83e3e1f5",
   "metadata": {},
   "source": [
    "# Method 4: 1024 tokens backward --> Where the location is mentioned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c3f76c-384a-49b5-bfa5-a87ee282fcac",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7844bb6c-7939-4a29-b15f-40e8986d9458",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andersen_story2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# prompt has the max number of tokens: 1024, and we start at a \" \" char.\n",
    "\n",
    "m4_predictions = {}\n",
    "\n",
    "for item in dir_list_andersen:\n",
    "    \n",
    "    if item in dir_list_annotations:\n",
    "        \n",
    "        print(item)\n",
    "        \n",
    "        f = open(os.path.join(path_andersen, item), 'r') \n",
    "        story = f.read()\n",
    "        f.close()\n",
    "        \n",
    "        out_path = \"Method4_\" + item[:-3] + \"xlsx\"\n",
    "        writer = pd.ExcelWriter(out_path, engine='xlsxwriter')\n",
    "        workbook = writer.book\n",
    "        format = workbook.add_format({'text_wrap': True})\n",
    "        \n",
    "        m4_predictions[item] = [ [] for _ in range(1,24)]\n",
    "        \n",
    "        f = open(os.path.join(path_annotations, item), 'r')\n",
    "        annotations = pd.read_csv(f, sep=\"\\t\")\n",
    "        annotations = annotations.values\n",
    "        f.close()\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        paragraphs = story.split(\"\\n\\n\")\n",
    "        paragraph = paragraphs[0]\n",
    "        len_title = len(paragraph) + 2        \n",
    "    \n",
    "        for line in annotations:\n",
    "            \n",
    "            character = line[1]\n",
    "            gold_answer = line[2]\n",
    "            grammatical_number = line[3]\n",
    "\n",
    "            gold_locations = gold_answer.split(\"/\")\n",
    "            my_dic = {\"Prompts\": [gold_answer, \"-\", \"-\"]}\n",
    "            \n",
    "            for k in range(1, 24):\n",
    "                \n",
    "                y = line[0]\n",
    "                x = y - 5120\n",
    "\n",
    "                if x < len_title:\n",
    "                    text = story[len_title:y]\n",
    "\n",
    "                else:\n",
    "                    x = story[x:y].find(\" \") + x\n",
    "                    text = story[x:y]                \n",
    "                \n",
    "                text = text.rstrip(\", ;-\\n\")\n",
    "                if text[-1] != \".\":\n",
    "                    text += \".\"\n",
    "                    \n",
    "                text += \"John was in the kitchen.\"\n",
    "                \n",
    "                prompt, context2 = create_prompt_clipped(k, text, character, grammatical_number, 1024)\n",
    "                inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "                \n",
    "                inputs = inputs.to(\"cuda:0\")\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = model.generate(inputs)\n",
    "                    \n",
    "                out = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                \n",
    "                match1 = \"No\"\n",
    "                match2 = \"No\"\n",
    "                \n",
    "                pred_tokenized = word_tokenize(out.lower())\n",
    "                new_pred_tokens = [ token for token in pred_tokenized if token not in stop_words ]\n",
    "                pred_wo_stop_words = \" \".join(new_pred_tokens) \n",
    "                \n",
    "                for gold_location in gold_locations:\n",
    "                    \n",
    "                    gold_tokenized = word_tokenize(gold_location.lower())\n",
    "                    new_gold_tokens = [ token for token in gold_tokenized if token not in stop_words ]\n",
    "                    gold_wo_stop_words = \" \".join(new_gold_tokens)\n",
    "                    \n",
    "                    if gold_wo_stop_words == pred_wo_stop_words:\n",
    "                        match1 = \"Yes\"\n",
    "                        \n",
    "                    if fuzz.partial_ratio(gold_wo_stop_words, pred_wo_stop_words) > 90:\n",
    "                        match2 = \"Yes\"\n",
    "                        \n",
    "                my_dic[prompt] = [out, match1, match2]\n",
    "                m4_predictions[item][k-1].append(out)  \n",
    "                \n",
    "            df = pd.DataFrame(data=my_dic, index=[\"output\", \"exact match?\", \"fuzzy match?\"])\n",
    "            df = (df.T)\n",
    "            df.to_excel(writer, sheet_name=str(i+1))\n",
    "            worksheet = writer.sheets[str(i+1)]\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "            for idx, col in enumerate(df):\n",
    "                max_len = 75\n",
    "                worksheet.set_column(idx, idx, max_len, format)\n",
    "        \n",
    "        writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5707c8-dd7d-412c-b151-f7465d0d2454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"Method4Predictions_distraction.txt\", \"wb\") as f:\n",
    "    pickle.dump(m4_predictions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb9535-c6ce-4fbe-8bf2-4fd68bf5ca77",
   "metadata": {},
   "source": [
    "## Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2709c790-01e1-47a4-80fc-bfbff2d3cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Method4Predictions_distraction.txt\", \"rb\") as f:\n",
    "    m4_predictions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737a5c59-17d0-45b0-a81f-66b50f24968f",
   "metadata": {},
   "source": [
    "### Exact Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4433f30-5075-41fc-a097-53545cb2ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_matches_exact = exact_match(m4_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "299f49b9-0106-491c-85de-5271d0dfb81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_accuracy_exact = {}\n",
    "\n",
    "for item in m4_matches_exact:\n",
    "    m4_accuracy_exact[item] = []\n",
    "    for prompt_version in m4_matches_exact[item]:\n",
    "        m4_accuracy_exact[item].append(np.mean(np.array(prompt_version)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "532f58b9-9a8e-41e6-a691-3bd6f5e3c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_prompt_accuracies_exact = [ [] for _ in range(23)]\n",
    "\n",
    "for k in range(23):\n",
    "    for item in m4_accuracy_exact:\n",
    "        m4_prompt_accuracies_exact[k].append(m4_accuracy_exact[item][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82c6c39b-c76e-4615-ac8e-553478298379",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_prompt_accuracy_exact = np.mean(np.array(m4_prompt_accuracies_exact), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f97f4042-f319-48a9-aa60-f3f4091229a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4_prompt_accuracy_exact.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bf09924-0a58-43a2-87d9-560bea48f78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4588121496186012"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4_prompt_accuracy_exact[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbc4a210-0ef5-4915-9f12-2d01c33a2d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.333451937911966"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4_prompt_accuracy_exact.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "179fa7a8-6850-4a12-aae7-86864f3b1947",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm2_prompt_accuracy_exact' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e23af365b255>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# without removing the stop words, this is the accuracy: 0.14213797977384932\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm2_prompt_accuracy_exact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'm2_prompt_accuracy_exact' is not defined"
     ]
    }
   ],
   "source": [
    "# without removing the stop words, this is the accuracy: 0.14213797977384932\n",
    "m2_prompt_accuracy_exact.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76ca2d6-2496-4621-8910-f6876ea9a4a2",
   "metadata": {},
   "source": [
    "### Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90345eca-45a1-4808-abe1-ccd102c7a99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andersen_story2.txt\n",
      "Andersen_story8.txt\n",
      "Andersen_story11.txt\n",
      "Andersen_story7.txt\n",
      "Andersen_story17.txt\n",
      "Andersen_story15.txt\n",
      "Andersen_story9.txt\n",
      "Andersen_story5.txt\n",
      "Andersen_story1.txt\n",
      "Andersen_story12.txt\n",
      "Andersen_story16.txt\n",
      "Andersen_story18.txt\n",
      "Andersen_story3.txt\n",
      "Andersen_story10.txt\n",
      "Andersen_story13.txt\n"
     ]
    }
   ],
   "source": [
    "m4_matches_fuzzy = fuzzy_match(m4_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10f88e76-283a-4b38-b65b-565bd60744e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_accuracy_fuzzy = {}\n",
    "\n",
    "for item in m4_matches_fuzzy:\n",
    "    m4_accuracy_fuzzy[item] = []\n",
    "    for prompt_version in m4_matches_fuzzy[item]:\n",
    "        m4_accuracy_fuzzy[item].append(np.mean(np.array(prompt_version)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d7e8b5d-1b5a-4448-8702-982eb9fae7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_prompt_accuracies_fuzzy = [ [] for _ in range(23)]\n",
    "\n",
    "for k in range(23):\n",
    "    for item in m4_accuracy_fuzzy:\n",
    "        m4_prompt_accuracies_fuzzy[k].append(m4_accuracy_fuzzy[item][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62287e3b-ac37-40f0-8ef3-6ab7ae1749f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_prompt_accuracy_fuzzy = np.mean(np.array(m4_prompt_accuracies_fuzzy), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75f2b4f2-71c3-472b-96ed-59e90f738377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4_prompt_accuracy_fuzzy.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdbc1e72-fe48-4e35-82ae-bd081bf4ab74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.524921867260577"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4_prompt_accuracy_fuzzy[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57463b8e-040e-4062-8dea-6fb615d136ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4573698262933888"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4_prompt_accuracy_fuzzy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebd3632b-a4a9-45ad-afc2-30c352553e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43146218214153004"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_fuzzy.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b09bfc-a1fb-4718-b32e-a779dbca444f",
   "metadata": {},
   "source": [
    "### Previous Trials with Fuzzy Matching: Accuracy Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f8c900ea-cffb-4abc-95e0-f2e0c81b0b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08154767289299424"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_lev_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "71121c13-c011-4020-b513-78a03b7c51fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11087874166360825"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_lev_75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b0956f29-d4bb-4106-8130-24f3985020dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2071396326993166"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_lev_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ec696521-9234-43ed-9f6a-fd297c42f0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32427335322769507"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_lev_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4d37d070-84a6-4446-8e4d-e73997ba7b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47486706971055076"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_partial_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0ce39d08-1b14-47ae-8b5c-d2636c98724d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42054966164745144"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_partial_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "45c0f883-71a6-4d8a-b4ee-ce18239c0a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36112372717734176"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_partial_75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f8636022-ad31-4dfa-852a-d4acfbb163b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33079366003527017"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_partial_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "30ec4f71-132d-4ceb-840c-128ca1cc4cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31400508087830614"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_partial_99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4438f5a8-ed1d-4584-a10c-4948183865ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31400508087830614"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_partial_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7acbfa37-2389-4d93-bd00-f2095540b316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2067773138587369"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_ratio_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "431dcc5a-b890-4313-9fdf-cbca39400067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32042887955123456"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_ratio_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8899be82-a04c-4b0d-b406-9798cb047226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11087874166360825"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_ratio_80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c555f95c-ddb8-4a95-b94b-e2ee1077c3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3129697970542027"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_prompt_accuracy_old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b201a7db-1537-49d0-9620-1fef135d0dc8",
   "metadata": {},
   "source": [
    "### Compare the Two Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a69e9756-b2f9-4265-a7df-3a015ccddf40",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andersen_story2.txt\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "GOLD:  ['between the court-ladies']\n",
      "PREDICTION:  the court\n",
      "GOLD:  [\"near the swineherd's room\", \"around the swineherd's room\", \"near the swineherd's place\", \"around the swineherd's place\"]\n",
      "PREDICTION:  in the palace\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "GOLD:  ['in a large hall', 'large hall']\n",
      "PREDICTION:  The princess is in the large hall.\n",
      "GOLD:  ['a dirty little room close by the pigsty', 'his room', \"prince's room\", 'by the pigsty', 'room']\n",
      "PREDICTION:  The Prince is in the pigsty.\n",
      "GOLD:  ['the balcony']\n",
      "PREDICTION:  The Emperor's balcony\n",
      "GOLD:  ['a dirty little room close by the pigsty', 'his room', \"prince's room\", 'by the pigsty', 'room']\n",
      "PREDICTION:  The Prince is in the pigsty.\n",
      "GOLD:  ['the balcony']\n",
      "PREDICTION:  The Emperor's balcony\n",
      "GOLD:  ['behind a tree']\n",
      "PREDICTION:  Behind a tree.\n",
      "GOLD:  [\"the swineherd's room\", \"the swineherd's place\"]\n",
      "PREDICTION:  in the palace\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  the Princess\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  the swineherd's own little kingdom\n",
      "GOLD:  ['in a large hall', 'large hall']\n",
      "PREDICTION:  The princess is in the large hall.\n",
      "GOLD:  ['the door', \"the emperor's house\", 'the palace']\n",
      "PREDICTION:  The Emperor's Palace\n",
      "GOLD:  ['a dirty little room close by the pigsty', 'his room', \"prince's room\", 'by the pigsty', 'room']\n",
      "PREDICTION:  He is in the pigsty.\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  The Princess\n",
      "GOLD:  ['behind a tree']\n",
      "PREDICTION:  The swineherd went behind a tree.\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  The prince is in his own little kingdom.\n",
      "GOLD:  ['the door', \"the emperor's house\", 'the palace']\n",
      "PREDICTION:  The Emperor is at the palace.\n",
      "GOLD:  ['a dirty little room close by the pigsty', 'his room', \"prince's room\", 'by the pigsty', 'room']\n",
      "PREDICTION:  He is in the pigsty.\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "GOLD:  ['the balcony']\n",
      "PREDICTION:  The emperor is on the balcony.\n",
      "GOLD:  ['behind a tree']\n",
      "PREDICTION:  The swineherd went behind a tree.\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  The prince is in his own little kingdom.\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "GOLD:  ['between the court-ladies']\n",
      "PREDICTION:  in the court\n",
      "GOLD:  [\"near the swineherd's room\", \"around the swineherd's room\", \"near the swineherd's place\", \"around the swineherd's place\"]\n",
      "PREDICTION:  the palace\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "GOLD:  ['between the court-ladies']\n",
      "PREDICTION:  court\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  He is in his own little kingdom\n",
      "GOLD:  ['the door', \"the emperor's house\", 'the palace']\n",
      "PREDICTION:  He is outside the palace\n",
      "GOLD:  [\"near the swineherd's room\", \"around the swineherd's room\", \"near the swineherd's place\", \"around the swineherd's place\"]\n",
      "PREDICTION:  in the palace\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  In front of her\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  He is in his own little kingdom.\n",
      "GOLD:  ['in a large hall', 'large hall']\n",
      "PREDICTION:  in the hall\n",
      "GOLD:  [\"near the swineherd's room\", \"around the swineherd's room\", \"near the swineherd's place\", \"around the swineherd's place\"]\n",
      "PREDICTION:  in the palace\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  He is in his own little kingdom\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  In front of her\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  The prince is in his own little kingdom.\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  In front of her\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  The prince is in his own little kingdom.\n",
      "GOLD:  ['in a large hall', 'large hall']\n",
      "PREDICTION:  in the hall\n",
      "GOLD:  ['the door', \"the emperor's house\", 'the palace']\n",
      "PREDICTION:  He is outside the palace\n",
      "GOLD:  [\"near the swineherd's room\", \"around the swineherd's room\", \"near the swineherd's place\", \"around the swineherd's place\"]\n",
      "PREDICTION:  in the palace\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  He is in his own little kingdom.\n",
      "GOLD:  ['in a large hall', 'large hall']\n",
      "PREDICTION:  In the hall\n",
      "GOLD:  ['the door', \"the emperor's house\", 'the palace']\n",
      "PREDICTION:  The Emperor's palace\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  In front of her\n",
      "GOLD:  ['out of the city']\n",
      "PREDICTION:  He is out of the city.\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  The prince is in his own little kingdom\n",
      "GOLD:  ['in a large hall', 'large hall']\n",
      "PREDICTION:  in the hall\n",
      "GOLD:  ['the door', \"the emperor's house\", 'the palace']\n",
      "PREDICTION:  The Emperor is in the palace\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  In front of her\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  The prince is in his own little kingdom\n",
      "GOLD:  [\"near the swineherd's room\", \"around the swineherd's room\", \"near the swineherd's place\", \"around the swineherd's place\"]\n",
      "PREDICTION:  in the palace\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  his own little kingdom\n",
      "GOLD:  [\"near the swineherd's room\", \"around the swineherd's room\", \"near the swineherd's place\", \"around the swineherd's place\"]\n",
      "PREDICTION:  in the palace\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  his own little kingdom\n",
      "GOLD:  [\"near the swineherd's room\", \"around the swineherd's room\", \"near the swineherd's place\", \"around the swineherd's place\"]\n",
      "PREDICTION:  in the palace\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  In front of her\n",
      "GOLD:  [\"the prince's kingdom\", 'kingdom']\n",
      "PREDICTION:  He is in his own little kingdom.\n",
      "GOLD:  [\"near the swineherd's room\", \"around the swineherd's room\", \"near the swineherd's place\", \"around the swineherd's place\"]\n",
      "PREDICTION:  in the palace\n",
      "GOLD:  ['in front of the princess']\n",
      "PREDICTION:  in front of her\n",
      "Andersen_story8.txt\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  up a-top of the house all alone\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  in the beautiful garden of their home\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  a-top of the house all alone\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  in the beautiful garden of their home\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  up a-top of the house\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  In the middle of the Elderbush\n",
      "GOLD:  ['the country']\n",
      "PREDICTION:  The boy is in the country\n",
      "GOLD:  ['the smithy']\n",
      "PREDICTION:  The little maiden is in the smithy\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  He lives up a-top of the house all alone.\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  In the middle of the Elderbush.\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  She is in the garden of her home.\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  He is in the garden of his home.\n",
      "GOLD:  ['the country']\n",
      "PREDICTION:  The little maiden is in the country.\n",
      "GOLD:  ['the country']\n",
      "PREDICTION:  The boy is in the country.\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  He lives up a-top of the house all alone.\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  In the middle of the Elderbush.\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  He is in the garden of his home.\n",
      "GOLD:  ['the country']\n",
      "PREDICTION:  The little maiden is in the country.\n",
      "GOLD:  ['the country']\n",
      "PREDICTION:  The little boy is in the country.\n",
      "GOLD:  ['in his bed']\n",
      "PREDICTION:  He is in his bed.\n",
      "GOLD:  [\"old woman's bosom\"]\n",
      "PREDICTION:  on her bosom\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  in the garden of their home\n",
      "GOLD:  ['the smithy']\n",
      "PREDICTION:  The little maiden is in the smithy\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  He lives up a-top of the house all alone\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  She is in the garden of her home.\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  He is in the garden of his home.\n",
      "GOLD:  ['the country']\n",
      "PREDICTION:  The little boy is in the country.\n",
      "GOLD:  ['the country']\n",
      "PREDICTION:  The little boy was in the country\n",
      "GOLD:  ['the smithy']\n",
      "PREDICTION:  The little maiden is in the smithy.\n",
      "GOLD:  ['the smithy']\n",
      "PREDICTION:  The boy is in the smithy.\n",
      "GOLD:  ['in the tree']\n",
      "PREDICTION:  She is in the tree.\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  a-top of the house\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  She is in the garden of her home.\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  He is in the garden of his home.\n",
      "GOLD:  ['the country']\n",
      "PREDICTION:  The little maiden is in the country.\n",
      "GOLD:  ['the country']\n",
      "PREDICTION:  The boy is in the country.\n",
      "GOLD:  ['the smithy']\n",
      "PREDICTION:  The little maiden is in the smithy.\n",
      "GOLD:  ['the smithy']\n",
      "PREDICTION:  The boy is in the smithy.\n",
      "GOLD:  ['in the tree']\n",
      "PREDICTION:  She is in the tree.\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  up a-top of the house\n",
      "GOLD:  [\"old woman's bosom\"]\n",
      "PREDICTION:  on her bosom\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  in the garden of their home\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  up a-top of the house\n",
      "GOLD:  [\"old woman's bosom\"]\n",
      "PREDICTION:  on her bosom\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  in the garden of their home\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  up a-top of the house\n",
      "GOLD:  [\"old woman's bosom\"]\n",
      "PREDICTION:  on her bosom\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  in the garden of their home\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  a-top of the house\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  in the garden of their home\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  a-top of the house\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  in the garden of their home\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  In the middle of the Elderbush\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  In the middle of the Elderbush\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  In the middle of the Elderbush\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  Up a-top of the house\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  In the middle of the Elderbush\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  In the middle of the Elderbush\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  in the garden of her home\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  In the middle of the Elderbush\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  in the garden of her home\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  up a-top of the house\n",
      "GOLD:  [\"old woman's bosom\"]\n",
      "PREDICTION:  on her bosom\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  in the garden of their home\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  Up a-top of the house\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  In the middle of the Elderbush\n",
      "GOLD:  ['the garden']\n",
      "PREDICTION:  in the garden of their home\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  Up a-top of the house\n",
      "GOLD:  ['in the middle of the bush', 'bush']\n",
      "PREDICTION:  In the middle of the Elderbush\n",
      "GOLD:  ['the house']\n",
      "PREDICTION:  a-top of the house\n",
      "Andersen_story7.txt\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The grasshopper is in the middle of the room.\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The flea is in the middle of the room.\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The leap-frog is in the middle of the room.\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The king is in the room.\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The grasshopper is in the middle of the room.\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The flea is in the middle of the room.\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The leap-frog is in the middle of the room.\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The king is in the room.\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The leap-frog is in the middle of the room.\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The king is in the room.\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The leap-frog is in the middle of the room.\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The king is in the room.\n",
      "GOLD:  ['the room']\n",
      "PREDICTION:  The leap-frog is in the middle of the room.\n",
      "Andersen_story9.txt\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  a clump of willows which grew on the skirts of the forest\n",
      "GOLD:  ['the forest']\n",
      "PREDICTION:  a clump of willows which grew on the skirts of the forest\n",
      "GOLD:  ['upon the trees', 'trees']\n",
      "PREDICTION:  The ugly apes sat upon the trees.\n",
      "GOLD:  ['upon the trees', 'trees']\n",
      "PREDICTION:  The ugly apes sat upon the trees.\n",
      "GOLD:  ['upon the trees', 'trees']\n",
      "PREDICTION:  The ugly apes sat upon the trees.\n",
      "Andersen_story5.txt\n",
      "GOLD:  ['in a court-yard', 'court-yard', 'yard']\n",
      "PREDICTION:  in a court-yard with the other trees\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  in the drawing-room\n",
      "GOLD:  ['out of the room', 'in the loft', 'in a dark corner']\n",
      "PREDICTION:  in a dark corner, where no daylight could enter\n",
      "GOLD:  ['in a court-yard', 'court-yard', 'yard']\n",
      "PREDICTION:  in a court-yard with the other trees\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  in the drawing-room\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree', 'tree']\n",
      "PREDICTION:  Towards the Tree\n",
      "GOLD:  ['out of the room', 'in the loft', 'in a dark corner']\n",
      "PREDICTION:  in a dark corner, where no daylight could enter\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  in a large and splendid drawing-room\n",
      "GOLD:  ['under the tree', 'in the room', 'room', 'next to the fat man']\n",
      "PREDICTION:  The Tree was very happy when the young ladies came to decorate him, but he was very\n",
      "GOLD:  ['out in the woods', 'in the woods', 'woods']\n",
      "PREDICTION:  The fir tree is in the woods.\n",
      "GOLD:  ['out in the woods', 'in the woods', 'woods', 'next to the tree', 'by the tree', 'in the tree', 'near the tree', 'around the tree', 'tree']\n",
      "PREDICTION:  The Tree lay down in the wood and waited for the swallows and the stork\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  The young ladies are in the drawing-room.\n",
      "GOLD:  ['behind the children', 'following the children', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  The older persons are in the room.\n",
      "GOLD:  ['round the tree', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  They are dancing round the Tree.\n",
      "GOLD:  ['between the branches', 'round the tree', 'in the room', 'room', 'near the tree', 'by the tree', 'tree']\n",
      "PREDICTION:  The old nurse is in the room.\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree', 'tree']\n",
      "PREDICTION:  He is near the Tree.\n",
      "GOLD:  ['under the tree', 'in the room', 'room', 'next to the fat man']\n",
      "PREDICTION:  The Tree was very happy when the young ladies brought their beautiful Tree into the house.\n",
      "GOLD:  ['out of the room', 'in the loft', 'in a dark corner']\n",
      "PREDICTION:  in a dark corner, where no daylight could enter\n",
      "GOLD:  ['around the tree', 'around the fir tree', 'about the tree', 'about the fir tree', 'in the loft']\n",
      "PREDICTION:  The mice are in the loft.\n",
      "GOLD:  ['in the court-yard', 'out in the courtyard', 'in the courtyard', 'in the yard', 'out', 'outside', 'about the tree', 'about the fir tree', 'near the tree', 'near the fir tree']\n",
      "PREDICTION:  The children are playing in the court-yard.\n",
      "GOLD:  ['out in the woods', 'in the woods', 'woods']\n",
      "PREDICTION:  The fir tree is in the woods.\n",
      "GOLD:  ['out in the woods', 'in the woods', 'woods', 'next to the tree', 'by the tree', 'in the tree', 'near the tree', 'around the tree', 'tree']\n",
      "PREDICTION:  The Tree lay down in the wood and waited for the sunbeams to shine on\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  The young ladies are in the drawing-room.\n",
      "GOLD:  ['behind the children', 'following the children', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  The older persons are in the room.\n",
      "GOLD:  ['round the tree', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  They are dancing round the Tree.\n",
      "GOLD:  ['between the branches', 'round the tree', 'in the room', 'room', 'near the tree', 'by the tree', 'tree']\n",
      "PREDICTION:  The old nurse is in the room.\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree', 'tree']\n",
      "PREDICTION:  He is near the Tree.\n",
      "GOLD:  ['under the tree', 'in the room', 'room', 'next to the fat man']\n",
      "PREDICTION:  The Tree was very happy when the young ladies came to decorate him.\n",
      "GOLD:  ['out of the room', 'in the loft', 'in a dark corner']\n",
      "PREDICTION:  in a dark corner, where no daylight could enter\n",
      "GOLD:  ['in the court-yard', 'out in the courtyard', 'in the courtyard', 'in the yard', 'out', 'outside', 'about the tree', 'about the fir tree', 'near the tree', 'near the fir tree']\n",
      "PREDICTION:  The children are playing in the court-yard.\n",
      "GOLD:  ['under the tree', 'in the room', 'room']\n",
      "PREDICTION:  The little fat man came to the Tree and sat under it.\n",
      "GOLD:  ['under the tree', 'in the room', 'room', 'next to the fat man']\n",
      "PREDICTION:  The Tree was very happy when the young ladies came to decorate him, but he was very\n",
      "GOLD:  ['in the court-yard', 'out in the courtyard', 'in the courtyard', 'in the yard', 'out', 'outside', 'about the tree', 'about the fir tree', 'near the tree', 'near the fir tree']\n",
      "PREDICTION:  the court\n",
      "GOLD:  ['out in the woods', 'in the woods', 'woods']\n",
      "PREDICTION:  The fir tree is in the woods.\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  The young ladies are in the drawing-room.\n",
      "GOLD:  ['round the tree', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  They are dancing round the Tree.\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree', 'tree']\n",
      "PREDICTION:  He is near the Tree.\n",
      "GOLD:  ['under the tree', 'in the room', 'room']\n",
      "PREDICTION:  The Tree was very happy when the evening came, and he trembled with\n",
      "GOLD:  ['under the tree', 'in the room', 'room', 'next to the fat man']\n",
      "PREDICTION:  The Tree was very happy when the young ladies came to decorate him, but he was very\n",
      "GOLD:  ['in the court-yard', 'out in the courtyard', 'in the courtyard', 'in the yard', 'out', 'outside', 'about the tree', 'about the fir tree', 'near the tree', 'near the fir tree']\n",
      "PREDICTION:  They are in the court-yard.\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  The young ladies are in the drawing-room.\n",
      "GOLD:  ['round the tree', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  They are dancing round the Tree.\n",
      "GOLD:  ['under the tree', 'in the room', 'room']\n",
      "PREDICTION:  The little fat man was sitting under the Tree, and the children drew him towards\n",
      "GOLD:  ['under the tree', 'in the room', 'room', 'next to the fat man']\n",
      "PREDICTION:  The Tree was very happy when the young ladies came to decorate him, but he was very\n",
      "GOLD:  ['in the court-yard', 'out in the courtyard', 'in the courtyard', 'in the yard', 'out', 'outside', 'about the tree', 'about the fir tree', 'near the tree', 'near the fir tree']\n",
      "PREDICTION:  They are in the court-yard.\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  in the drawing-room\n",
      "GOLD:  ['out in the woods', 'in the woods', 'woods', 'next to the tree', 'by the tree', 'in the tree', 'near the tree', 'around the tree', 'tree']\n",
      "PREDICTION:  They are in the wood\n",
      "GOLD:  ['behind the children', 'following the children', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  The older persons are in the room with the tree\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree', 'tree']\n",
      "PREDICTION:  Towards the Tree\n",
      "GOLD:  ['out of the room', 'in the loft', 'in a dark corner']\n",
      "PREDICTION:  in a dark corner, where no daylight can enter\n",
      "GOLD:  ['out in the woods', 'in the woods', 'woods', 'next to the tree', 'by the tree', 'in the tree', 'near the tree', 'around the tree', 'tree']\n",
      "PREDICTION:  They are in the wood\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree', 'tree']\n",
      "PREDICTION:  Towards the Tree\n",
      "GOLD:  ['out of the room', 'in the loft', 'in a dark corner']\n",
      "PREDICTION:  in a dark corner, where no daylight can enter\n",
      "GOLD:  ['under the tree', 'in the room', 'room', 'next to the fat man']\n",
      "PREDICTION:  They are dancing around the tree\n",
      "GOLD:  ['round the tree', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  They are dancing around the tree\n",
      "GOLD:  ['under the tree', 'in the room', 'room', 'next to the fat man']\n",
      "PREDICTION:  They are dancing around the tree\n",
      "GOLD:  ['out in the woods', 'in the woods', 'woods', 'next to the tree', 'by the tree', 'in the tree', 'near the tree', 'around the tree', 'tree']\n",
      "PREDICTION:  They are in the wood\n",
      "GOLD:  ['round the tree', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  They are dancing around the tree\n",
      "GOLD:  ['under the tree', 'in the room', 'room', 'next to the fat man']\n",
      "PREDICTION:  They are dancing in the room\n",
      "GOLD:  ['round the tree', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  They are dancing around the tree\n",
      "GOLD:  ['round the tree', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  They are dancing around the tree\n",
      "GOLD:  ['out in the woods', 'in the woods', 'woods', 'next to the tree', 'by the tree', 'in the tree', 'near the tree', 'around the tree', 'tree']\n",
      "PREDICTION:  in the wood\n",
      "GOLD:  ['out in the woods', 'in the woods', 'woods', 'next to the tree', 'by the tree', 'in the tree', 'near the tree', 'around the tree', 'tree']\n",
      "PREDICTION:  They are in the wood\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  in the drawing-room\n",
      "GOLD:  ['behind the children', 'following the children', 'in the room', 'room', 'near the tree', 'by the tree']\n",
      "PREDICTION:  The older persons are in the room with the children\n",
      "GOLD:  ['in the room', 'room', 'near the tree', 'by the tree', 'tree']\n",
      "PREDICTION:  The children drew the fat man towards the Tree\n",
      "GOLD:  ['under the tree', 'in the room', 'room']\n",
      "PREDICTION:  He seated himself under the Tree\n",
      "Andersen_story1.txt\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the streets of his capital\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the streets of his capital\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the streets of his capital\n",
      "GOLD:  ['the hall']\n",
      "PREDICTION:  The Emperor's hall\n",
      "GOLD:  ['under his high canopy', 'under the canopy', 'in the midst of the procession', 'procession', '']\n",
      "PREDICTION:  The Emperor is in the midst of the procession.\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the streets of his capital\n",
      "GOLD:  ['the hall']\n",
      "PREDICTION:  the Emperor's hall\n",
      "GOLD:  ['under his high canopy', 'under the canopy', 'in the midst of the procession', 'procession', '']\n",
      "PREDICTION:  The Emperor is in the midst of the procession.\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the streets of his capital\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the streets of his capital\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the streets of his capital\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the streets of his capital\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "GOLD:  ['the hall']\n",
      "PREDICTION:  The Emperor's hall\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "GOLD:  ['the hall']\n",
      "PREDICTION:  The Emperor's hall\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the streets of his capital\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the streets of his capital\n",
      "GOLD:  ['the hall']\n",
      "PREDICTION:  the weavers' hall\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "GOLD:  ['procession', 'the streets']\n",
      "PREDICTION:  in the street\n",
      "Andersen_story3.txt\n",
      "GOLD:  ['the bedroom']\n",
      "PREDICTION:  The old King went to the bedroom.\n",
      "GOLD:  ['his palace', \"the prince's palace\", 'the palace']\n",
      "PREDICTION:  He is in the palace.\n",
      "GOLD:  ['the palace']\n",
      "PREDICTION:  The king is in his palace.\n",
      "GOLD:  ['the bedroom']\n",
      "PREDICTION:  The old King went to the bedroom.\n",
      "GOLD:  ['the bedroom']\n",
      "PREDICTION:  The old King went to the bedroom.\n",
      "GOLD:  ['the bedroom']\n",
      "PREDICTION:  The old King went to the bedroom.\n",
      "GOLD:  ['the bedroom']\n",
      "PREDICTION:  the old King's bedroom\n",
      "GOLD:  ['the palace']\n",
      "PREDICTION:  outside the palace\n",
      "GOLD:  ['the palace']\n",
      "PREDICTION:  He is outside the palace\n",
      "GOLD:  ['the palace']\n",
      "PREDICTION:  outside the palace\n",
      "GOLD:  ['the palace']\n",
      "PREDICTION:  outside the palace\n",
      "GOLD:  ['the palace']\n",
      "PREDICTION:  outside the palace\n",
      "GOLD:  ['the palace']\n",
      "PREDICTION:  outside the palace\n",
      "GOLD:  ['the palace']\n",
      "PREDICTION:  outside the palace\n",
      "GOLD:  ['the palace']\n",
      "PREDICTION:  outside the palace\n",
      "GOLD:  ['the palace']\n",
      "PREDICTION:  He is outside the palace\n",
      "Andersen_story10.txt\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  in the old man's room\n",
      "GOLD:  ['away']\n",
      "PREDICTION:  he is away, and he stayed away.\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The old man sat in the room with the projecting windows\n",
      "GOLD:  ['on the floor']\n",
      "PREDICTION:  thrown himself off the drawers right down on the floor\n",
      "GOLD:  ['away']\n",
      "PREDICTION:  He is away, and he stayed away.\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He lives in the old house opposite.\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The old man is in the room with the projecting windows.\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home.\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is in the old house.\n",
      "GOLD:  ['away']\n",
      "PREDICTION:  He is away, and he stayed away.\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  He is at home.\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  He is in the house here, where the garden is.\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He lives in the old house opposite.\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  He is in the room with the projecting windows.\n",
      "GOLD:  ['the other room', 'room']\n",
      "PREDICTION:  In a room with a lot of furniture.\n",
      "GOLD:  ['on the drawers', 'drawers']\n",
      "PREDICTION:  On the drawers.\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home.\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  The little boy is in the old house.\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is in the old house.\n",
      "GOLD:  ['away']\n",
      "PREDICTION:  He is away, and he stayed away.\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  He is at home.\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  He is in the house here, where the garden is.\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  She is in the garden.\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  the old man's room\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  the old man's room\n",
      "GOLD:  ['the window opposite the old house', 'window']\n",
      "PREDICTION:  He is in the old house\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is in the old house.\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is in the old house.\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  He is in the room with the projecting windows.\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  The little boy is at home\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  He is in the house here, where the garden is.\n",
      "GOLD:  ['the window opposite the old house', 'window']\n",
      "PREDICTION:  He is in the old house\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is in the old house.\n",
      "GOLD:  ['the other room', 'room']\n",
      "PREDICTION:  He is in a room with a lot of furniture.\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  He is in the house here, where the garden is.\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  quite alone in the old house\n",
      "GOLD:  ['away']\n",
      "PREDICTION:  he was away, and he stayed away.\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is in his own house\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  He is in the house where the garden was\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is in his own house\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  in the old man's room\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  He is in the house where the garden is\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  He is in the house where the garden is.\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is in the old house.\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  He is in the house where the garden is.\n",
      "GOLD:  ['the old house']\n",
      "PREDICTION:  He is in his own house\n",
      "GOLD:  ['the room where the projecting windows were', 'the room']\n",
      "PREDICTION:  The old man's room\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  He is in the house where the garden is.\n",
      "GOLD:  ['home']\n",
      "PREDICTION:  He went home\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  He is in the house where the garden is.\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  He is in the house where the garden is.\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  She is in the house with the garden\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  He is in the house where the garden is\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  In the house where the garden was\n",
      "GOLD:  ['garden']\n",
      "PREDICTION:  In the house where the garden was\n"
     ]
    }
   ],
   "source": [
    "for item in m2_predictions:\n",
    "    \n",
    "    print(item)    \n",
    "    \n",
    "    f = open(os.path.join(path_annotations, item), 'r')\n",
    "    annotations = pd.read_csv(f, sep=\"\\t\")\n",
    "    annotations = annotations.values #numpy array\n",
    "    f.close()\n",
    "    \n",
    "    for k in range(1,24):\n",
    "        \n",
    "        pred_locs = m2_predictions[item][k-1]\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        for line in annotations:\n",
    "            \n",
    "            gold_locations = line[2].split(\"/\")\n",
    "            \n",
    "            pred_tokenized = word_tokenize(pred_locs[i].lower())\n",
    "            new_pred_tokens = [ token for token in pred_tokenized if token not in stop_words]\n",
    "            pred_wo_stop_words = \" \".join(new_pred_tokens)\n",
    "            \n",
    "            match1 = False\n",
    "            match2 = False\n",
    " \n",
    "            for gold_location in gold_locations:                \n",
    "                \n",
    "                gold_tokenized = word_tokenize(gold_location.lower())\n",
    "                new_gold_tokens = [ token for token in gold_tokenized if token not in stop_words]\n",
    "                gold_wo_stop_words = \" \".join(new_gold_tokens)\n",
    "                \n",
    "                if gold_wo_stop_words == pred_wo_stop_words:\n",
    "                    match1 = True\n",
    "                    \n",
    "                if fuzz.partial_ratio(gold_wo_stop_words, pred_wo_stop_words) > 90:\n",
    "                    match2 = True\n",
    "                \n",
    "            if match2 and not match1:\n",
    "                print(\"GOLD: \", gold_locations)\n",
    "                print(\"PREDICTION: \", pred_locs[i])\n",
    "            \n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335bcf46-e39c-404e-bfb4-7831d20ddb88",
   "metadata": {},
   "source": [
    "### Save the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2beb317e-4b40-4eda-b518-c1ccb42356de",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(\"method2_accuracy.xlsx\", engine='xlsxwriter')\n",
    "df = pd.DataFrame(data = method2_accuracy)\n",
    "df.to_excel(writer, sheet_name=\"Accuracies\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "088bf3b6-d7a5-469c-8d21-ec2982ffa9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(\"method2_accuracy_prompt.xlsx\", engine='xlsxwriter')\n",
    "df = pd.DataFrame(data = m2_prompt_accuracy)\n",
    "df.to_excel(writer, sheet_name=\"Accuracies\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f9630-7678-4740-ae27-6bd3d9dd03d7",
   "metadata": {},
   "source": [
    "# Method 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1562bf86-ccff-405c-b8c0-a3b38ee12498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[popenfile(path='/scratch/users/bozyurt20/jupyter-4098654.log', fd=1, position=5916, mode='a', flags=33793), popenfile(path='/scratch/users/bozyurt20/jupyter-4098654.log', fd=2, position=14413, mode='a', flags=33793), popenfile(path='/scratch/users/bozyurt20/.ipython/profile_default/history.sqlite', fd=37, position=12288, mode='r+', flags=688130), popenfile(path='/scratch/users/bozyurt20/.ipython/profile_default/history.sqlite', fd=38, position=40, mode='r+', flags=688130), popenfile(path='/scratch/users/bozyurt20/.ipython/profile_default/history.sqlite-journal', fd=110, position=13312, mode='r+', flags=688130)]\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "proc = psutil.Process()\n",
    "print(proc.open_files())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa8e1f7-f482-4c37-9ce8-21cda961d767",
   "metadata": {},
   "source": [
    "## Making Predictions Without a Starting Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dabb39-dcc1-4124-bae6-5a7258abb660",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_no_tokens = 512\n",
    "\n",
    "m3_predictions = {}\n",
    "\n",
    "for item in dir_list_andersen:\n",
    "    \n",
    "    if item in dir_list_annotations:\n",
    "        \n",
    "        f = open(os.path.join(path_annotations, item), 'r')\n",
    "        annotations = pd.read_csv(f, sep=\"\\t\")\n",
    "        annotations = annotations.values #numpy array\n",
    "        f.close()\n",
    "\n",
    "        f = open(os.path.join(path_andersen, item), 'r') \n",
    "        story = f.read()\n",
    "        f.close()\n",
    "\n",
    "        paragraphs = story.split(\"\\n\\n\")\n",
    "        paragraphs = paragraphs[1:] # first paragraph is just the title\n",
    "\n",
    "        out_path = \"Method3_\" + item[:-3] + \"xlsx\"\n",
    "        writer = pd.ExcelWriter(out_path, engine='xlsxwriter')\n",
    "        workbook = writer.book\n",
    "        format = workbook.add_format({'text_wrap': True})\n",
    "\n",
    "        m3_predictions[item] = {}\n",
    "\n",
    "        no_paragraphs = len(paragraphs)\n",
    "\n",
    "        characters = []\n",
    "\n",
    "        for line in annotations:\n",
    "            characters.append((line[1], line[3]))\n",
    "\n",
    "        characters = list(set(characters))\n",
    "\n",
    "        for i, paragraph in enumerate(paragraphs):\n",
    "\n",
    "            paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "\n",
    "            tokens_paragraph = tokenizer.encode(paragraph, return_tensors=\"pt\")\n",
    "            no_tokens_paragraph = len(tokens_paragraph[0])\n",
    "            \n",
    "            my_dic = {}\n",
    "\n",
    "            for character_tuple in characters:\n",
    "\n",
    "                character, grammatical_number = character_tuple\n",
    "\n",
    "                if grammatical_number == 'singular':\n",
    "                    to_be = 'is'\n",
    "                elif grammatical_number == 'plural':\n",
    "                    to_be = 'are'\n",
    "\n",
    "                question = \" Tell me where \" + character + \" \" + to_be + \" at this point in the story.\"\n",
    "                question_tokens = tokenizer.encode(question, return_tensors=\"pt\")\n",
    "                no_question_tokens = len(question_tokens[0])\n",
    "                \n",
    "                prompts = []\n",
    "\n",
    "                no_tokens_left = max_no_tokens - no_question_tokens\n",
    "\n",
    "                if no_tokens_left < no_tokens_paragraph:\n",
    "\n",
    "                    print(\"CUTTING ALERT!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "                    cutting = len(paragraph) // 2\n",
    "                    x = paragraph[cutting:].find(\".\") + cutting + 1\n",
    "                    paragraph1 = paragraph[0:x]\n",
    "                    paragraph2 = paragraph[x:]\n",
    "                    prompt1 = paragraph1 + question\n",
    "                    prompt2 = paragraph2 + question\n",
    "                    prompts.append(prompt1)\n",
    "                    prompts.append(prompt2)\n",
    "\n",
    "                else: \n",
    "\n",
    "                    prompt = paragraph + question\n",
    "                    prompts.append(prompt)       \n",
    "                \n",
    "                for prompt in prompts:\n",
    "                    \n",
    "                    tokens_prompt = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "                    tokens_prompt = tokens_prompt.to(\"cuda:0\")\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model.generate(tokens_prompt)   \n",
    "\n",
    "                    out = tokenizer.decode(outputs[0], skip_special_tokens=True)                \n",
    "                    my_dic[prompt] = [character, out]\n",
    "\n",
    "                    m3_predictions[item][prompt] = out\n",
    "\n",
    "            df = pd.DataFrame(data=my_dic, index=[\"Character\", \"Output\"])\n",
    "            df = (df.T)\n",
    "            df.to_excel(writer, sheet_name=\"Paragraph \" + str(i+1))\n",
    "            worksheet = writer.sheets[\"Paragraph \" + str(i+1)]\n",
    "\n",
    "            for idx, col in enumerate(df):\n",
    "                max_len = 75\n",
    "                worksheet.set_column(idx, idx, max_len, format)\n",
    "                    \n",
    "        writer.save()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc219d38-99a7-407d-893a-621950fb85e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kuacc/users/bozyurt20/.conda/envs/hf/lib/python3.9/site-packages/xlsxwriter/workbook.py:336: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    }
   ],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f1a9aa5-c6b0-4bbf-bb23-aa8ef667fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Method3Predictions.txt\", \"wb\") as f:\n",
    "    pickle.dump(m3_predictions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120acd56-6f17-41c6-9572-9282d46e4361",
   "metadata": {},
   "source": [
    "## Making Predictions With a Starting Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "094fa11e-e64e-4585-8331-8a39822953f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "starting_prompt = \"I am going to tell you a story. Try to remember it: \"\n",
    "tokens_starting_prompt = tokenizer.encode(starting_prompt, return_tensors=\"pt\")\n",
    "no_tokens_starting_prompt = len(tokens_starting_prompt[0])\n",
    "\n",
    "max_no_tokens = 512\n",
    "\n",
    "m3_predictions = {}\n",
    "\n",
    "item = \"Andersen_story1.txt\"\n",
    "\n",
    "for item in dir_list_andersen:\n",
    "    \n",
    "    if item in dir_list_annotations:\n",
    "        \n",
    "        check = 1\n",
    "\n",
    "        f = open(os.path.join(path_annotations, item), 'r')\n",
    "        annotations = pd.read_csv(f, sep=\"\\t\")\n",
    "        annotations = annotations.values #numpy array\n",
    "        f.close()\n",
    "\n",
    "        f = open(os.path.join(path_andersen, item), 'r') \n",
    "        story = f.read()\n",
    "        f.close()\n",
    "\n",
    "        paragraphs = story.split(\"\\n\\n\")\n",
    "        paragraphs = paragraphs[1:] # first paragraph is just the title\n",
    "\n",
    "        out_path = \"Method3_\" + item[:-3] + \"xlsx\"\n",
    "        writer = pd.ExcelWriter(out_path, engine='xlsxwriter')\n",
    "        workbook = writer.book\n",
    "        format = workbook.add_format({'text_wrap': True})\n",
    "\n",
    "        m3_predictions[item] = {}\n",
    "\n",
    "        no_paragraphs = len(paragraphs)\n",
    "\n",
    "        characters = []\n",
    "\n",
    "        for line in annotations:\n",
    "            characters.append((line[1], line[3]))\n",
    "\n",
    "        characters = list(set(characters))\n",
    "\n",
    "        for i, paragraph in enumerate(paragraphs):\n",
    "\n",
    "            paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "\n",
    "            tokens_paragraph = tokenizer.encode(paragraph, return_tensors=\"pt\")\n",
    "            no_tokens_paragraph = len(tokens_paragraph[0])\n",
    "            \n",
    "            my_dic = {}\n",
    "\n",
    "            for character_tuple in characters:\n",
    "\n",
    "                character, grammatical_number = character_tuple\n",
    "\n",
    "                if grammatical_number == 'singular':\n",
    "                    to_be = 'is'\n",
    "                elif grammatical_number == 'plural':\n",
    "                    to_be = 'are'\n",
    "\n",
    "                question = \" Tell me where \" + character + \" \" + to_be + \" at this point in the story.\"\n",
    "                question_tokens = tokenizer.encode(question, return_tensors=\"pt\")\n",
    "                no_question_tokens = len(question_tokens[0])\n",
    "                \n",
    "                prompts = []\n",
    "                \n",
    "                if check == 1:\n",
    "\n",
    "                    no_tokens_left = max_no_tokens - no_question_tokens - no_tokens_starting_prompt\n",
    "\n",
    "                    if no_tokens_left < no_tokens_paragraph:\n",
    "\n",
    "                        print(\"CUTTING ALERT!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "                        cutting = len(paragraph) // 2\n",
    "                        x = paragraph[cutting:].find(\".\") + cutting + 1\n",
    "                        paragraph1 = paragraph[0:x]\n",
    "                        paragraph2 = paragraph[x:]\n",
    "                        prompt1 = starting_prompt + paragraph1 + question\n",
    "                        prompt2 = paragraph2 + question\n",
    "                        prompts.append(prompt1)\n",
    "                        prompts.append(prompt2)\n",
    "\n",
    "                    else: \n",
    "\n",
    "                        prompt = starting_prompt + paragraph + question\n",
    "                        prompts.append(prompt)\n",
    "\n",
    "                    check = 0\n",
    "\n",
    "                else:\n",
    "\n",
    "                    no_tokens_left = max_no_tokens - no_question_tokens\n",
    "\n",
    "                    if no_tokens_left < no_tokens_paragraph:\n",
    "\n",
    "                        print(\"CUTTING ALERT!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "                        cutting = len(paragraph) // 2\n",
    "                        x = paragraph[cutting:].find(\".\") + cutting + 1\n",
    "                        paragraph1 = paragraph[0:x]\n",
    "                        paragraph2 = paragraph[x:]\n",
    "                        prompt1 = paragraph1 + question\n",
    "                        prompt2 = paragraph2 + question\n",
    "                        prompts.append(prompt1)\n",
    "                        prompts.append(prompt2)\n",
    "\n",
    "                    else: \n",
    "\n",
    "                        prompt = paragraph + question\n",
    "                        prompts.append(prompt)       \n",
    "                \n",
    "                for prompt in prompts:\n",
    "                    \n",
    "                    tokens_prompt = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "                    tokens_prompt = tokens_prompt.to(\"cuda:0\")\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model.generate(tokens_prompt)   \n",
    "\n",
    "                    out = tokenizer.decode(outputs[0], skip_special_tokens=True)                \n",
    "                    my_dic[prompt] = [character, out]\n",
    "\n",
    "                    m3_predictions[item][prompt] = out\n",
    "\n",
    "            df = pd.DataFrame(data=my_dic, index=[\"Character\", \"Output\"])\n",
    "            df = (df.T)\n",
    "            df.to_excel(writer, sheet_name=\"Paragraph \" + str(i+1))\n",
    "            worksheet = writer.sheets[\"Paragraph \" + str(i+1)]\n",
    "\n",
    "            for idx, col in enumerate(df):\n",
    "                max_len = 75\n",
    "                worksheet.set_column(idx, idx, max_len, format)\n",
    "                    \n",
    "        writer.save()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b78244-0397-45ab-8ca9-01b78e5d5c77",
   "metadata": {},
   "source": [
    "# Recency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a0a7929-c5dc-4cc2-8b84-fe42145c173e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dir_list_andersen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m match_abs_inv_recency \u001b[38;5;241m=\u001b[39m [ [] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m24\u001b[39m)]\n\u001b[1;32m      4\u001b[0m non_match_abs_inv_recency \u001b[38;5;241m=\u001b[39m [ [] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m24\u001b[39m)]\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdir_list_andersen\u001b[49m:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m dir_list_annotations:\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(item)        \n",
      "\u001b[0;31mNameError\u001b[0m: name 'dir_list_andersen' is not defined"
     ]
    }
   ],
   "source": [
    "match_loc_mentions = {}\n",
    "non_match_loc_mentions = {}\n",
    "match_abs_inv_recency = [ [] for _ in range(1,24)]\n",
    "non_match_abs_inv_recency = [ [] for _ in range(1,24)]\n",
    "\n",
    "for item in dir_list_andersen:\n",
    "    \n",
    "    if item in dir_list_annotations:\n",
    "        \n",
    "        print(item)        \n",
    "\n",
    "        match_loc_mentions[item] = [ [] for _ in range(1,24)]\n",
    "        non_match_loc_mentions[item] = [ [] for _ in range(1,24)]\n",
    "        \n",
    "        f = open(os.path.join(path_andersen, item), 'r') \n",
    "        story = f.read()\n",
    "        f.close()\n",
    "        \n",
    "        f = open(os.path.join(path_annotations, item), 'r')\n",
    "        annotations = pd.read_csv(f, sep=\"\\t\")\n",
    "        annotations = annotations.values\n",
    "        f.close()\n",
    "        \n",
    "        i = 0\n",
    "    \n",
    "        for line in annotations:\n",
    "            \n",
    "            character = line[1]\n",
    "            gold_answer = line[2]\n",
    "            grammatical_number = line[3]\n",
    "\n",
    "            gold_locations = gold_answer.split(\"/\")\n",
    "            \n",
    "            for k in range(1, 24):\n",
    "                \n",
    "                y = line[0]\n",
    "                x = y - 5120\n",
    "\n",
    "                if x < 0:\n",
    "                    text = story[0:y]\n",
    "\n",
    "                else:\n",
    "                    x = story[x:y].find(\" \") + x\n",
    "                    text = story[x:y]\n",
    "\n",
    "                text = text.rstrip(\", ;-\\n\")\n",
    "                if text[-1] != \".\":\n",
    "                    text += \".\"\n",
    "                text_list = text.split(\"\\n\\n\")\n",
    "                new_text_list = []                \n",
    "                for element in text_list:\n",
    "                    new_text_list.append(element.replace(\"\\n\", \" \"))\n",
    "                text = \"\\n\".join(new_text_list)\n",
    "                prompt, context = create_prompt_clipped(k, text, character, grammatical_number, 1024) \n",
    "                pred_locs = m4_predictions[item][k-1]\n",
    "                pred_tokenized = word_tokenize(pred_locs[i].lower())\n",
    "                new_pred_tokens = [ token for token in pred_tokenized if token not in stop_words ]\n",
    "                pred_wo_stop_words = \" \".join(new_pred_tokens) \n",
    "                \n",
    "                match = False\n",
    "                \n",
    "                matches = [False for _ in range(len(gold_locations))]\n",
    "                distances = [1e9 for _ in range(len(gold_locations))]\n",
    "                for num_loc, gold_location in enumerate(gold_locations):\n",
    "                    \n",
    "                    gold_tokenized = word_tokenize(gold_location.lower())\n",
    "                    new_gold_tokens = [ token for token in gold_tokenized if token not in stop_words ]\n",
    "                    gold_wo_stop_words = \" \".join(new_gold_tokens)\n",
    "                    \n",
    "                    loc_mention = prompt.rfind(gold_location)\n",
    "                    \n",
    "                    if loc_mention != -1:\n",
    "                        \n",
    "                        loc_mention += len(gold_location)\n",
    "                        abs_inv_recency = len(prompt) - loc_mention\n",
    "                        \n",
    "                        distances[num_loc] = abs_inv_recency\n",
    "                            \n",
    "                        if gold_wo_stop_words == pred_wo_stop_words:\n",
    "                            matches[num_loc] = True\n",
    "                            \n",
    "                if sum(matches) > 0:\n",
    "                    \n",
    "                    matched_distances = [distances[num_loc] for num_loc in range(len(distances)) if matches[num_loc] == True]\n",
    "                    if matched_distances == []:\n",
    "                        abs_inv_recency = min(distances)\n",
    "                    else:\n",
    "                        abs_inv_recency = min(matched_distances)\n",
    "                    \n",
    "                    match_loc_mentions[item][k-1].append(abs_inv_recency)\n",
    "                    match_abs_inv_recency[k-1].append(abs_inv_recency)\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    if not min(distances) < 1e8:\n",
    "                        pass\n",
    "                    else:\n",
    "                        abs_inv_recency = min(matched_distances)                        \n",
    "                        non_match_loc_mentions[item][k-1].append(abs_inv_recency)\n",
    "                        non_match_abs_inv_recency[k-1].append(abs_inv_recency)\n",
    "                \n",
    "            \n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "82d2067a-7ca1-4854-9a46-8556459632d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(match_abs_inv_recency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "8ec36ae6-86e6-4036-9f8d-6b72b86b3378",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_no = 13\n",
    "loc_mention_graph = []\n",
    "\n",
    "for dist in match_abs_inv_recency[prompt_no-1]:\n",
    "    loc_mention_graph.append((dist, 1))\n",
    "    \n",
    "for dist in non_match_abs_inv_recency[prompt_no-1]:\n",
    "    loc_mention_graph.append((dist, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "6c6a63c9-1013-48b7-ae81-aa279c512269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "667.5952380952381"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(match_abs_inv_recency[prompt_no-1])/len(match_abs_inv_recency[prompt_no-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "7802334a-6fd2-433c-af12-50e88da5eed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497.5238095238095"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(non_match_abs_inv_recency[prompt_no-1])/len(non_match_abs_inv_recency[prompt_no-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "09b6d6df-3d9d-4627-bed6-2a12e503110d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_distances = [x[0] for x in loc_mention_graph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "18194344-8e1f-4cf9-b761-550e7b63e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_distances = sorted(all_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3a1e0baa-f0da-4552-b710-97947aa1276f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(all_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ae6ce5d9-05ee-4031-b69d-6cfe0d7e3e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3451"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_distances[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "171e9fb2-c8be-4f3c-a0c5-7911ad45850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "421824ac-553f-4152-a378-de26e2665294",
   "metadata": {},
   "outputs": [],
   "source": [
    "grap = defaultdict(list)\n",
    "for tupl in loc_mention_graph:\n",
    "    for i in range(10):\n",
    "        if 350*i<=tupl[0]<350*i+350:\n",
    "            grap[i].append(tupl)\n",
    "for i in range(10):\n",
    "    if len(grap[i]) != 0 and len(grap[i]) > 5:\n",
    "        grap[i] = sum([tupl[1] == 1 for tupl in grap[i]]) / len(grap[i]) * 100\n",
    "    else:\n",
    "        grap[i] = 0\n",
    "grap_tuples = [(key, grap[key]) for key in grap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "ed6e6e97-6d17-4296-93c1-9262ee336e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x2b5f830886d0>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f830886a0>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f83083d00>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f830c9430>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f830c9940>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f830c9e50>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f830d13a0>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f830d18b0>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f830d1dc0>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f830d7310>],\n",
       " [Text(0, 0, '0-350'),\n",
       "  Text(1, 0, '350-700'),\n",
       "  Text(2, 0, '700-1050'),\n",
       "  Text(3, 0, ''),\n",
       "  Text(4, 0, '1400-1750'),\n",
       "  Text(5, 0, ''),\n",
       "  Text(6, 0, '2100-2450'),\n",
       "  Text(7, 0, ''),\n",
       "  Text(8, 0, ''),\n",
       "  Text(9, 0, '3150-3500')])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(*zip(*grap_tuples))\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.xticks(np.arange(10), ['0-350', '350-700', '700-1050', \"\", \"1400-1750\",\"\", \"2100-2450\", \"\", \"\", \"3150-3500\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4fa5b932-3928-4cc6-afc4-aab7e770b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "eedd429d-47cf-496e-a465-6f992fad1a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x2b5f73b89740>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(*loc_mention_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe01fe0-7cbe-4288-a275-d6190e2fa681",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(*zip(*loc_mention_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c85c2efe-e136-41aa-aa0a-f8439578bb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pos = np.arange(len(loc_mention_graph)) \n",
    "plt.bar(y_pos, [x[1] for x in loc_mention_graph], align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, [x[0] for x in loc_mention_graph])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6239ba0d-bb8e-454b-9356-3aac82fc1490",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b774a66e-b06f-4d8c-9ac7-92a35e22ea33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a32a6c0b-4c6e-4b63-80fe-c500e882b484",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[153,\n",
       " 181,\n",
       " 470,\n",
       " 106,\n",
       " 136,\n",
       " 105,\n",
       " 107,\n",
       " 104,\n",
       " 101,\n",
       " 108,\n",
       " 112,\n",
       " 112,\n",
       " 111,\n",
       " 102,\n",
       " 107,\n",
       " 174,\n",
       " 2356,\n",
       " 106,\n",
       " 243,\n",
       " 666,\n",
       " 1499,\n",
       " 2705,\n",
       " 133,\n",
       " 145,\n",
       " 337,\n",
       " 3451,\n",
       " 103,\n",
       " 620,\n",
       " 1502,\n",
       " 135,\n",
       " 1970,\n",
       " 3371,\n",
       " 123,\n",
       " 102,\n",
       " 117,\n",
       " 76,\n",
       " 110,\n",
       " 157,\n",
       " 2155,\n",
       " 3235,\n",
       " 3220,\n",
       " 105,\n",
       " 105,\n",
       " 158,\n",
       " 141,\n",
       " 134,\n",
       " 162,\n",
       " 107,\n",
       " 1596,\n",
       " 99,\n",
       " 110,\n",
       " 101,\n",
       " 104,\n",
       " 160,\n",
       " 97,\n",
       " 249,\n",
       " 98,\n",
       " 142,\n",
       " 104,\n",
       " 3146,\n",
       " 152,\n",
       " 461,\n",
       " 1040,\n",
       " 1126,\n",
       " 120,\n",
       " 106,\n",
       " 103,\n",
       " 179,\n",
       " 105,\n",
       " 1929,\n",
       " 1953,\n",
       " 112,\n",
       " 744,\n",
       " 1169,\n",
       " 126,\n",
       " 2319,\n",
       " 2400,\n",
       " 3027,\n",
       " 108,\n",
       " 110,\n",
       " 140,\n",
       " 362,\n",
       " 113,\n",
       " 230,\n",
       " 4]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(match_abs_inv_recency[12] + [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "017b7f2f-849c-4aa0-900d-3279beda75aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_loc_recency = {}\n",
    "for k, prompt_distances in enumerate(match_abs_inv_recency):\n",
    "    match_loc_recency[k+1] = sum(prompt_distances)/len(prompt_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c784090d-f74f-4974-b768-e36a6568d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_match_loc_recency = {}\n",
    "for k, prompt_distances in enumerate(non_match_abs_inv_recency):\n",
    "    non_match_loc_recency[k+1] = sum(prompt_distances)/len(prompt_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "47915d00-f660-4fbc-91f8-56b3bea3a983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "75\n",
      "79\n",
      "28\n",
      "25\n",
      "78\n",
      "22\n",
      "26\n",
      "68\n",
      "82\n",
      "69\n",
      "80\n",
      "84\n",
      "70\n",
      "69\n",
      "65\n",
      "84\n",
      "71\n",
      "70\n",
      "74\n",
      "76\n",
      "68\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "for key in match_abs_inv_recency:\n",
    "    print(len(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "87963283-7d88-4489-9c49-13173dc23622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n",
      "135\n",
      "131\n",
      "182\n",
      "185\n",
      "132\n",
      "188\n",
      "184\n",
      "142\n",
      "128\n",
      "141\n",
      "130\n",
      "126\n",
      "140\n",
      "141\n",
      "145\n",
      "126\n",
      "139\n",
      "140\n",
      "136\n",
      "134\n",
      "142\n",
      "145\n"
     ]
    }
   ],
   "source": [
    "for key in non_match_abs_inv_recency:\n",
    "    print(len(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a605ba-66ed-4806-b878-a8fe19bab6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acd036f3-c97b-42e5-b795-a369a81829df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andersen_story2.txt\n"
     ]
    }
   ],
   "source": [
    "for item in dir_list_andersen:\n",
    "    \n",
    "    if item in dir_list_annotations:\n",
    "        \n",
    "        print(item)        \n",
    "        \n",
    "        f = open(os.path.join(path_andersen, item), 'r') \n",
    "        story = f.read()\n",
    "        f.close()\n",
    "        \n",
    "        f = open(os.path.join(path_annotations, item), 'r')\n",
    "        annotations = pd.read_csv(f, sep=\"\\t\")\n",
    "        annotations = annotations.values\n",
    "        f.close()\n",
    "        \n",
    "        break\n",
    "        i = 0\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3635d56d-26cf-4f7c-94ea-082f50b48277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6606, 'the emperor', 'the balcony', 'singular'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fab0bf1-1ae9-4c23-8c90-d41e8e5a6a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2f2527d-a8cf-4eb3-9aef-52850abd066d",
   "metadata": {},
   "source": [
    "# Character Mention - Location Mention Distance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "519381f3-1227-41e4-a8f1-899a2c14c5fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andersen_story2.txt\n",
      "Andersen_story8.txt\n",
      "Andersen_story11.txt\n",
      "Andersen_story7.txt\n",
      "Andersen_story17.txt\n",
      "Andersen_story15.txt\n",
      "Andersen_story9.txt\n",
      "Andersen_story5.txt\n",
      "Andersen_story1.txt\n",
      "Andersen_story12.txt\n",
      "Andersen_story16.txt\n",
      "Andersen_story18.txt\n",
      "Andersen_story3.txt\n",
      "Andersen_story10.txt\n",
      "Andersen_story13.txt\n"
     ]
    }
   ],
   "source": [
    "match_distances = []\n",
    "non_match_distances = []\n",
    "\n",
    "for item in dir_list_andersen:\n",
    "    \n",
    "    if item in dir_list_annotations:\n",
    "        \n",
    "        print(item)        \n",
    "        f = open(os.path.join(path_andersen, item), 'r') \n",
    "        story = f.read()\n",
    "        f.close()\n",
    "        \n",
    "        f = open(os.path.join(path_annotations, item), 'r')\n",
    "        annotations = pd.read_csv(f, sep=\"\\t\")\n",
    "        annotations = annotations.values\n",
    "        f.close()\n",
    "        \n",
    "        i = 0\n",
    "    \n",
    "        for line in annotations:\n",
    "            \n",
    "            character = line[1]\n",
    "            gold_answer = line[2]\n",
    "            grammatical_number = line[3]\n",
    "\n",
    "            gold_locations = gold_answer.split(\"/\")\n",
    "            \n",
    "            for k in range(1, 24):\n",
    "                \n",
    "                y = line[0]\n",
    "                x = y - 5120\n",
    "\n",
    "                if x < 0:\n",
    "                    text = story[0:y]\n",
    "\n",
    "                else:\n",
    "                    x = story[x:y].find(\" \") + x\n",
    "                    text = story[x:y]\n",
    "\n",
    "                text = text.rstrip(\", ;-\\n\")\n",
    "                if text[-1] != \".\":\n",
    "                    text += \".\"\n",
    "                text_list = text.split(\"\\n\\n\")\n",
    "                new_text_list = []                \n",
    "                for element in text_list:\n",
    "                    new_text_list.append(element.replace(\"\\n\", \" \"))\n",
    "                text = \"\\n\".join(new_text_list)\n",
    "                prompt, context = create_prompt_clipped(k, text, character, grammatical_number, 1024) \n",
    "                pred_locs = m4_predictions[item][k-1]\n",
    "                pred_tokenized = word_tokenize(pred_locs[i].lower())\n",
    "                new_pred_tokens = [ token for token in pred_tokenized if token not in stop_words ]\n",
    "                pred_wo_stop_words = \" \".join(new_pred_tokens) \n",
    "                               \n",
    "                for gold_location in gold_locations:\n",
    "                    \n",
    "                    gold_tokenized = word_tokenize(gold_location.lower())\n",
    "                    new_gold_tokens = [ token for token in gold_tokenized if token not in stop_words ]\n",
    "                    gold_wo_stop_words = \" \".join(new_gold_tokens)\n",
    "                    \n",
    "                    loc_mention = context.rfind(gold_location)                    \n",
    "                \n",
    "                    if loc_mention != -1:\n",
    "                        \n",
    "                        char_mention_left = context[:loc_mention].rfind(character)                        \n",
    "                        char_mention_right = context[loc_mention+len(gold_location):].find(character)\n",
    "                        \n",
    "                        if char_mention_left != -1:\n",
    "                            distance_left = loc_mention - (char_mention_left + len(character))\n",
    "                            \n",
    "                        if char_mention_right != -1:\n",
    "                            distance_right = char_mention_right\n",
    "                            \n",
    "                        if char_mention_left != -1 and char_mention_right != -1:\n",
    "                            \n",
    "                            if distance_left > distance_right:\n",
    "                                distance = distance_right\n",
    "                            else:\n",
    "                                distance = distance_left\n",
    "                                \n",
    "                        elif char_mention_left != -1:\n",
    "                            distance = distance_left\n",
    "                        elif char_mention_right != -1:\n",
    "                            distance = distance_right\n",
    "                        else:\n",
    "                            distance = -1\n",
    "                        \n",
    "                        if distance != -1:        \n",
    "                            \n",
    "                            if gold_wo_stop_words == pred_wo_stop_words:\n",
    "                                match_distances.append(distance)\n",
    "\n",
    "                            else:\n",
    "                                non_match_distances.append(distance)\n",
    "                   # else:\n",
    "                   #     abs_inv_recency = -1\n",
    "\n",
    "                    \n",
    "            \n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "465fa03f-6b1d-4224-8280-815f30b6b25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312.51221001221"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(match_distances)/len(match_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c4fc55be-76fe-4284-b637-438ef8d6f200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536.8461710954143"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(non_match_distances)/len(non_match_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "42737bdd-b38c-48d4-885e-b5d2ee187f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "charloc_mention_graph = []\n",
    "\n",
    "for dist in match_distances:\n",
    "    charloc_mention_graph.append((dist, 1))\n",
    "    \n",
    "for dist in non_match_distances:\n",
    "    charloc_mention_graph.append((dist, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "aa306db7-8388-4d4d-adcb-826cd5b87e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4120"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(non_match_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "9701ee07-2786-43a8-8f23-6fe439377e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "grap = defaultdict(list)\n",
    "for tupl in charloc_mention_graph:\n",
    "    for i in range(10):\n",
    "        if 420*i<=tupl[0]<420*i+420:\n",
    "            grap[i].append(tupl)\n",
    "for i in range(10):\n",
    "    if len(grap[i]) != 0:# and len(grap[i]) > 5:\n",
    "        grap[i] = sum([tupl[1] == 1 for tupl in grap[i]]) / len(grap[i]) * 100\n",
    "    else:\n",
    "        grap[i] = 0\n",
    "grap_tuples = [(key, grap[key]) for key in grap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "d80a7f39-559c-4542-ac7a-a76716c6eff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x2b5f831a5fa0>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f831a5f70>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f831a5670>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f831e0d60>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f831ef2b0>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f831ef7c0>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f831efcd0>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f831f4220>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f831f4730>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f831f4c40>],\n",
       " [Text(0, 0, '210'),\n",
       "  Text(1, 0, '630'),\n",
       "  Text(2, 0, '1050'),\n",
       "  Text(3, 0, '1470'),\n",
       "  Text(4, 0, '1890'),\n",
       "  Text(5, 0, '2310'),\n",
       "  Text(6, 0, '2730'),\n",
       "  Text(7, 0, '3150'),\n",
       "  Text(8, 0, '3570'),\n",
       "  Text(9, 0, '3990')])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(*zip(*grap_tuples))\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.xticks(np.arange(10), ['210', '630', '1050', \"1470\", \"1890\",\"2310\", \"2730\", \"3150\", \"3570\", \"3990\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76730545-d176-45d0-90d4-414eb4a01e17",
   "metadata": {},
   "source": [
    "# Character Mention Recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "3778aa2e-634e-4b7a-aea7-fdbffc682107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andersen_story2.txt\n",
      "Andersen_story8.txt\n",
      "Andersen_story11.txt\n",
      "Andersen_story7.txt\n",
      "Andersen_story17.txt\n",
      "Andersen_story15.txt\n",
      "Andersen_story9.txt\n",
      "Andersen_story5.txt\n",
      "Andersen_story1.txt\n",
      "Andersen_story12.txt\n",
      "Andersen_story16.txt\n",
      "Andersen_story18.txt\n",
      "Andersen_story3.txt\n",
      "Andersen_story10.txt\n",
      "Andersen_story13.txt\n"
     ]
    }
   ],
   "source": [
    "match_char_recency_dic = {}\n",
    "non_match_char_recency_dic = {}\n",
    "\n",
    "match_char_recency = [ [] for _ in range(1,24)]\n",
    "non_match_char_recency = [ [] for _ in range(1,24)]\n",
    "\n",
    "for item in dir_list_andersen:\n",
    "    \n",
    "    if item in dir_list_annotations:\n",
    "        \n",
    "        print(item)\n",
    "\n",
    "        match_char_recency_dic[item] = [ [] for _ in range(1,24)]\n",
    "        non_match_char_recency_dic[item] = [ [] for _ in range(1,24)]\n",
    "        \n",
    "        f = open(os.path.join(path_andersen, item), 'r') \n",
    "        story = f.read()\n",
    "        f.close()\n",
    "        \n",
    "        f = open(os.path.join(path_annotations, item), 'r')\n",
    "        annotations = pd.read_csv(f, sep=\"\\t\")\n",
    "        annotations = annotations.values\n",
    "        f.close()\n",
    "        \n",
    "        i = 0\n",
    "    \n",
    "        for line in annotations:\n",
    "            \n",
    "            character = line[1]\n",
    "            gold_answer = line[2]\n",
    "            grammatical_number = line[3]\n",
    "\n",
    "            gold_locations = gold_answer.split(\"/\")\n",
    "            \n",
    "            for k in range(1, 24):\n",
    "                \n",
    "                y = line[0]\n",
    "                x = y - 5120\n",
    "\n",
    "                if x < 0:\n",
    "                    text = story[0:y]\n",
    "                else:\n",
    "                    x = story[x:y].find(\" \") + x\n",
    "                    text = story[x:y]\n",
    "\n",
    "                text = text.rstrip(\", ;-\\n\")\n",
    "                if text[-1] != \".\":\n",
    "                    text += \".\"\n",
    "                text_list = text.split(\"\\n\\n\")\n",
    "                new_text_list = []                \n",
    "                for element in text_list:\n",
    "                    new_text_list.append(element.replace(\"\\n\", \" \"))                    \n",
    "                text = \"\\n\".join(new_text_list)\n",
    "                \n",
    "                prompt, context = create_prompt_clipped(k, text, character, grammatical_number, 1024) \n",
    "                pred_locs = m4_predictions[item][k-1]\n",
    "                pred_tokenized = word_tokenize(pred_locs[i].lower())\n",
    "                new_pred_tokens = [ token for token in pred_tokenized if token not in stop_words ]\n",
    "                pred_wo_stop_words = \" \".join(new_pred_tokens) \n",
    "                                \n",
    "                match = False\n",
    "                char_mention = context.rfind(character)\n",
    "                \n",
    "                for num_loc, gold_location in enumerate(gold_locations):\n",
    "                    \n",
    "                    gold_tokenized = word_tokenize(gold_location.lower())\n",
    "                    new_gold_tokens = [ token for token in gold_tokenized if token not in stop_words ]\n",
    "                    gold_wo_stop_words = \" \".join(new_gold_tokens)\n",
    "                    \n",
    "                    if gold_wo_stop_words == pred_wo_stop_words:\n",
    "                        match = True\n",
    "                            \n",
    "                if char_mention != -1:\n",
    "                    char_mention += len(character)\n",
    "                    char_recency = len(context) - char_mention\n",
    "                    if match:\n",
    "                        match_char_recency_dic[item][k-1].append(char_recency)\n",
    "                        match_char_recency[k-1].append(char_recency)\n",
    "                    else:\n",
    "                        non_match_char_recency_dic[item][k-1].append(char_recency)\n",
    "                        non_match_char_recency[k-1].append(char_recency)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "3bebd224-9117-445b-9242-38f9c30d6af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_no = 1\n",
    "char_mention_graph = []\n",
    "\n",
    "for dist in match_char_recency[prompt_no-1]:\n",
    "    char_mention_graph.append((dist, 1))    \n",
    "\n",
    "for dist in non_match_char_recency[prompt_no-1]:\n",
    "    char_mention_graph.append((dist, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "5dd638b4-e1b3-4fda-836d-124d3bb3bcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3041"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d4197914-96c0-4c09-9db7-27d80f65fb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3075"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "48c00ec8-4cc9-4479-bdac-2571e74e2c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "7f130e5b-f402-45ad-8f5e-c4b200d8fbd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(char_mention_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d4a4f708-97e7-43de-b185-6fa7fb9277a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3633, 0)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(char_mention_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "03128d27-6a7b-41d4-8002-db0f3bf91283",
   "metadata": {},
   "outputs": [],
   "source": [
    "grap = defaultdict(list)\n",
    "for tupl in char_mention_graph:\n",
    "    for i in range(4):\n",
    "        if 80*i<=tupl[0]<80*i+80:\n",
    "            grap[i].append(tupl)\n",
    "for i in range(4):\n",
    "    if len(grap[i]) > 6:\n",
    "        grap[i] = sum([tupl[1] == 1 for tupl in grap[i]]) / len(grap[i]) * 100\n",
    "    else:\n",
    "        grap[i] = 0\n",
    "grap_tuples = [(key, grap[key]) for key in grap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "11fbdcad-5016-40a5-9163-4c2af9ab4189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x2b5f832823d0>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f832823a0>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f8327aac0>,\n",
       "  <matplotlib.axis.XTick at 0x2b5f832b2280>],\n",
       " [Text(0, 0, '0-79'),\n",
       "  Text(1, 0, '80-159'),\n",
       "  Text(2, 0, '160-239'),\n",
       "  Text(3, 0, '240-299')])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(*zip(*grap_tuples))\n",
    "plt.xlabel(\"distance\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.xticks(np.arange(4), ['0-79', '80-159', '160-239', \"240-299\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "20de0fb9-f049-49bb-9066-02157ee4a33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '')"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(*zip(*grap_tuples))\n",
    "plt.xlabel(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792e5402-d2fc-40f5-aff2-73394d9bedc3",
   "metadata": {},
   "source": [
    "# (Unnecessary) Other Way of Creating Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a048622-b310-4624-82f1-d8f6803222ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def create_prompt(version, context, character, grammatical_number):\n",
    "    \n",
    "    if grammatical_number == 'singular':\n",
    "        to_be = 'is'\n",
    "    elif grammatical_number == 'plural':\n",
    "        to_be = 'are'\n",
    "    \n",
    "    if version in [1, 2, 9, 10, 11, 12, 13, 20, 21, 22]:\n",
    "        question = \"Where \" + to_be + \" \" + character + \" in the end?\"\n",
    "    elif version in [4, 5, 7, 8, 15, 16, 18, 19]:\n",
    "        question = \"where \" + character + \" \" + to_be + \" in the end.\"\n",
    "    elif version in [3, 14]:\n",
    "        question = \"where \" + character + \" \" + to_be + \" in the end?\"\n",
    "    elif version in [6, 17]:\n",
    "        question = \"where \" + to_be + \" \" + character + \" in the end?\"\n",
    "        \n",
    "    if version == 1 or version == 12:\n",
    "        intro = \"Answer the question depending on the context.\"\n",
    "    elif version == 2 or version == 13:\n",
    "        intro = \"What is the answer?\"\n",
    "    elif version == 3 or version == 14:\n",
    "        intro = \"Can you tell me \"\n",
    "    elif version == 4 or version == 15:\n",
    "        intro = \"Please tell me \"\n",
    "    elif version == 5 or version == 16:\n",
    "        intro = \"Tell me \"\n",
    "    elif version == 6 or version == 17:\n",
    "        intro = \"From the passage, \"\n",
    "    elif version == 7 or version == 18:\n",
    "        intro = \"I want to know \"\n",
    "    elif version == 8 or version == 19:\n",
    "        intro = \"I want to ask \"\n",
    "    elif version == 9 or version == 20:\n",
    "        intro = \"What is the answer to: \"\n",
    "    elif version == 10 or version == 21:\n",
    "        intro = \"Find the answer to: \"\n",
    "    elif version == 11 or version == 22:\n",
    "        intro = \"Answer: \"\n",
    "        \n",
    "    if version in [1, 2]:\n",
    "        tm = Template(\"\"\"{{ intro }}\n",
    "Context: {{context}};\n",
    "Question: {{question}};\n",
    "Answer: \"\"\")\n",
    "        prompt = tm.render(intro=intro, context=context, question=question)\n",
    "    elif version in [3, 4, 5, 6, 7, 8, 9, 10, 11]:\n",
    "        tm = Template(\"{{context}} {{intro}}{{question}}\")\n",
    "        prompt = tm.render(intro=intro, context=context, question=question)\n",
    "    if version in [12, 13]:\n",
    "        tm = Template(\"\"\"{{ intro }}\n",
    "Context: {{context}};\n",
    "Question: {{question}};\n",
    "If you can't find the answer, please respond \"unanswerable\".\n",
    "Answer: \"\"\")\n",
    "        prompt = tm.render(intro=intro, context=context, question=question)\n",
    "    elif version in [14, 15, 16, 17, 18, 19, 20, 21, 22]:\n",
    "        tm = Template('{{context}} {{intro}}{{question}} If you can\\'t find the answer, please respond \"unanswerable\".\"')\n",
    "        prompt = tm.render(intro=intro, context=context, question=question) \n",
    "        \n",
    "    return prompt\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cba622-19fe-4c30-878f-0a7fdc1b2a1f",
   "metadata": {},
   "source": [
    "# (Unnecessary) Minibatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55204131-78de-4d2d-9856-d444f3cc4049",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = {}\n",
    "\n",
    "for item in dir_list_andersen:\n",
    "    \n",
    "    if item in dir_list_annotations:\n",
    "        \n",
    "        f = open(os.path.join(path_andersen, item), 'r') \n",
    "        story = f.read()\n",
    "        f.close()\n",
    "        \n",
    "        all_tokens[item] = []\n",
    "        \n",
    "        y = 0\n",
    "        \n",
    "        len_story = len(story)\n",
    "        \n",
    "        while y+530 <= len_story:\n",
    "            \n",
    "            x = story[y+500:y+530].find(\" \") + (y + 500)\n",
    "            to_be_tokenized = story[y:x]\n",
    "            inputs = tokenizer.encode(to_be_tokenized, return_tensors=\"pt\")\n",
    "            all_tokens[item].extend(inputs)\n",
    "            y = x\n",
    "            \n",
    "        to_be_tokenized = story[y:]\n",
    "        inputs = tokenizer.encode(to_be_tokenized, return_tensors=\"pt\")\n",
    "        all_tokens[item].extend(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eaf8c082-8234-4216-8f85-0a86cab275ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatches = {}\n",
    "\n",
    "for item in all_tokens:\n",
    "    \n",
    "    my_tensor = all_tokens[item][0]\n",
    "    \n",
    "    for i in range(len(all_tokens[item])-1):\n",
    "        my_tensor = torch.cat((my_tensor, all_tokens[item][i+1]), dim=0)\n",
    "    \n",
    "    B = my_tensor.shape[0] // 512 + 1\n",
    "    padding = torch.zeros(512 - (my_tensor.shape[0] % 512)) \n",
    "    my_tensor = torch.cat((my_tensor, padding), dim=0)\n",
    "    minibatches[item] = my_tensor.reshape(B, 512)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "693dae17-f672-4ee8-8641-10cdec9c024f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 512])\n",
      "torch.Size([9, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([6, 512])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([6, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([9, 512])\n"
     ]
    }
   ],
   "source": [
    "for item in minibatches:\n",
    "    print(minibatches[item].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b3c4da-f8d7-48ad-bf63-33fd17e89a52",
   "metadata": {},
   "source": [
    "# (Unnecessary) Rouge Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0acb9800-f7f3-486e-832d-4d6e08aeb11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a335cad2-092e-4b59-8e97-a52c46ba4774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andersen_story2.txt\n",
      "Andersen_story8.txt\n",
      "Andersen_story7.txt\n",
      "Andersen_story9.txt\n",
      "Andersen_story1.txt\n",
      "Andersen_story3.txt\n",
      "Andersen_story10.txt\n",
      "Andersen_story4.txt\n"
     ]
    }
   ],
   "source": [
    "recall = []\n",
    "all_scores = []\n",
    "for item in predictions:\n",
    "    print(item)\n",
    "    pred_locs = predictions[item]\n",
    "    f = open(os.path.join(path_annotations, item), 'r')\n",
    "    annotations = pd.read_csv(f, sep=\"\\t\")\n",
    "    annotations = annotations.values #numpy array\n",
    "    f.close()\n",
    "    i = 0    \n",
    "    for line in annotations:\n",
    "        if line[2] == \"0\" or line[2] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            rouge_scores = rouge.get_scores(pred_locs[i], line[2])\n",
    "            all_scores.append(rouge_scores)\n",
    "            recall.append(rouge_scores[0]['rouge-1']['r'])\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b6c41fb-1573-4635-9676-c13bba384204",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_recall = []\n",
    "r1_precision = []\n",
    "r1_f = []\n",
    "r2_recall = []\n",
    "r2_precision = []\n",
    "r2_f = []\n",
    "rl_recall = []\n",
    "rl_precision = []\n",
    "rl_f = []\n",
    "\n",
    "for scores in all_scores:\n",
    "    r1_recall.append(scores[0][\"rouge-1\"][\"r\"])\n",
    "    r1_precision.append(scores[0][\"rouge-1\"][\"p\"])\n",
    "    r1_f.append(scores[0][\"rouge-1\"][\"f\"])\n",
    "    r2_recall.append(scores[0][\"rouge-2\"][\"r\"])\n",
    "    r2_precision.append(scores[0][\"rouge-2\"][\"p\"])\n",
    "    r2_f.append(scores[0][\"rouge-2\"][\"f\"])\n",
    "    rl_recall.append(scores[0][\"rouge-l\"][\"r\"])\n",
    "    rl_precision.append(scores[0][\"rouge-l\"][\"p\"])\n",
    "    rl_f.append(scores[0][\"rouge-l\"][\"f\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4d00f9f6-7f15-4ff2-b5ce-7fea65b82cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_recall_avg = sum(r1_recall)/len(r1_recall)\n",
    "r1_precision_avg = sum(r1_precision)/len(r1_precision)\n",
    "r1_f_avg = sum(r1_f)/len(r1_f)\n",
    "r2_recall_avg = sum(r2_recall)/len(r2_recall)\n",
    "r2_precision_avg = sum(r2_precision)/len(r2_precision)\n",
    "r2_f_avg = sum(r2_f)/len(r2_f)\n",
    "rl_recall_avg = sum(rl_recall)/len(rl_recall)\n",
    "rl_precision_avg = sum(rl_precision)/len(rl_precision)\n",
    "rl_f_avg = sum(rl_f)/len(rl_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8bac4829-dedc-4c38-9f6c-c2c741b95cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4278079710144929, 0.33635012330664493, 0.3433857255959268)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1_recall_avg, r1_precision_avg, r1_f_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8caf4e61-37a5-4582-aab3-85334013fe7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2423913043478261, 0.1527380228467185, 0.16400470156621647)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_recall_avg, r2_precision_avg, r2_f_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2e29458f-9e8a-4bc1-a79e-ab28ac3daae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4256340579710147, 0.33557372579111694, 0.3422415608362014)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl_recall_avg, rl_precision_avg, rl_f_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25dc3fb-79e1-4554-baf2-0ee48fbde4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(\"mymymymy.xlsx\", engine='xlsxwriter')\n",
    "my_dic = {\"first\": [\"second\", \"third\"], \"fourth\": [\"\"\"The Tree only came to himself when he was unloaded in a court-yard with\n",
    "the other trees, and heard a man say, “That one is splendid! We don't\n",
    "want the others.” Then two servants came in rich livery and carried the\n",
    "Fir Tree into a large and splendid drawing-room. Portraits were hanging\n",
    "on the walls, and near the white porcelain stove stood two large Chinese\n",
    "vases with lions on the covers. There, too, were large easy-chairs,\n",
    "silken sofas, large tables full of picture-books and full of toys, worth\n",
    "hundreds and hundreds of crowns--at least the children said so. And the\n",
    "Fir Tree was stuck upright in a cask that was filled with sand; but no\n",
    "one could see that it was a cask, for green cloth was hung all round it,\n",
    "and it stood on a large gaily-colored carpet. Oh! how the Tree quivered!\n",
    "What was to happen? The servants, as well as the young ladies, decorated\n",
    "it. On one branch there hung little nets cut out of colored paper, and\n",
    "each net was filled with sugarplums; and among the other boughs gilded\n",
    "apples and walnuts were suspended, looking as though they had grown\n",
    "there, and little blue and white tapers were placed among the leaves.\n",
    "Dolls that looked for all the world like men--the Tree had never beheld\n",
    "such before--were seen among the foliage, and at the very top a\n",
    "large star of gold tinsel was fixed. It was really splendid--beyond\n",
    "description splendid.\"\"\", \" love me\"]}\n",
    "df = pd.DataFrame(data=my_dic, index=[\"loo\",\"lee\"])\n",
    "df = (df.T)\n",
    "df.to_excel(writer, sheet_name=\"fifth\")\n",
    "worksheet = writer.sheets[\"fifth\"]\n",
    "workbook = writer.book\n",
    "format = workbook.add_format({'text_wrap': True})\n",
    "for idx, col in enumerate(df):\n",
    "    series = df[col]\n",
    "    max_len = 75\n",
    "    worksheet.set_column(idx, idx, max_len, format)\n",
    "\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
