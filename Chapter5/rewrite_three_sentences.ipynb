{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b771d45-8e5a-474d-963e-b689a537bb08",
   "metadata": {},
   "source": [
    "# Necessary Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a29b66c-06ac-4b12-b842-5b6fe4cbae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from jinja2 import Template\n",
    "import xmltodict\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import sys\n",
    "sys.path.append('/scratch/users/bozyurt20/hpc_run/utilities')\n",
    "sys.path.append(\"/scratch/users/bozyurt20/hpc_run/blobs/\")\n",
    "from util_research import *\n",
    "\n",
    "#from toy_dataset import contexts\n",
    "\n",
    "max_len = 512\n",
    "num_layers = 24\n",
    "d_model = 4096\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/T0pp\", truncation_side=\"right\", add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8a295e2f-bfdd-4f76-87d4-f92ce640df21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /kuacc/users/bozyurt20/.conda/envs/hf/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 110\n",
      "CUDA SETUP: Loading binary /kuacc/users/bozyurt20/.conda/envs/hf/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda110.so...\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0pp\", device_map=\"balanced\", load_in_8bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e55dabc3-2c7f-42bb-adfa-dd33b382591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_1 = [\"John\", \"Harry\", \"Andrew\"]\n",
    "names_2 = [\"Henry\", \"David\", \"Sophia\"]\n",
    "names_3 = [\"Olivia\", \"Emma\", \"Lisa\"]\n",
    "\n",
    "cities_1 = [\"London\", \"Paris\", \"Oslo\"]\n",
    "cities_2 = [\"Sydney\", \"Cairo\", \"Seoul\"]\n",
    "cities_3 = [\"Istanbul\", \"Beijing\", \"Rome\"]\n",
    "\n",
    "class DataSample_ThreeSentences():\n",
    "    def __init__(self, name_1, name_2, name_3, city_1, city_2, city_3):\n",
    "        self.name_1 = name_1\n",
    "        self.name_2 = name_2\n",
    "        self.name_3 = name_3\n",
    "        self.city_1 = city_1\n",
    "        self.city_2 = city_2\n",
    "        self.city_3 = city_3\n",
    "        self.prev_context = name_1 + \" travelled to \" + city_1 + \". \" + name_2 + \" travelled to \" + city_2 + \". \" + name_3 + \" travelled to \" + city_3 + \". Where did \" + name_3 + \" travel to?\" \n",
    "        self.current_context_1 = name_1 + \" met Lucas. Lucas was 30 years old. Where is \" + name_1 + \"?\"\n",
    "        self.current_context_2 = name_2 + \" met Lucas. Lucas was 30 years old. Where is \" + name_2 + \"?\"\n",
    "        self.current_context_3 = name_3 + \" met Lucas. Lucas was 30 years old. Where is \" + name_3 + \"?\"\n",
    "    \n",
    "    def add_prev_encoding(self, encoding):\n",
    "        self.prev_encoding = encoding\n",
    "    def add_current_encoding_1(self, encoding):\n",
    "        self.curr_encoding_1 = encoding\n",
    "    def add_current_encoding_2(self, encoding):\n",
    "        self.curr_encoding_2 = encoding\n",
    "    def add_current_encoding_3(self, encoding):\n",
    "        self.curr_encoding_3 = encoding\n",
    "    def add_generation(self, model_out):\n",
    "        self.model_out = model_out\n",
    "        \n",
    "class ThreeSentenceRewriteResultCase1():\n",
    "    def __init__ (self, context_1, context_2, generation_1, generation_2, generation_rewritten, answer_1, answer_2):\n",
    "        \n",
    "        #self.data_point_1 = data_point_1\n",
    "        #self.data_point_2 = data_point_2\n",
    "        self.context_1 = context_1\n",
    "        self.context_2 = context_2\n",
    "        self.generation_1 = generation_1\n",
    "        self.generation_2 = generation_2\n",
    "        self.generation_rewritten = generation_rewritten\n",
    "        self.answer_1 = answer_1\n",
    "        self.answer_2 = answer_2\n",
    "        \n",
    "class ThreeSentenceRewriteResultCase2():\n",
    "    def __init__ (self, context_1, context_2, generation_1, generation_2, generation_rewritten, answer_1, answer_2):\n",
    "        \n",
    "        #self.data_point_1 = data_point_1\n",
    "        #self.data_point_2 = data_point_2\n",
    "        self.context_1 = context_1\n",
    "        self.context_2 = context_2\n",
    "        self.generation_1 = generation_1\n",
    "        self.generation_2 = generation_2\n",
    "        self.generation_rewritten = generation_rewritten\n",
    "        self.answer_1 = answer_1\n",
    "        self.answer_2 = answer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "061b1975-73ef-477b-9457-ec091c433a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def case1_rewrite(pairs_to_observe, ids_to_move):\n",
    "    \n",
    "    case1_results = []\n",
    "\n",
    "    for sample_1, sample_2 in pairs_to_observe:\n",
    "\n",
    "        encoding_sample_1 = sample_1.prev_encoding\n",
    "\n",
    "        context_1 = sample_1.prev_context\n",
    "        context_2 = sample_2.prev_context\n",
    "        generation_1 = sample_1.model_out\n",
    "        generation_2 = sample_2.model_out\n",
    "        answer_1 = sample_1.city_3\n",
    "        answer_2 = sample_2.city_3\n",
    "\n",
    "        special_hidden = encoding_sample_1.special_hidden_states # 24 x (1, T, d)\n",
    "        len_input_ids = special_hidden[0].shape[1]\n",
    "        special_reformatted = torch.zeros(num_layers, len_input_ids, d_model) # (24, T, d)\n",
    "        for i, hidden in enumerate(special_hidden):\n",
    "            special_reformatted[i:i+1, :, :] = hidden\n",
    "\n",
    "        entities_hidden_states = special_reformatted[:, ids_to_move[0], :].unsqueeze(0) # 1, 24, d\n",
    "        \n",
    "        for tok_id in ids_to_move[1:]:\n",
    "            entity_hidden_states = special_reformatted[:, tok_id, :].unsqueeze(0) # 1, 24, d\n",
    "            entities_hidden_states = torch.cat((entities_hidden_states,\n",
    "                                                entity_hidden_states), dim=0)\n",
    "\n",
    "        input_ids = tokenizer.encode(context_2, return_tensors=\"pt\").to(model.encoder.device)\n",
    "        generation_rewritten = model.generate(input_ids=input_ids, \n",
    "                                             max_new_tokens=10,\n",
    "                                             entity_hidden_states=entities_hidden_states,\n",
    "                                             entity_inds=ids_to_move,\n",
    "                                             return_dict_in_generate=True, \n",
    "                                             output_scores=True)\n",
    "\n",
    "        case1_results.append(ThreeSentenceRewriteResultCase1(context_1, context_2, generation_1, generation_2, generation_rewritten, answer_1, answer_2))\n",
    "        \n",
    "    return case1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d161261b-56c4-4234-9a1b-942cfdcfc169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def case2_rewrite(pairs_to_observe, ids_to_move):\n",
    "\n",
    "    case2_results = []\n",
    "\n",
    "    for sample_1, sample_2 in pairs_to_observe:\n",
    "\n",
    "        encoding_sample_1 = sample_1.prev_encoding\n",
    "        encoding_sample_2 = sample_2.prev_encoding\n",
    "\n",
    "        context_1 = sample_1.prev_context\n",
    "        context_2 = sample_2.prev_context\n",
    "        generation_1 = sample_1.model_out\n",
    "        generation_2 = sample_2.model_out\n",
    "        answer_1 = sample_1.city_3\n",
    "        answer_2 = sample_2.city_3\n",
    "\n",
    "        encoding_sample_2_copy = copy.deepcopy(encoding_sample_2)\n",
    "\n",
    "        for i in ids_to_move:\n",
    "            encoding_sample_2_copy.last_hidden_state[:,i:i+1,:] = encoding_sample_1.last_hidden_state[:,i:i+1,:]\n",
    "        \n",
    "        generation_rewritten = model.generate(encoder_outputs=encoding_sample_2_copy, \n",
    "                                               max_new_tokens=10,\n",
    "                                               return_dict_in_generate=True, \n",
    "                                               output_scores=True)\n",
    "        case2_results.append(ThreeSentenceRewriteResultCase2(context_1, context_2, generation_1, generation_2, generation_rewritten, answer_1, answer_2))\n",
    "        \n",
    "    return case2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb2ee1-1c8e-443c-955e-22c81e8ffd31",
   "metadata": {},
   "source": [
    "# Case 1 Pre-Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad7ed818-5150-411f-a98a-65bff9e897c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points_three_sentences_case1 = []\n",
    "for name_1 in names_1:\n",
    "    for name_2 in names_2:\n",
    "        for name_3 in names_3:\n",
    "            for city_1 in cities_1:\n",
    "                for city_2 in cities_2:\n",
    "                    for city_3 in cities_3:\n",
    "                        sample = DataSample_ThreeSentences(name_1, name_2, name_3, city_1, city_2, city_3)\n",
    "                        \n",
    "                        prev_context = sample.prev_context\n",
    "                        \n",
    "                        prev_tokens = tokenizer.encode(prev_context, return_tensors=\"pt\").to(model.encoder.device)\n",
    "                        with torch.no_grad():\n",
    "                            encoded_prev = model.encoder(prev_tokens, output_special=True, output_hidden_states=True)\n",
    "                        with torch.no_grad():\n",
    "                            model_out = model.generate(input_ids=prev_tokens, \n",
    "                                         max_new_tokens=10,\n",
    "                                         return_dict_in_generate=True, \n",
    "                                         output_scores=True)\n",
    "\n",
    "                        sample.add_prev_encoding(encoded_prev)\n",
    "                        sample.add_generation(model_out)\n",
    "                        \n",
    "                        data_points_three_sentences_case1.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7214f4be-be4a-4dc7-a20a-d6d502714fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/ThreeSentenceDataEncodings/data_points_three_sentences_case1.txt\", \"wb\") as f:\n",
    "    pickle.dump(data_points_three_sentences_case1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fed6080c-a8dd-4e8d-abf0-3bdbe0367ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/ThreeSentenceDataEncodings/data_points_three_sentences_case1.txt\", \"rb\") as f:\n",
    "    data_points_three_sentences_case1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d852859-d5f0-4910-b011-1d7113887f0e",
   "metadata": {},
   "source": [
    "# Case 2 Pre-Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc4c7778-5873-4fa6-9cb0-c2b8409f474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points_three_sentences_case2 = []\n",
    "for sample in data_points_three_sentences_case1:\n",
    "    name_1 = sample.name_1\n",
    "    name_2 = sample.name_2\n",
    "    name_3 = sample.name_3\n",
    "    city_1 = sample.city_1\n",
    "    city_2 = sample.city_2\n",
    "    city_3 = sample.city_3\n",
    "    prev_context = sample.prev_context \n",
    "    current_context_1 = sample.current_context_1\n",
    "    current_context_2 = sample.current_context_2\n",
    "    current_context_3 = sample.current_context_3\n",
    "    prev_encoding = sample.prev_encoding\n",
    "    \n",
    "    sample = DataSample_ThreeSentences(name_1, name_2, name_3, city_1, city_2, city_3)\n",
    "    \n",
    "    sample.add_prev_encoding(prev_encoding)\n",
    "    \n",
    "    curr_tokens_1 = tokenizer.encode(current_context_1, return_tensors=\"pt\").to(model.encoder.device)\n",
    "    with torch.no_grad():\n",
    "        encoded_curr_1 = model.encoder(curr_tokens_1)\n",
    "    sample.add_current_encoding_1(encoded_curr_1)\n",
    "\n",
    "    curr_tokens_2 = tokenizer.encode(current_context_2, return_tensors=\"pt\").to(model.encoder.device)\n",
    "    with torch.no_grad():\n",
    "        encoded_curr_2 = model.encoder(curr_tokens_2)\n",
    "    sample.add_current_encoding_2(encoded_curr_2)\n",
    "    \n",
    "    curr_tokens_3 = tokenizer.encode(current_context_3, return_tensors=\"pt\").to(model.encoder.device)\n",
    "    with torch.no_grad():\n",
    "        encoded_curr_3 = model.encoder(curr_tokens_3)\n",
    "    sample.add_current_encoding_3(encoded_curr_3)\n",
    "\n",
    "    data_points_three_sentences_case2.append(sample)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18ca4d11-5ecf-41ed-8787-7e0a56be97d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/ThreeSentenceDataEncodings/data_points_three_sentences_case2.txt\", \"wb\") as f:\n",
    "    pickle.dump(data_points_three_sentences_case2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "817699a7-7cdf-4aa1-8f95-540418ca12d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/ThreeSentenceDataEncodings/data_points_three_sentences_case2.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/ThreeSentenceDataEncodings/data_points_three_sentences_case2.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     data_points_three_sentences_case2 \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[0;32m~/.conda/envs/hf/lib/python3.8/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/ThreeSentenceDataEncodings/data_points_three_sentences_case2.txt'"
     ]
    }
   ],
   "source": [
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/ThreeSentenceDataEncodings/data_points_three_sentences_case2.txt\", \"rb\") as f:\n",
    "    data_points_three_sentences_case2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6d2878-38c7-4013-97b9-11574e4d272b",
   "metadata": {},
   "source": [
    "# Pairs to Rewrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c1b351d3-0cfb-455f-bfa3-eb5a8f60f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_to_observe = []\n",
    "\n",
    "for i in range(len(data_points_three_sentences_case1)-1):\n",
    "    for j in range(i+1, len(data_points_three_sentences_case1)):\n",
    "        sample_1 = data_points_three_sentences_case1[i]\n",
    "        sample_2 = data_points_three_sentences_case1[j]\n",
    "\n",
    "        if (sample_1.name_1 == sample_2.name_1\n",
    "            and sample_1.name_2 == sample_2.name_2 \n",
    "            and sample_1.name_3 == sample_2.name_3\n",
    "            and sample_1.city_1 == sample_2.city_1 \n",
    "            and sample_1.city_2 == sample_2.city_2 \n",
    "            and sample_1.city_3 != sample_2.city_3):\n",
    "\n",
    "            \"\"\"print(sample_1.prev_context)\n",
    "            print(sample_2.prev_context)\n",
    "            \n",
    "            print()\n",
    "            print()\"\"\"\n",
    "            \n",
    "            pairs_to_observe.append((sample_1, sample_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a548aaf9-1469-484d-a82c-62acb385b035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_points_three_sentences_case1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a62b81dc-d625-41a4-8a00-e68feed555f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs_to_observe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e76fae-6145-4418-bafb-058394205ac2",
   "metadata": {},
   "source": [
    "# Case 1 Rewrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfe92950-44c9-42e7-9391-04cde4d0c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_move = [9] # middle _to token\n",
    "\n",
    "case1_middle_to_results = case1_rewrite(pairs_to_observe, ids_to_move)\n",
    "\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case1_middle_to_results.txt\", \"wb\") as f:\n",
    "    pickle.dump(case1_middle_to_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b89f304-e303-4a92-8f70-57efb2a30e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case1_middle_to_results.txt\", \"rb\") as f:\n",
    "    case1_middle_to_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c33e5b9d-f48a-439a-8ded-0f435223a71d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids_to_move = [16]\n",
    "\n",
    "case1_loc_results = case1_rewrite(pairs_to_observe, ids_to_move)\n",
    "\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case1_loc_results.txt\", \"wb\") as f:\n",
    "    pickle.dump(case1_loc_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6718fda1-ce5b-4062-a0b5-9a4045c58d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_move = [12, 13, 14, 15]\n",
    "\n",
    "case1_allexceptloc_results = case1_rewrite(pairs_to_observe, ids_to_move)\n",
    "\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case1_allexceptloc_results.txt\", \"wb\") as f:\n",
    "    pickle.dump(case1_allexceptloc_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1ba7c746-522a-4939-b68a-d9dea2debdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_move = [12, 13, 14, 15, 16]\n",
    "\n",
    "case1_alltok_results = case1_rewrite(pairs_to_observe, ids_to_move)\n",
    "\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case1_alltok_results.txt\", \"wb\") as f:\n",
    "    pickle.dump(case1_alltok_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d938fca5-771d-43d7-815c-04f03dcdabc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_move = list(range(16))\n",
    "\n",
    "case1_all3sentexceptlastloc_results = case1_rewrite(pairs_to_observe, ids_to_move)\n",
    "\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case1_all3sentexceptlastloc_results.txt\", \"wb\") as f:\n",
    "    pickle.dump(case1_all3sentexceptlastloc_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bada61d-838f-4d28-9b53-66cb817cc854",
   "metadata": {},
   "source": [
    "# Case 2 Rewrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcac9de5-0f9d-417e-8642-58d7e8b41aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_move = [9] # middle _to token\n",
    "\n",
    "case2_middle_to_results = case2_rewrite(pairs_to_observe, ids_to_move)\n",
    "\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case2_middle_to_results.txt\", \"wb\") as f:\n",
    "    pickle.dump(case2_middle_to_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a44110f8-b266-4567-b416-a3b3a3c6ed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case2_middle_to_results.txt\", \"rb\") as f:\n",
    "    case2_middle_to_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "de98a98f-98e5-4290-8d9d-d5f76314dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_move = [16]\n",
    "\n",
    "case2_loc_results = case2_rewrite(pairs_to_observe, ids_to_move)\n",
    "\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case2_loc_results.txt\", \"wb\") as f:\n",
    "    pickle.dump(case2_loc_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "99432a00-2619-46b9-be45-54761fda2ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_move = [12, 13, 14, 15]\n",
    "\n",
    "case2_allexceptloc_results = case2_rewrite(pairs_to_observe, ids_to_move)\n",
    "\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case2_allexceptloc_results.txt\", \"wb\") as f:\n",
    "    pickle.dump(case2_allexceptloc_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "56b1b2d5-4451-458a-8944-69328e16a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_move = [12, 13, 14, 15, 16]\n",
    "\n",
    "case2_alltok_results = case2_rewrite(pairs_to_observe, ids_to_move)\n",
    "\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case2_alltok_results.txt\", \"wb\") as f:\n",
    "    pickle.dump(case2_alltok_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9ea392c6-85ab-4ac2-b593-9f7364aca3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_move = list(range(16))\n",
    "\n",
    "case2_all3sentexceptlastloc_results = case2_rewrite(pairs_to_observe, ids_to_move)\n",
    "\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case2_all3sentexceptlastloc_results.txt\", \"wb\") as f:\n",
    "    pickle.dump(case2_all3sentexceptlastloc_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad585bb1-bcf8-4a40-b9ef-5886c1892bd6",
   "metadata": {},
   "source": [
    "# Result Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28dc5599-0781-46a6-88e2-7ee2b50db800",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case1_middle_to_results.txt\", \"rb\") as f:\n",
    "    case1_middle_to_results = pickle.load(f)\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case1_loc_results.txt\", \"rb\") as f:\n",
    "    case1_loc_results = pickle.load(f)\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case1_allexceptloc_results.txt\", \"rb\") as f:\n",
    "    case1_allexceptloc_results = pickle.load(f)\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case1_alltok_results.txt\", \"rb\") as f:\n",
    "    case1_alltok_results = pickle.load(f)\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case1_all3sentexceptlastloc_results.txt\", \"rb\") as f:\n",
    "    case1_all3sentexceptlastloc_results = pickle.load(f)\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case2_middle_to_results.txt\", \"rb\") as f:\n",
    "    case2_middle_to_results = pickle.load(f)\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case2_loc_results.txt\", \"rb\") as f:\n",
    "    case2_loc_results = pickle.load(f)\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case2_allexceptloc_results.txt\", \"rb\") as f:\n",
    "    case2_allexceptloc_results = pickle.load(f)\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case2_alltok_results.txt\", \"rb\") as f:\n",
    "    case2_alltok_results = pickle.load(f)\n",
    "with open(\"/kuacc/users/bozyurt20/hpc_run/Sherlock Holmes/Rewrite/Results/case2_all3sentexceptlastloc_results.txt\", \"rb\") as f:\n",
    "    case2_all3sentexceptlastloc_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11ad4558-4a2f-4ff2-8953-84e3b41e00b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_probability(model_out, token):\n",
    "    global next_token_scores\n",
    "    token_id = tokenizer.encode(token)[0]\n",
    "    next_token_scores = torch.nn.functional.softmax(model_out.scores[0].float(), dim=-1)  # (batch_size * num_beams, vocab_size)\n",
    "    probability = next_token_scores[0][token_id].item()\n",
    "    \n",
    "    _, indices = torch.sort(next_token_scores, descending=True)\n",
    "    max_prob_ind = torch.where(indices[0] == token_id)[0].item() + 1\n",
    "    \n",
    "    return probability, max_prob_ind\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8af0347-8dc0-4e91-8478-3dcf131767e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_rewrite_results(results):\n",
    "\n",
    "    sentence_1_acc = []\n",
    "    sentence_2_acc = []\n",
    "\n",
    "    sentence_rewritten_answer_1 = []\n",
    "    sentence_rewritten_answer_2 = []\n",
    "\n",
    "    generation_lens = defaultdict(int)\n",
    "\n",
    "    probability_results = np.zeros((3, 2, 3**6))\n",
    "    probability_results_diff = np.zeros((3, 2, 3**6))\n",
    "    sorted_results = np.zeros((3, 2, 3**6))\n",
    "    sorted_results_diff = np.zeros((3, 2, 3**6))\n",
    "\n",
    "    for i, result in enumerate(results):\n",
    "        context_1 = result.context_1    \n",
    "        context_2 = result.context_2\n",
    "        generation_1 = result.generation_1\n",
    "        generation_2 = result.generation_2\n",
    "        generation_rewritten = result.generation_rewritten\n",
    "        answer_1 = result.answer_1\n",
    "        answer_2 = result.answer_2\n",
    "\n",
    "        out_sequence_1 = tokenizer.decode(generation_1.sequences[0], skip_special_tokens=True)\n",
    "        out_sequence_2 = tokenizer.decode(generation_2.sequences[0], skip_special_tokens=True)\n",
    "        out_sequence_rewritten = tokenizer.decode(generation_rewritten.sequences[0], skip_special_tokens=True)\n",
    "\n",
    "        gen_1_ans_1, ind_11 = get_token_probability(generation_1, answer_1)\n",
    "        gen_1_ans_2, ind_12 = get_token_probability(generation_1, answer_2)    \n",
    "        gen_2_ans_1, ind_21 = get_token_probability(generation_2, answer_1)\n",
    "        gen_2_ans_2, ind_22 = get_token_probability(generation_2, answer_2)\n",
    "        gen_rw_ans_1, ind_rw1 = get_token_probability(generation_rewritten, answer_1)\n",
    "        gen_rw_ans_2, ind_rw2 = get_token_probability(generation_rewritten, answer_2)\n",
    "\n",
    "        \"\"\"print(gen_1_ans_1)\n",
    "        print(gen_1_ans_2)\n",
    "        print(gen_2_ans_1)\n",
    "        print(gen_2_ans_2)\n",
    "        print(gen_rw_ans_1)\n",
    "        print(gen_rw_ans_2)\n",
    "\n",
    "        print(ind_11)\n",
    "        print(ind_12)\n",
    "        print(ind_21)\n",
    "        print(ind_22)\n",
    "        print(ind_rw1)\n",
    "        print(ind_rw2)\"\"\"\n",
    "\n",
    "        generation_lens[len(generation_1.sequences[0])] += 1\n",
    "        generation_lens[len(generation_2.sequences[0])] += 1\n",
    "        generation_lens[len(generation_rewritten.sequences[0])] += 1\n",
    "\n",
    "        if answer_1 in out_sequence_1:\n",
    "            sentence_1_acc.append(1)\n",
    "        else:\n",
    "            sentence_1_acc.append(0)\n",
    "        if answer_2 in out_sequence_2:\n",
    "            sentence_2_acc.append(1)\n",
    "        else:\n",
    "            sentence_2_acc.append(0)      \n",
    "\n",
    "        if answer_1 in out_sequence_rewritten:\n",
    "            sentence_rewritten_answer_1.append(1)\n",
    "        else:\n",
    "            sentence_rewritten_answer_1.append(0)\n",
    "        if answer_2 in out_sequence_rewritten:\n",
    "            sentence_rewritten_answer_2.append(1)\n",
    "        else:\n",
    "            sentence_rewritten_answer_2.append(0)\n",
    "            \n",
    "        probability_results[:, :, i] = [ [gen_1_ans_1, gen_1_ans_2],\n",
    "                                         [gen_2_ans_1, gen_2_ans_2], \n",
    "                                         [gen_rw_ans_1 , gen_rw_ans_2] ]\n",
    "\n",
    "        probability_results_diff[:, :, i] = [ [gen_1_ans_1 - gen_2_ans_1, gen_1_ans_2 - gen_2_ans_2],\n",
    "                                         [gen_rw_ans_1 - gen_1_ans_1, gen_rw_ans_2 - gen_1_ans_2], \n",
    "                                         [gen_rw_ans_1 - gen_2_ans_1, gen_rw_ans_2 - gen_2_ans_2]]\n",
    "\n",
    "        sorted_results[:, :, i] = [  [ind_11, ind_12],\n",
    "                                     [ind_21, ind_22], \n",
    "                                     [ind_rw1, ind_rw2]]\n",
    "\n",
    "        sorted_results_diff[:, :, i] = [  [ind_11 - ind_21, ind_12 - ind_22],\n",
    "                                     [ind_rw1 - ind_11, ind_rw2 - ind_12], \n",
    "                                     [ind_rw1 - ind_21, ind_rw2 - ind_22]]\n",
    "\n",
    "    acc_1 = sum(sentence_1_acc)/len(sentence_1_acc)\n",
    "    acc_2 = sum(sentence_2_acc)/len(sentence_2_acc)\n",
    "\n",
    "    acc_rw1 = sum(sentence_rewritten_answer_1)/len(sentence_rewritten_answer_1)\n",
    "    acc_rw2 = sum(sentence_rewritten_answer_2)/len(sentence_rewritten_answer_2)\n",
    "    \n",
    "    print(\"Accuracy of context 1, city1:\", acc_1)\n",
    "    print(\"Accuracy of context 2, city2:\", acc_2)\n",
    "    print(\"Accuracy of rewritten context, city 1:\", acc_rw1)\n",
    "    print(\"Accuracy of rewritten context, city 2:\", acc_rw2)\n",
    "    print()\n",
    "    print(\"Probability of generating the answer tokens: \", np.average(probability_results, axis=-1).tolist())\n",
    "    print(\"Probability of generating the answer tokens, difference: \", np.average(probability_results_diff, axis=-1).tolist())\n",
    "    print(\"Token generation index:\", np.average(sorted_results, axis=-1).tolist())\n",
    "    print(\"Token generation index, difference:\", np.average(sorted_results_diff, axis=-1).tolist())\n",
    "    \n",
    "    return acc_1, acc_2, acc_rw1, acc_rw2, generation_lens, probability_results, probability_results_diff, sorted_results, sorted_results_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b73333-3e74-4258-8584-cefc052312f6",
   "metadata": {},
   "source": [
    "## Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7be28c97-d41d-407e-8711-42e6c834b018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of context 1, city1: 1.0\n",
      "Accuracy of context 2, city2: 1.0\n",
      "Accuracy of rewritten context, city 1: 0.0\n",
      "Accuracy of rewritten context, city 2: 1.0\n",
      "\n",
      "Probability of generating the answer tokens:  [[0.9578431850434658, 3.6188950995433694e-05], [1.0024356529266287e-05, 0.9808337654923542], [9.977434288914297e-06, 0.9809350096639783]]\n",
      "Probability of generating the answer tokens, difference:  [[0.9578331606869366, -0.9807975765413588], [-0.9578332076091768, 0.9808988207129828], [-4.692224035198956e-08, 0.00010124417162399397]]\n",
      "Token generation index: [[1.0, 269.997256515775], [192.77366255144034, 1.0], [192.31001371742113, 1.0]]\n",
      "Token generation index, difference: [[-191.77366255144034, 268.997256515775], [191.31001371742113, -268.997256515775], [-0.46364883401920437, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "acc_1, acc_2, acc_rw1, acc_rw2, generation_lens, probability_results, probability_results_diff, sorted_results, sorted_results_diff = check_rewrite_results(case1_middle_to_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "042f089c-87ec-489b-9ec6-901029bd3c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of context 1, city1: 1.0\n",
      "Accuracy of context 2, city2: 1.0\n",
      "Accuracy of rewritten context, city 1: 1.0\n",
      "Accuracy of rewritten context, city 2: 0.0\n",
      "\n",
      "Probability of generating the answer tokens:  [[0.9578431850434658, 3.6188950995433694e-05], [1.0024356529266287e-05, 0.9808337654923542], [0.9565908590789031, 3.736941194759639e-05]]\n",
      "Probability of generating the answer tokens, difference:  [[0.9578331606869366, -0.9807975765413588], [-0.001252325964562687, 1.1804609521626924e-06], [0.9565808347223739, -0.9807963960804067]]\n",
      "Token generation index: [[1.0, 269.997256515775], [192.77366255144034, 1.0], [1.0, 272.7818930041152]]\n",
      "Token generation index, difference: [[-191.77366255144034, 268.997256515775], [0.0, 2.784636488340192], [-191.77366255144034, 271.7818930041152]]\n"
     ]
    }
   ],
   "source": [
    "acc_1, acc_2, acc_rw1, acc_rw2, generation_lens, probability_results, probability_results_diff, sorted_results, sorted_results_diff = check_rewrite_results(case1_loc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3893397-9d32-4d69-a1a4-032b0fedd716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of context 1, city1: 1.0\n",
      "Accuracy of context 2, city2: 1.0\n",
      "Accuracy of rewritten context, city 1: 0.0\n",
      "Accuracy of rewritten context, city 2: 1.0\n",
      "\n",
      "Probability of generating the answer tokens:  [[0.9578431850434658, 3.6188950995433694e-05], [1.0024356529266287e-05, 0.9808337654923542], [1.005252838808857e-05, 0.9801506396837849]]\n",
      "Probability of generating the answer tokens, difference:  [[0.9578331606869366, -0.9807975765413588], [-0.9578331325150777, 0.9801144507327895], [2.817185882228476e-08, -0.0006831258085693025]]\n",
      "Token generation index: [[1.0, 269.997256515775], [192.77366255144034, 1.0], [191.93141289437585, 1.0]]\n",
      "Token generation index, difference: [[-191.77366255144034, 268.997256515775], [190.93141289437585, -268.997256515775], [-0.8422496570644719, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "acc_1, acc_2, acc_rw1, acc_rw2, generation_lens, probability_results, probability_results_diff, sorted_results, sorted_results_diff = check_rewrite_results(case1_allexceptloc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c97916e-e919-40d9-8309-578439a3e571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of context 1, city1: 1.0\n",
      "Accuracy of context 2, city2: 1.0\n",
      "Accuracy of rewritten context, city 1: 1.0\n",
      "Accuracy of rewritten context, city 2: 0.0\n",
      "\n",
      "Probability of generating the answer tokens:  [[0.9578431850434658, 3.6188950995433694e-05], [1.0024356529266287e-05, 0.9808337654923542], [0.9570660140615759, 3.609393726884016e-05]]\n",
      "Probability of generating the answer tokens, difference:  [[0.9578331606869366, -0.9807975765413588], [-0.0007771709818898896, -9.501372659354153e-08], [0.9570559897050467, -0.9807976715550853]]\n",
      "Token generation index: [[1.0, 269.997256515775], [192.77366255144034, 1.0], [1.0, 274.91495198902606]]\n",
      "Token generation index, difference: [[-191.77366255144034, 268.997256515775], [0.0, 4.917695473251029], [-191.77366255144034, 273.91495198902606]]\n"
     ]
    }
   ],
   "source": [
    "acc_1, acc_2, acc_rw1, acc_rw2, generation_lens, probability_results, probability_results_diff, sorted_results, sorted_results_diff = check_rewrite_results(case1_alltok_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c6e5b73-48d6-4c62-9d93-fe428ab21875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of context 1, city1: 1.0\n",
      "Accuracy of context 2, city2: 1.0\n",
      "Accuracy of rewritten context, city 1: 0.0\n",
      "Accuracy of rewritten context, city 2: 1.0\n",
      "\n",
      "Probability of generating the answer tokens:  [[0.9578431850434658, 3.6188950995433694e-05], [1.0024356529266287e-05, 0.9808337654923542], [9.341803144641105e-06, 0.980047610725068]]\n",
      "Probability of generating the answer tokens, difference:  [[0.9578331606869366, -0.9807975765413588], [-0.9578338432403212, 0.9800114217740725], [-6.825533846251811e-07, -0.0007861547672863032]]\n",
      "Token generation index: [[1.0, 269.997256515775], [192.77366255144034, 1.0], [198.22085048010973, 1.0]]\n",
      "Token generation index, difference: [[-191.77366255144034, 268.997256515775], [197.22085048010973, -268.997256515775], [5.44718792866941, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "acc_1, acc_2, acc_rw1, acc_rw2, generation_lens, probability_results, probability_results_diff, sorted_results, sorted_results_diff = check_rewrite_results(case1_all3sentexceptlastloc_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a3de8a-4016-43ca-87be-041bea5601d8",
   "metadata": {},
   "source": [
    "## Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a9b4e9a-fd5d-430a-b0b1-6ad5cf66d104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of context 1, city1: 1.0\n",
      "Accuracy of context 2, city2: 1.0\n",
      "Accuracy of rewritten context, city 1: 0.0\n",
      "Accuracy of rewritten context, city 2: 1.0\n",
      "\n",
      "Probability of generating the answer tokens:  [[0.9578431850434658, 3.6188950995433694e-05], [1.0024356529266287e-05, 0.9808337654923542], [1.0093023461045406e-05, 0.9807449892388123]]\n",
      "Probability of generating the answer tokens, difference:  [[0.9578331606869366, -0.9807975765413588], [-0.9578330920200048, 0.9807088002878168], [6.866693177911862e-08, -8.877625354196473e-05]]\n",
      "Token generation index: [[1.0, 269.997256515775], [192.77366255144034, 1.0], [193.90946502057614, 1.0]]\n",
      "Token generation index, difference: [[-191.77366255144034, 268.997256515775], [192.90946502057614, -268.997256515775], [1.1358024691358024, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "acc_1, acc_2, acc_rw1, acc_rw2, generation_lens, probability_results, probability_results_diff, sorted_results, sorted_results_diff = check_rewrite_results(case2_middle_to_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d8a129b-7519-4f80-b580-e43b037f9ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of context 1, city1: 1.0\n",
      "Accuracy of context 2, city2: 1.0\n",
      "Accuracy of rewritten context, city 1: 1.0\n",
      "Accuracy of rewritten context, city 2: 0.0\n",
      "\n",
      "Probability of generating the answer tokens:  [[0.9578431850434658, 3.6188950995433694e-05], [1.0024356529266287e-05, 0.9808337654923542], [0.9593255508420235, 3.8994317712524644e-05]]\n",
      "Probability of generating the answer tokens, difference:  [[0.9578331606869366, -0.9807975765413588], [0.0014823657985577367, 2.8053667170909503e-06], [0.9593155264854943, -0.9807947711746418]]\n",
      "Token generation index: [[1.0, 269.997256515775], [192.77366255144034, 1.0], [1.0, 230.88477366255145]]\n",
      "Token generation index, difference: [[-191.77366255144034, 268.997256515775], [0.0, -39.1124828532236], [-191.77366255144034, 229.88477366255145]]\n"
     ]
    }
   ],
   "source": [
    "acc_1, acc_2, acc_rw1, acc_rw2, generation_lens, probability_results, probability_results_diff, sorted_results, sorted_results_diff = check_rewrite_results(case2_loc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e96b19d6-ee5a-4ad1-bba7-1c2141663738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of context 1, city1: 1.0\n",
      "Accuracy of context 2, city2: 1.0\n",
      "Accuracy of rewritten context, city 1: 0.0\n",
      "Accuracy of rewritten context, city 2: 1.0\n",
      "\n",
      "Probability of generating the answer tokens:  [[0.9578431850434658, 3.6188950995433694e-05], [1.0024356529266287e-05, 0.9808337654923542], [1.0353784404255143e-05, 0.9796839546110732]]\n",
      "Probability of generating the answer tokens, difference:  [[0.9578331606869366, -0.9807975765413588], [-0.9578328312590615, 0.9796477656600777], [3.294278749888563e-07, -0.0011498108812810952]]\n",
      "Token generation index: [[1.0, 269.997256515775], [192.77366255144034, 1.0], [186.86008230452674, 1.0]]\n",
      "Token generation index, difference: [[-191.77366255144034, 268.997256515775], [185.86008230452674, -268.997256515775], [-5.91358024691358, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "acc_1, acc_2, acc_rw1, acc_rw2, generation_lens, probability_results, probability_results_diff, sorted_results, sorted_results_diff = check_rewrite_results(case2_allexceptloc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d39198ec-5ef5-41c7-8530-6598d7bf4d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of context 1, city1: 1.0\n",
      "Accuracy of context 2, city2: 1.0\n",
      "Accuracy of rewritten context, city 1: 1.0\n",
      "Accuracy of rewritten context, city 2: 0.0\n",
      "\n",
      "Probability of generating the answer tokens:  [[0.9578431850434658, 3.6188950995433694e-05], [1.0024356529266287e-05, 0.9808337654923542], [0.9574766288241895, 3.673426079406445e-05]]\n",
      "Probability of generating the answer tokens, difference:  [[0.9578331606869366, -0.9807975765413588], [-0.0003665562192762503, 5.453097986307557e-07], [0.9574666044676603, -0.9807970312315601]]\n",
      "Token generation index: [[1.0, 269.997256515775], [192.77366255144034, 1.0], [1.0, 262.22770919067216]]\n",
      "Token generation index, difference: [[-191.77366255144034, 268.997256515775], [0.0, -7.769547325102881], [-191.77366255144034, 261.22770919067216]]\n"
     ]
    }
   ],
   "source": [
    "acc_1, acc_2, acc_rw1, acc_rw2, generation_lens, probability_results, probability_results_diff, sorted_results, sorted_results_diff = check_rewrite_results(case2_alltok_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a62d1428-3ccd-41f4-bc4e-d0f1bbdd0f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of context 1, city1: 1.0\n",
      "Accuracy of context 2, city2: 1.0\n",
      "Accuracy of rewritten context, city 1: 0.0\n",
      "Accuracy of rewritten context, city 2: 1.0\n",
      "\n",
      "Probability of generating the answer tokens:  [[0.9578431850434658, 3.6188950995433694e-05], [1.0024356529266287e-05, 0.9808337654923542], [9.973773307080501e-06, 0.9791468326283417]]\n",
      "Probability of generating the answer tokens, difference:  [[0.9578331606869366, -0.9807975765413588], [-0.9578332112701587, 0.9791106436773462], [-5.058322218578618e-08, -0.0016869328640125416]]\n",
      "Token generation index: [[1.0, 269.997256515775], [192.77366255144034, 1.0], [196.14677640603566, 1.0]]\n",
      "Token generation index, difference: [[-191.77366255144034, 268.997256515775], [195.14677640603566, -268.997256515775], [3.373113854595336, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "acc_1, acc_2, acc_rw1, acc_rw2, generation_lens, probability_results, probability_results_diff, sorted_results, sorted_results_diff = check_rewrite_results(case2_all3sentexceptlastloc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefd82fa-f122-4856-ba81-65cec0b6e3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dce1c19-c999-43d5-bf28-4fff05f896e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9033fb0c-2e11-4b8c-a526-b98d4c441526",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (676971914.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    cp modeling_t5.py /kuacc/users/bozyurt20/.conda/envs/hf/lib/python3.8/site-packages/transformers/models/t5/\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/kuacc/users/bozyurt20/.conda/envs/hf/lib/python3.8/site-packages/transformers/models/')\n",
    "cp modeling_t5.py /kuacc/users/bozyurt20/.conda/envs/hf/lib/python3.8/site-packages/transformers/models/t5/\n",
    "cp utils.py /kuacc/users/bozyurt20/.conda/envs/hf/lib/python3.8/site-packages/transformers/generation/\n",
    "cp modeling_outputs.py /kuacc/users/bozyurt20/.conda/envs/hf/lib/python3.8/site-packages/transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa7522-5427-4a8e-92e0-1d34ef26e125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
